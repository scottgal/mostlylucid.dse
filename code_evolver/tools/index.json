{
  "http_server": {
    "tool_id": "http_server",
    "name": "HTTP Server",
    "tool_type": "custom",
    "description": "HTTP server that allows workflows to serve content via HTTP. Supports both HTML and JSON/API responses. Enable workflows to be exposed as web services or REST APIs. Can register endpoints, handle requests, and return formatted responses.",
    "tags": [
      "http",
      "server",
      "api",
      "web",
      "rest",
      "endpoint",
      "service",
      "html",
      "json"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "custom\\http_server.yaml",
      "version": "1.0.0",
      "definition_hash": "e1f9848cc3e93ed5c37afad0bc69e3f94233a1e2eba9c744f3c4bef6475b8304",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299547Z"
    },
    "created_at": "2025-11-16T08:22:00.386029Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "e1f9848cc3e93ed5c37afad0bc69e3f94233a1e2eba9c744f3c4bef6475b8304",
    "breaking_changes": []
  },
  "bandit_security": {
    "tool_id": "bandit_security",
    "name": "Bandit Security Scanner",
    "tool_type": "executable",
    "description": "Runs bandit security scanner to find common security issues in Python code",
    "tags": [
      "python",
      "security",
      "vulnerability",
      "scanning"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\bandit_security.yaml",
      "command": "bandit",
      "args": [
        "-r",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "53b7f198ed0bf47b1d653c12c9f72a9f4e571d02c4ab77875ea9bc02ff50b701",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299560Z"
    },
    "created_at": "2025-11-16T08:22:01.350706Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "53b7f198ed0bf47b1d653c12c9f72a9f4e571d02c4ab77875ea9bc02ff50b701",
    "breaking_changes": []
  },
  "basic_calculator": {
    "tool_id": "basic_calculator",
    "name": "Basic Calculator",
    "tool_type": "executable",
    "description": "Fast arithmetic operations (add, subtract, multiply, divide, power, modulo). Direct Python execution - no LLM needed. Use for simple math.",
    "tags": [
      "math",
      "arithmetic",
      "calculator",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\basic_calculator.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); ops={'add': lambda a,b: a+b, 'subtract': lambda a,b: a-b, 'multiply': lambda a,b: a*b, 'divide': lambda a,b: a/b if b!=0 else float('inf'), 'power': lambda a,b: a**b, 'modulo': lambda a,b: a%b if b!=0 else 0}; result=ops.get(data['operation'], ops['add'])(data.get('a', 0), data.get('b', 0)); print(json.dumps({'result': result, 'operation': data.get('operation', 'add')}))"
      ],
      "input_schema": {
        "operation": "str - Operation: 'add', 'subtract', 'multiply', 'divide', 'power', 'modulo'",
        "a": "number - First operand",
        "b": "number - Second operand"
      },
      "output_schema": {
        "result": "number - Result of the operation",
        "operation": "str - Operation performed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "60ad537b0cc174444ffc347fc39166a15fac61fceebaa0c047e5f49ec575c68f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299566Z"
    },
    "created_at": "2025-11-16T08:22:01.479592Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "60ad537b0cc174444ffc347fc39166a15fac61fceebaa0c047e5f49ec575c68f",
    "breaking_changes": []
  },
  "black_formatter": {
    "tool_id": "black_formatter",
    "name": "Black Code Formatter",
    "tool_type": "executable",
    "description": "Runs black formatter to check if Python code follows black style (with --check flag)",
    "tags": [
      "python",
      "formatting",
      "style",
      "black"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\black_formatter.yaml",
      "command": "black",
      "args": [
        "--check",
        "--diff",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "b305d7015944f99679370dfc90c002b26d6b26ed1c7627f36c59da1e8968be44",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299572Z"
    },
    "created_at": "2025-11-16T08:22:01.604551Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "b305d7015944f99679370dfc90c002b26d6b26ed1c7627f36c59da1e8968be44",
    "breaking_changes": []
  },
  "call_tool_validator": {
    "tool_id": "call_tool_validator",
    "name": "call_tool() Usage Validator",
    "tool_type": "executable",
    "description": "Validates that call_tool() is used correctly with proper arguments (tool_name, prompt)",
    "tags": [
      "python",
      "validation",
      "call_tool",
      "node_runtime",
      "static-analysis"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\call_tool_validator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/call_tool_validator.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "6025a4a4362f8a0fca395be39a3e0bf90ef6e44792b2ebaaf0be585c377f9cc0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299578Z"
    },
    "created_at": "2025-11-16T08:22:01.718302Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6025a4a4362f8a0fca395be39a3e0bf90ef6e44792b2ebaaf0be585c377f9cc0",
    "breaking_changes": []
  },
  "isort_import_checker": {
    "tool_id": "isort_import_checker",
    "name": "Isort Import Checker",
    "tool_type": "executable",
    "description": "Checks if Python imports are sorted correctly",
    "tags": [
      "python",
      "imports",
      "style",
      "organization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\isort_import_checker.yaml",
      "command": "isort",
      "args": [
        "--check-only",
        "--diff",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "1e57d9554d404405f3e4f57d96d4b511af10079af04a85b068ac72fef72257a0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299584Z"
    },
    "created_at": "2025-11-16T08:22:01.837723Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "1e57d9554d404405f3e4f57d96d4b511af10079af04a85b068ac72fef72257a0",
    "breaking_changes": []
  },
  "json_output_validator": {
    "tool_id": "json_output_validator",
    "name": "JSON Output Validator",
    "tool_type": "executable",
    "description": "Validates that node code outputs valid JSON using json.dumps() and print()",
    "tags": [
      "python",
      "json",
      "validation",
      "output",
      "static-analysis"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\json_output_validator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/json_output_validator.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "9ade0c45183b21a026ebd04be205d56e4edb7ddd69414c23fe6ff73400e8e09b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299595Z"
    },
    "created_at": "2025-11-16T08:22:01.944711Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "9ade0c45183b21a026ebd04be205d56e4edb7ddd69414c23fe6ff73400e8e09b",
    "breaking_changes": []
  },
  "load_from_disk": {
    "tool_id": "load_from_disk",
    "name": "Load from Disk",
    "tool_type": "executable",
    "description": "Loads content from any file path on disk. Use for reading specifications, code, documentation, or configuration files. Can read from anywhere on the filesystem (not restricted to ./output/). Useful for self-optimization tasks where the system reads its own code.",
    "tags": [
      "file-io",
      "load",
      "read",
      "disk",
      "input"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\load_from_disk.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json, pathlib; data=json.load(sys.stdin); path=pathlib.Path(data['filepath']); content=path.read_text() if path.exists() else None; print(json.dumps({'status': 'loaded' if content else 'not_found', 'content': content, 'path': str(path)}))"
      ],
      "input_schema": {
        "filepath": "str - Full or relative path to file to load"
      },
      "output_schema": {
        "status": "str - 'loaded' if successful, 'not_found' if file doesn't exist",
        "content": "str - Content of the file",
        "path": "str - Full path that was read"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "f1aedee18eca7a5db9a44adb38bd2278469ffa8e357cefb5e3656c63231e897f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299600Z"
    },
    "created_at": "2025-11-16T08:22:02.053755Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "f1aedee18eca7a5db9a44adb38bd2278469ffa8e357cefb5e3656c63231e897f",
    "breaking_changes": []
  },
  "main_function_checker": {
    "tool_id": "main_function_checker",
    "name": "Main Function Checker",
    "tool_type": "executable",
    "description": "Validates that node code has a proper main() function and __main__ block",
    "tags": [
      "python",
      "structure",
      "validation",
      "main",
      "static-analysis"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\main_function_checker.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/main_function_checker.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "10c71f606aa04c4c90c3fe5bf23e51df3cacbc10000d915a4c8bb4b713ee2215",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299603Z"
    },
    "created_at": "2025-11-16T08:22:02.167106Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "10c71f606aa04c4c90c3fe5bf23e51df3cacbc10000d915a4c8bb4b713ee2215",
    "breaking_changes": []
  },
  "mypy_type_checker": {
    "tool_id": "mypy_type_checker",
    "name": "MyPy Type Checker",
    "tool_type": "executable",
    "description": "Runs mypy type checking on Python code to find type errors before runtime",
    "tags": [
      "python",
      "type-checking",
      "static-analysis",
      "types"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\mypy_type_checker.yaml",
      "command": "mypy",
      "args": [
        "--strict",
        "--show-error-codes",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "0f72ce2ef803c16f1b2bd02a7769e6b2902e9dc8820a574502a396665d37e887",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299607Z"
    },
    "created_at": "2025-11-16T08:22:02.276206Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "0f72ce2ef803c16f1b2bd02a7769e6b2902e9dc8820a574502a396665d37e887",
    "breaking_changes": []
  },
  "node_runtime_import_validator": {
    "tool_id": "node_runtime_import_validator",
    "name": "Node Runtime Import Validator",
    "tool_type": "executable",
    "description": "Validates that node_runtime imports come AFTER sys.path.insert() setup to prevent ModuleNotFoundError",
    "tags": [
      "python",
      "imports",
      "validation",
      "node_runtime",
      "static-analysis",
      "auto-fix"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\node_runtime_import_validator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/node_runtime_import_validator.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "8ad5b36f555ea1b4ac2a76f37c9331164dc4067e0cd2a5c3a2349bcbf4b15ecc",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299612Z"
    },
    "created_at": "2025-11-16T08:22:02.382327Z",
    "usage_count": 119,
    "version": "1.0.0",
    "definition_hash": "8ad5b36f555ea1b4ac2a76f37c9331164dc4067e0cd2a5c3a2349bcbf4b15ecc",
    "breaking_changes": []
  },
  "pip_install": {
    "tool_id": "pip_install",
    "name": "Install Python Package",
    "tool_type": "executable",
    "description": "Installs Python packages using pip. Use when code requires external dependencies like requests, numpy, pandas, etc. Can install single packages or multiple packages at once. Supports version specifications (e.g., 'requests>=2.28.0'). Essential for code that imports third-party libraries.",
    "tags": [
      "dependencies",
      "pip",
      "install",
      "packages",
      "requirements",
      "setup"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pip_install.yaml",
      "command": "python",
      "args": [
        "pip_install_tool.py"
      ],
      "input_schema": {
        "package": "str - Package name(s) to install. Can be single package like 'requests' or multiple like 'requests pandas numpy'. Supports version specs like 'requests>=2.28.0'"
      },
      "output_schema": {
        "status": "str - 'installed' if successful, 'failed' if error",
        "package": "str - Package(s) that were installed",
        "error": "str - Error message if installation failed (optional)"
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "f8b90afbb1440b6c70af18b6512d81a93e1d17a8e7adb654751ae70e05ac2e04",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299617Z"
    },
    "created_at": "2025-11-16T08:22:02.486280Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "f8b90afbb1440b6c70af18b6512d81a93e1d17a8e7adb654751ae70e05ac2e04",
    "breaking_changes": []
  },
  "pydocstyle_checker": {
    "tool_id": "pydocstyle_checker",
    "name": "Pydocstyle Docstring Checker",
    "tool_type": "executable",
    "description": "Checks docstring style and completeness according to PEP 257",
    "tags": [
      "python",
      "documentation",
      "docstrings",
      "pep257"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pydocstyle_checker.yaml",
      "command": "pydocstyle",
      "args": [
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "4d1e2c3402d156b430a26e84b99b15a1514a106274a54faf2ecdc395a5ec48da",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299633Z"
    },
    "created_at": "2025-11-16T08:22:02.604429Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "4d1e2c3402d156b430a26e84b99b15a1514a106274a54faf2ecdc395a5ec48da",
    "breaking_changes": []
  },
  "pyinstrument_profiler": {
    "tool_id": "pyinstrument_profiler",
    "name": "PyInstrument Profiler",
    "tool_type": "executable",
    "description": "Performance profiling using PyInstrument - provides detailed call stack analysis, line-level timing, and performance bottleneck identification. Generates text, HTML, and JSON reports for optimization analysis.",
    "tags": [
      "python",
      "profiling",
      "performance",
      "optimization",
      "pyinstrument"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pyinstrument_profiler.yaml",
      "command": "pyinstrument",
      "args": [
        "-r",
        "text",
        "--show-all",
        "{script_path}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "a9d1c309a217a97080f10a2cef5858f0459ca30581b0fe066fa9794f264e321f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299640Z"
    },
    "created_at": "2025-11-16T08:22:02.703608Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "a9d1c309a217a97080f10a2cef5858f0459ca30581b0fe066fa9794f264e321f",
    "breaking_changes": []
  },
  "pynguin_test_generator": {
    "tool_id": "pynguin_test_generator",
    "name": "Pynguin Test Generator",
    "tool_type": "executable",
    "description": "Fast automated unit test generation using Pynguin's evolutionary algorithm. Generates high-coverage pytest tests automatically from source code.",
    "tags": [
      "testing",
      "test-generation",
      "unit-tests",
      "pytest",
      "coverage",
      "fast",
      "automated",
      "pynguin",
      "evolutionary",
      "first-line-defense"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pynguin_test_generator.yaml",
      "command": "pynguin",
      "args": [
        "--project-path",
        "{project_path}",
        "--module-name",
        "{module_name}",
        "--output-path",
        "{output_path}",
        "--maximum-search-time",
        "{timeout}",
        "--assertion-generation",
        "MUTATION_ANALYSIS",
        "--test-case-output",
        "PytestTest"
      ],
      "input_schema": {
        "project_path": {
          "type": "string",
          "description": "Path to the project directory containing the module",
          "required": true
        },
        "module_name": {
          "type": "string",
          "description": "Name of the module to generate tests for (e.g., 'calculator' for calculator.py)",
          "required": true
        },
        "output_path": {
          "type": "string",
          "description": "Directory where generated tests will be saved",
          "required": true,
          "default": "./tests"
        },
        "timeout": {
          "type": "integer",
          "description": "Maximum search time in seconds (default: 60)",
          "required": false,
          "default": "60"
        }
      },
      "output_schema": {
        "test_file": {
          "type": "string",
          "description": "Path to generated test file (test_{module_name}.py)"
        },
        "coverage": {
          "type": "float",
          "description": "Estimated code coverage percentage"
        },
        "test_count": {
          "type": "integer",
          "description": "Number of test cases generated"
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "0b951c57a7ab4226c2d23f1ccb07e4b9d41e7cfe6326cb3baba813edef4ab03f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299647Z"
    },
    "created_at": "2025-11-16T08:22:02.825113Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "0b951c57a7ab4226c2d23f1ccb07e4b9d41e7cfe6326cb3baba813edef4ab03f",
    "breaking_changes": []
  },
  "pytest_coverage": {
    "tool_id": "pytest_coverage",
    "name": "Pytest with Coverage",
    "tool_type": "executable",
    "description": "Runs pytest with code coverage analysis",
    "tags": [
      "python",
      "testing",
      "coverage",
      "pytest"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pytest_coverage.yaml",
      "command": "pytest",
      "args": [
        "--cov={source_module}",
        "--cov-report=term-missing",
        "-v",
        "{test_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "ccada5c2292390442cc337664f3e2568c7732e0d250aa552b7b87f26c522c3b5",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299660Z"
    },
    "created_at": "2025-11-16T08:22:02.937138Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ccada5c2292390442cc337664f3e2568c7732e0d250aa552b7b87f26c522c3b5",
    "breaking_changes": []
  },
  "pytest_runner": {
    "tool_id": "pytest_runner",
    "name": "Pytest Test Runner",
    "tool_type": "executable",
    "description": "Runs pytest unit tests with coverage reporting",
    "tags": [
      "python",
      "testing",
      "pytest",
      "unit-tests"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pytest_runner.yaml",
      "command": "pytest",
      "args": [
        "-v",
        "--tb=short",
        "{test_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "71a1b01641cd2db207cb15bb1780ecf6f2119bcdbed7b0a7a9383d8db7d31d20",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299672Z"
    },
    "created_at": "2025-11-16T08:22:03.036664Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "71a1b01641cd2db207cb15bb1780ecf6f2119bcdbed7b0a7a9383d8db7d31d20",
    "breaking_changes": []
  },
  "python_syntax_validator": {
    "tool_id": "python_syntax_validator",
    "name": "Python Syntax Validator",
    "tool_type": "executable",
    "description": "Fast syntax check using Python's AST parser - catches syntax errors before expensive LLM tools",
    "tags": [
      "python",
      "syntax",
      "validation",
      "static-analysis",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\python_syntax_validator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/python_syntax_validator.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "526c2d1a47ffd69c25156fc150eeaedb81839cf1b75d6c9ab094dc5fbe4b64ca",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299678Z"
    },
    "created_at": "2025-11-16T08:22:03.146458Z",
    "usage_count": 119,
    "version": "1.0.0",
    "definition_hash": "526c2d1a47ffd69c25156fc150eeaedb81839cf1b75d6c9ab094dc5fbe4b64ca",
    "breaking_changes": []
  },
  "radon_complexity": {
    "tool_id": "radon_complexity",
    "name": "Radon Complexity Analyzer",
    "tool_type": "executable",
    "description": "Analyzes code complexity metrics (cyclomatic complexity, maintainability index)",
    "tags": [
      "python",
      "complexity",
      "metrics",
      "maintainability"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\radon_complexity.yaml",
      "command": "radon",
      "args": [
        "cc",
        "-s",
        "-a",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "ee1352677698b1a1759053f487db62d42ca5d4da5d0a39e572b438107c1f46ac",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299682Z"
    },
    "created_at": "2025-11-16T08:22:03.264641Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ee1352677698b1a1759053f487db62d42ca5d4da5d0a39e572b438107c1f46ac",
    "breaking_changes": []
  },
  "run_static_analysis": {
    "tool_id": "run_static_analysis",
    "name": "Static Analysis Runner",
    "tool_type": "executable",
    "description": "Runs all static validators on generated code and reports results. Can run all validators or specific ones. Supports auto-fix and retry-failed modes.",
    "tags": [
      "python",
      "validation",
      "static-analysis",
      "testing",
      "quality",
      "comprehensive"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\run_static_analysis.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/run_static_analysis.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "6686db2762cc1e7ec701fa659af4e3d7d9b1ace6aa2297268a93fb5bf6fe1996",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299686Z"
    },
    "created_at": "2025-11-16T08:22:03.374997Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6686db2762cc1e7ec701fa659af4e3d7d9b1ace6aa2297268a93fb5bf6fe1996",
    "breaking_changes": []
  },
  "save_to_disk": {
    "tool_id": "save_to_disk",
    "name": "Save to Disk",
    "tool_type": "executable",
    "description": "Saves content to a file in the ./output/ directory. For safety, only saves to ./output/ to prevent accidental overwrites.",
    "tags": [
      "file-io",
      "save",
      "write",
      "disk",
      "output",
      "storage"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\save_to_disk.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json, pathlib; data=json.load(sys.stdin); path=pathlib.Path('output')/data['filename']; path.parent.mkdir(parents=True, exist_ok=True); path.write_text(data['content']); print(json.dumps({'status': 'saved', 'path': str(path)})))"
      ],
      "input_schema": {
        "filename": "str - Name of file to save (will be saved in ./output/)",
        "content": "str - Content to write to file"
      },
      "output_schema": {
        "status": "str - 'saved' if successful",
        "path": "str - Full path where file was saved"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "a76215ecaf7fcafe16f883b2993e4701e14b28e4f8cf9da084abe17a96563647",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299689Z"
    },
    "created_at": "2025-11-16T08:22:03.492256Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "a76215ecaf7fcafe16f883b2993e4701e14b28e4f8cf9da084abe17a96563647",
    "breaking_changes": []
  },
  "stdin_usage_validator": {
    "tool_id": "stdin_usage_validator",
    "name": "Stdin Usage Validator",
    "tool_type": "executable",
    "description": "Validates that node code properly reads from stdin using json.load(sys.stdin)",
    "tags": [
      "python",
      "validation",
      "stdin",
      "input",
      "static-analysis"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\stdin_usage_validator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/stdin_usage_validator.py",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "077cfa75490f7bd96ccd2e18bdda2f188726663aa8c28c40a758026f3dfa5b7f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299693Z"
    },
    "created_at": "2025-11-16T08:22:03.599372Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "077cfa75490f7bd96ccd2e18bdda2f188726663aa8c28c40a758026f3dfa5b7f",
    "breaking_changes": []
  },
  "text_formatter": {
    "tool_id": "text_formatter",
    "name": "Text Formatter",
    "tool_type": "executable",
    "description": "Fast text formatting operations (uppercase, lowercase, title case, reverse, trim, etc.). Direct Python execution - instant results.",
    "tags": [
      "text",
      "formatting",
      "string",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\text_formatter.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); text=data.get('text', ''); ops={'upper': str.upper, 'lower': str.lower, 'title': str.title, 'capitalize': str.capitalize, 'reverse': lambda s: s[::-1], 'trim': str.strip, 'remove_spaces': lambda s: s.replace(' ', '')}; result=ops.get(data.get('operation', 'lower'), ops['lower'])(text); print(json.dumps({'result': result, 'operation': data.get('operation', 'lower'), 'original': text}))"
      ],
      "input_schema": {
        "text": "str - Text to format",
        "operation": "str - Operation: 'upper', 'lower', 'title', 'capitalize', 'reverse', 'trim', 'remove_spaces'"
      },
      "output_schema": {
        "result": "str - Formatted text",
        "operation": "str - Operation performed",
        "original": "str - Original text"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "31c8c8be0a3ad80be3cc77236f0e84b64adad3e6fd27d0c58bff167079175c48",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299699Z"
    },
    "created_at": "2025-11-16T08:22:03.715162Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "31c8c8be0a3ad80be3cc77236f0e84b64adad3e6fd27d0c58bff167079175c48",
    "breaking_changes": []
  },
  "undefined_name_checker": {
    "tool_id": "undefined_name_checker",
    "name": "Undefined Name Checker",
    "tool_type": "executable",
    "description": "Fast check for undefined variables/imports using flake8 (F821 errors)",
    "tags": [
      "python",
      "validation",
      "imports",
      "static-analysis",
      "undefined"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\undefined_name_checker.yaml",
      "command": "flake8",
      "args": [
        "--select=F821,F401,F811,E999",
        "--format=pylint",
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "38ab46268f048a56aa014787eb4de2bba4629f2e92f819fd45cad82b0e6c6582",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299705Z"
    },
    "created_at": "2025-11-16T08:22:03.824315Z",
    "usage_count": 119,
    "version": "1.0.0",
    "definition_hash": "38ab46268f048a56aa014787eb4de2bba4629f2e92f819fd45cad82b0e6c6582",
    "breaking_changes": []
  },
  "unit_converter": {
    "tool_id": "unit_converter",
    "name": "Unit Converter",
    "tool_type": "executable",
    "description": "Fast unit conversions (length, weight, temperature, time). Direct Python execution. Supports common units like meters/feet, kg/lbs, celsius/fahrenheit, etc.",
    "tags": [
      "conversion",
      "units",
      "measurement",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\unit_converter.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); conversions={'m_to_ft': lambda x: x*3.28084, 'ft_to_m': lambda x: x/3.28084, 'kg_to_lbs': lambda x: x*2.20462, 'lbs_to_kg': lambda x: x/2.20462, 'c_to_f': lambda x: x*9/5+32, 'f_to_c': lambda x: (x-32)*5/9, 'km_to_mi': lambda x: x*0.621371, 'mi_to_km': lambda x: x/0.621371}; conv=data.get('conversion', 'm_to_ft'); result=conversions.get(conv, conversions['m_to_ft'])(data.get('value', 0)); print(json.dumps({'result': result, 'conversion': conv, 'original_value': data.get('value', 0)}))"
      ],
      "input_schema": {
        "conversion": "str - Conversion type: 'm_to_ft', 'ft_to_m', 'kg_to_lbs', 'lbs_to_kg', 'c_to_f', 'f_to_c', 'km_to_mi', 'mi_to_km'",
        "value": "number - Value to convert"
      },
      "output_schema": {
        "result": "number - Converted value",
        "conversion": "str - Conversion performed",
        "original_value": "number - Original value"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "64abdd23d662cbb0ec0808593d874eb6e9ffe67de093a1b284a0ec6d2f56abca",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299710Z"
    },
    "created_at": "2025-11-16T08:22:03.931733Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "64abdd23d662cbb0ec0808593d874eb6e9ffe67de093a1b284a0ec6d2f56abca",
    "breaking_changes": []
  },
  "vulture_deadcode": {
    "tool_id": "vulture_deadcode",
    "name": "Vulture Dead Code Finder",
    "tool_type": "executable",
    "description": "Finds unused code (dead code) in Python projects",
    "tags": [
      "python",
      "dead-code",
      "optimization",
      "cleanup"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\vulture_deadcode.yaml",
      "command": "vulture",
      "args": [
        "{source_file}"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "c82c0fd59be59106e88021fec25b8517b3d3a5f633fc6f2c3f2ade03257aa8c4",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299715Z"
    },
    "created_at": "2025-11-16T08:22:04.044869Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "c82c0fd59be59106e88021fec25b8517b3d3a5f633fc6f2c3f2ade03257aa8c4",
    "breaking_changes": []
  },
  "article_analyzer": {
    "tool_id": "article_analyzer",
    "name": "Article Content Analyzer",
    "tool_type": "llm",
    "description": "Analyzes blog posts and articles for clarity, technical accuracy, SEO, and readability. Provides improvement suggestions.",
    "tags": [
      "analysis",
      "blog",
      "seo",
      "readability",
      "content",
      "review"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\article_analyzer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "1eae78a54e6221fa1fd29a447c092008648ba004d01b5e5a6638d73b667b462e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299723Z"
    },
    "created_at": "2025-11-16T08:22:04.152162Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "1eae78a54e6221fa1fd29a447c092008648ba004d01b5e5a6638d73b667b462e",
    "breaking_changes": []
  },
  "code_explainer": {
    "tool_id": "code_explainer",
    "name": "Code Concept Explainer",
    "tool_type": "llm",
    "description": "Explains complex programming concepts in simple terms for blog articles and tutorials. Creates analogies and examples.",
    "tags": [
      "explanation",
      "tutorial",
      "teaching",
      "concepts",
      "examples"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\code_explainer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "a124e21c9030d51f9229a5e7c9301c4d7874c32024071afdf3e6059cedcf6139",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299728Z"
    },
    "created_at": "2025-11-16T08:22:04.259938Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "a124e21c9030d51f9229a5e7c9301c4d7874c32024071afdf3e6059cedcf6139",
    "breaking_changes": []
  },
  "code_optimizer": {
    "tool_id": "code_optimizer",
    "name": "Code Optimizer",
    "tool_type": "llm",
    "description": "Comprehensive code optimization tool with profiling, hierarchical optimization (local → cloud → deep), automatic test updating, and version comparison. Handles the complete optimization lifecycle.",
    "tags": [
      "optimization",
      "performance",
      "refactoring",
      "testing",
      "profiling"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\code_optimizer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are an expert code optimizer. When asked to optimize code, follow this workflow:\n\nPHASE 1: ANALYSIS\n1. Profile current code to establish baseline\n2. Identify bottlenecks (CPU, I/O, memory)\n3. Analyze algorithm complexity\n4. Check for obvious inefficiencies\n\nPHASE 2: OPTIMIZATION HIERARCHY\n\nLevel 1 - LOCAL (Fast, Free, 10-20% improvement):\n- Use local model (qwen2.5-coder:14b)\n- Quick wins: remove redundancy, fix O(n²) loops\n- Improve algorithms (use sets instead of lists for lookups)\n- Add caching for repeated computations\n- Optimize string concatenation\n\nLevel 2 - CLOUD (Expensive, 20-40% improvement):\n- Triggered if local < 15% improvement OR code is critical\n- Use cloud LLM (GPT-4/Claude) with RAG context\n- Advanced optimizations: async/await, multiprocessing\n- Data structure redesign\n- Memory layout optimization\n\nLevel 3 - DEEP (Very Expensive, System-level):\n- Triggered for workflows/systems, not individual functions\n- Analyze entire call graph\n- Identify architectural bottlenecks\n- Suggest tool replacements (faster libraries)\n- Recommend breaking changes if necessary\n\nPHASE 3: TEST UPDATING\n1. Identify existing tests for the code\n2. Update tests to match new implementation\n3. Add performance regression tests\n4. Ensure all tests pass\n\nPHASE 4: VALIDATION\n1. Profile optimized code\n2. Compare before/after metrics\n3. Verify correctness (tests pass)\n4. Calculate improvement %\n\nPHASE 5: DECISION\n- If improvement >= 10%: ACCEPT\n- If improvement < 10%: REJECT (keep original)\n- If tests fail: FIX or ROLLBACK\n\nOUTPUT FORMAT:\n```\n## Optimization Report\n\n### Baseline Performance\n- Duration: X.XXs\n- Bottlenecks: [list]\n\n### Optimization Level: [LOCAL|CLOUD|DEEP]\n- Strategy: [description]\n- Changes: [list of modifications]\n\n### Optimized Code\n```python\n[optimized code]\n```\n\n### Updated Tests\n```python\n[updated test code]\n```\n\n### Performance Comparison\n- Before: X.XXs\n- After: Y.XXs\n- Improvement: Z.Z%\n- Recommendation: [ACCEPT|REJECT]\n\n### Breaking Changes\n- [None or list of breaking changes]\n```\n",
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "40f5e846736907b19689dbc8fb0b75bfa37ef070068e7d5f5b394e159f2b41b0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299732Z"
    },
    "created_at": "2025-11-16T08:22:04.378119Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "40f5e846736907b19689dbc8fb0b75bfa37ef070068e7d5f5b394e159f2b41b0",
    "breaking_changes": []
  },
  "code_reviewer": {
    "tool_id": "code_reviewer",
    "name": "Code Reviewer",
    "tool_type": "llm",
    "description": "Reviews code for quality, best practices, and potential issues. Uses base model for thorough analysis.",
    "tags": [
      "review",
      "quality",
      "code-analysis",
      "best-practices",
      "assessment"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\code_reviewer.yaml",
      "llm_tier": "quality.tier_2",
      "llm_role": "base",
      "system_prompt": "You are an expert code reviewer with deep knowledge of software engineering best practices, design patterns, and common pitfalls.\n",
      "prompt_template": "Review this code:\n\n{code}\n\nProvide:\n1. Quality assessment (1-10 score)\n2. Issues found (bugs, anti-patterns, violations of best practices)\n3. Improvement suggestions (specific, actionable recommendations)\n4. Security concerns (if any)\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "long",
      "version": "1.0.0",
      "definition_hash": "5d32468bae327c008fd87e729f90c5f351500435af2d4d7486f513d366c9776a",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299736Z"
    },
    "created_at": "2025-11-16T08:22:04.495892Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "5d32468bae327c008fd87e729f90c5f351500435af2d4d7486f513d366c9776a",
    "breaking_changes": []
  },
  "code_translation_validator": {
    "tool_id": "code_translation_validator",
    "name": "Code Translation Validator",
    "tool_type": "llm",
    "description": "Fast validator that ensures translation hasn't corrupted Python code blocks. Checks that code syntax remains valid, only comments are translated, and no code keywords were mistranslated. Use AFTER translating documents containing code.",
    "tags": [
      "code",
      "validation",
      "translation",
      "syntax-check",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\code_translation_validator.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a code validator. Check that Python code remains syntactically valid after translation. ONLY comments should be translated, never code itself.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Validate this translated code:\n\n{translated_code}\n\nCheck:\n1. Python syntax is still valid\n2. Only comments were translated (not keywords, variables, functions)\n3. Code structure is unchanged\n4. No code keywords mistranslated (def, class, import, if, for, etc.)\n\nRespond with:\n- 'OK' if code is valid\n- 'ERROR: <list of issues>' if problems found\n\nBe concise (under 100 tokens).",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "short",
      "version": "1.0.1",
      "definition_hash": "b85bb21e8c5c93b53512f24ae4a09b68c606069b06501463fbec4426252a6e69",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299741Z"
    },
    "created_at": "2025-11-17T01:04:53.135606Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "b85bb21e8c5c93b53512f24ae4a09b68c606069b06501463fbec4426252a6e69",
    "breaking_changes": []
  },
  "content_generator": {
    "tool_id": "content_generator",
    "name": "Content Generator",
    "tool_type": "llm",
    "description": "General purpose content generation for creative writing, articles, stories, and text content. Uses base model for quality output.",
    "tags": [
      "content",
      "generation",
      "creative",
      "writing",
      "articles",
      "stories"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\content_generator.yaml",
      "llm_tier": "content.tier_2",
      "llm_role": "base",
      "system_prompt": "You are a creative content generator. Generate engaging, high-quality content that meets the user's requirements.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}\n",
      "prompt_template": "{prompt}\n\nGenerate creative, engaging content. Return ONLY the content itself, without explanations or meta-commentary.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "long",
      "version": "1.0.0",
      "definition_hash": "855d21cd65d566d635b0db03c3ac81f3edc2e197f6d059e9078474aa98ad7dad",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299752Z"
    },
    "created_at": "2025-11-16T08:22:04.712133Z",
    "usage_count": 33,
    "version": "1.0.0",
    "definition_hash": "855d21cd65d566d635b0db03c3ac81f3edc2e197f6d059e9078474aa98ad7dad",
    "breaking_changes": []
  },
  "doc_generator": {
    "tool_id": "doc_generator",
    "name": "Documentation Generator",
    "tool_type": "llm",
    "description": "Generates comprehensive code documentation",
    "tags": [
      "documentation",
      "docs"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\doc_generator.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "ca7c50c4fb145db5370f75af8131125c6a3521257e650d0271ef16fcac401bf8",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299765Z"
    },
    "created_at": "2025-11-16T08:22:04.832969Z",
    "usage_count": 1,
    "version": "1.0.0",
    "definition_hash": "ca7c50c4fb145db5370f75af8131125c6a3521257e650d0271ef16fcac401bf8",
    "breaking_changes": []
  },
  "fast_code_generator": {
    "tool_id": "fast_code_generator",
    "name": "Fast Code Generator",
    "tool_type": "llm",
    "description": "Fast code generation for simple tasks. Best for basic arithmetic, simple functions, straightforward algorithms. NOT suitable for complex logic or multi-step workflows.",
    "tags": [
      "fast",
      "simple",
      "basic",
      "code-generation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\fast_code_generator.yaml",
      "llm_tier": "coding.tier_1",
      "llm_role": "fast",
      "system_prompt": "You are a fast code generator for SIMPLE tasks. Generate clean, working Python code for basic tasks.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}\n",
      "prompt_template": "Generate Python code for this SIMPLE task:\n\n{task}\n\nRequirements:\n- Keep code simple and focused\n- Proper error handling\n- Must work for the specific task\n- Follow Python best practices\n",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "9b56051986fc316c54009f77193b7ca0af9830c586a0d92fc46ec1d9f90e136b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299772Z"
    },
    "created_at": "2025-11-16T08:22:04.951266Z",
    "usage_count": 47,
    "version": "1.0.0",
    "definition_hash": "9b56051986fc316c54009f77193b7ca0af9830c586a0d92fc46ec1d9f90e136b",
    "breaking_changes": []
  },
  "general": {
    "tool_id": "general",
    "name": "General Code Generator",
    "tool_type": "llm",
    "description": "General purpose code generation for any programming task. Used as fallback when no specialized tool matches. Handles complex logic, multi-step workflows, and sophisticated algorithms.",
    "tags": [
      "general",
      "fallback",
      "code-generation",
      "any-task",
      "complex"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\general.yaml",
      "llm_tier": "coding.tier_2",
      "llm_role": "base",
      "system_prompt": "You are an expert software engineer. Write clean, efficient, well-documented code following best practices.\n\nIMPORTANT: For content generation tasks (stories, articles, jokes), write Python code that DIRECTLY creates the content as a string in the main() function. DO NOT use call_tool().\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}\n",
      "prompt_template": "Generate code for the following task:\n\n{task}\n\nWorkflow Context:\n- Priority: {priority} (determines speed vs quality tradeoff)\n- Quality level: {quality_level} (draft/good/production/perfect)\n- Speed: {speed_requirement} (fast/balanced/thorough)\n\nFor content generation tasks:\n- Write a simple main() function that DIRECTLY creates the content\n- DO NOT use call_tool() - that function doesn't exist in the runtime\n- Just create the content as a string variable and output it\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "very-long",
      "version": "1.0.0",
      "definition_hash": "24ca0d9eda3749fe6a97485047cd8f202c5ed68f438c7e9869d7e22f5c07cb8b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299778Z"
    },
    "created_at": "2025-11-16T08:22:05.064105Z",
    "usage_count": 181,
    "version": "1.0.0",
    "definition_hash": "24ca0d9eda3749fe6a97485047cd8f202c5ed68f438c7e9869d7e22f5c07cb8b",
    "breaking_changes": []
  },
  "long_form_writer": {
    "tool_id": "long_form_writer",
    "name": "Long-Form Content Writer",
    "tool_type": "llm",
    "description": "Specialized for writing long-form content (novels, books, long articles) using mistral-nemo's massive 128K context window. Best for creative writing, story generation, and content that requires maintaining continuity over many pages. Use with summarizer for ultra-long content.",
    "tags": [
      "creative-writing",
      "novel",
      "story",
      "long-form",
      "article",
      "book",
      "large-context"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\long_form_writer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a creative writer specializing in long-form content. You have a massive 128K token context window, allowing you to maintain consistency and continuity across very long texts. Write engaging, well-structured content that flows naturally.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "{prompt}\n\nPrevious context (if continuing):\n{context}\n\nGenerate the next section maintaining consistency with previous content.",
      "cost_tier": "high",
      "speed_tier": "slow",
      "quality_tier": "excellent",
      "max_output_length": "very-long",
      "version": "1.0.0",
      "definition_hash": "cb109970522fe7f2edc043f5b0e9c136c8bd99b5fd8e00fb639439d5450d651c",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299784Z"
    },
    "created_at": "2025-11-16T08:22:05.186048Z",
    "usage_count": 1,
    "version": "1.0.0",
    "definition_hash": "cb109970522fe7f2edc043f5b0e9c136c8bd99b5fd8e00fb639439d5450d651c",
    "breaking_changes": []
  },
  "outline_generator": {
    "tool_id": "outline_generator",
    "name": "Article Outline Generator",
    "tool_type": "llm",
    "description": "Creates detailed outlines for technical articles based on topics. Structures content logically.",
    "tags": [
      "outline",
      "structure",
      "planning",
      "article",
      "organization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\outline_generator.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "73959ed68d0ffb82b0ed00224a784cb4d0dd0e285aba71878c34698c745f20fa",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299789Z"
    },
    "created_at": "2025-11-16T08:22:05.299080Z",
    "usage_count": 1,
    "version": "1.0.0",
    "definition_hash": "73959ed68d0ffb82b0ed00224a784cb4d0dd0e285aba71878c34698c745f20fa",
    "breaking_changes": []
  },
  "performance_optimizer": {
    "tool_id": "performance_optimizer",
    "name": "Performance Optimizer",
    "tool_type": "llm",
    "description": "Suggests performance optimizations",
    "tags": [
      "performance",
      "optimization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\performance_optimizer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "bf602aff33797789d55f906ec1f89331183fd8f70228f3571f4091209351372c",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299793Z"
    },
    "created_at": "2025-11-16T08:22:05.415405Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "bf602aff33797789d55f906ec1f89331183fd8f70228f3571f4091209351372c",
    "breaking_changes": []
  },
  "performance_profiler": {
    "tool_id": "performance_profiler",
    "name": "Performance Profiler",
    "tool_type": "llm",
    "description": "Analyzes code performance using PyInstrument profiling and provides detailed performance metrics, bottleneck identification, and optimization recommendations. Use this when asked to profile code, find performance issues, or analyze execution time.",
    "tags": [
      "performance",
      "profiling",
      "optimization",
      "analysis",
      "pyinstrument"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\performance_profiler.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a performance profiling expert. When given code to analyze:\n\n1. EXECUTION: Run the code with PyInstrument profiling enabled\n2. ANALYSIS: Analyze the profiling data to identify:\n   - Total execution time\n   - Hotspots (functions taking most time)\n   - Call stack depth and patterns\n   - I/O vs CPU time breakdown\n   - Memory allocation patterns\n\n3. BOTTLENECK IDENTIFICATION:\n   - List top 5 slowest operations\n   - Identify unnecessary loops or recursion\n   - Spot inefficient algorithms (O(n²) when O(n) possible)\n   - Find blocking I/O operations\n   - Detect redundant computations\n\n4. RECOMMENDATIONS:\n   - Specific optimization suggestions\n   - Alternative algorithms or approaches\n   - Caching opportunities\n   - Parallelization possibilities\n   - Tool version upgrades if applicable\n\n5. OUTPUT FORMAT:\n   ```\n   ## Performance Profile\n\n   **Total Time**: X.XXs\n   **Samples**: N\n\n   ### Top Bottlenecks\n   1. function_name (XX.X%) - X.XXs\n      Location: file.py:line\n      Issue: [description]\n      Fix: [suggestion]\n\n   2. ...\n\n   ### Breakdown\n   - CPU Time: XX%\n   - I/O Time: XX%\n   - Memory: XX MB peak\n\n   ### Optimization Opportunities\n   1. [High Impact] ...\n   2. [Medium Impact] ...\n\n   ### Recommended Actions\n   - [ ] Action 1\n   - [ ] Action 2\n   ```\n\nUse the profiling.py module to actually profile the code.\nReturn actionable insights, not just data.\n",
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "a3abfc80c39dbbb10edb24f0f7fb3c70f9cb7d97f2b0790ad74bc5e34fac071d",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299799Z"
    },
    "created_at": "2025-11-16T08:22:05.533947Z",
    "usage_count": 2,
    "version": "1.0.0",
    "definition_hash": "a3abfc80c39dbbb10edb24f0f7fb3c70f9cb7d97f2b0790ad74bc5e34fac071d",
    "breaking_changes": []
  },
  "proofreader": {
    "tool_id": "proofreader",
    "name": "Technical Proofreader",
    "tool_type": "llm",
    "description": "Proofreads technical content for grammar, style, consistency, and technical accuracy",
    "tags": [
      "proofreading",
      "grammar",
      "style",
      "editing",
      "quality"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\proofreader.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are an expert proofreader specializing in technical content. You have a keen eye for grammar, style, consistency, and technical accuracy. You provide constructive feedback while preserving the author's voice and intent.",
      "prompt_template": "Proofread the following technical content:\n\n{content}\n\nCheck for:\n1. Grammar and spelling errors\n2. Technical accuracy\n3. Consistency in terminology\n4. Clarity and readability\n5. Code example correctness\n\nProvide corrected version and list of changes made.",
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "5b0700a083c7d12366632b4a8c1892ac67ad24adc92c57c7cbdca3e8e043a527",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299803Z"
    },
    "created_at": "2025-11-16T08:22:05.650865Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "5b0700a083c7d12366632b4a8c1892ac67ad24adc92c57c7cbdca3e8e043a527",
    "breaking_changes": []
  },
  "quick_feedback": {
    "tool_id": "quick_feedback",
    "name": "Quick Feedback Checker",
    "tool_type": "llm",
    "description": "Fast proofreading and quick feedback for text. Uses fast model for speed.",
    "tags": [
      "spellcheck",
      "grammar",
      "quick-feedback",
      "proofreading",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\quick_feedback.yaml",
      "llm_tier": "validation.tier_1",
      "llm_role": "fast",
      "system_prompt": "You are a fast proofreader. Check for errors quickly and provide concise feedback.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}\n",
      "prompt_template": "Quick check this text:\n\n{text}\n\nFind spelling, grammar, and syntax issues. Be brief and to the point.\n",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "short",
      "version": "1.0.0",
      "definition_hash": "2692869ce3bd0baf21d737c053ac7c596d0bfaf29a8559abd4850656678fdb14",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299808Z"
    },
    "created_at": "2025-11-16T08:22:05.760519Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "2692869ce3bd0baf21d737c053ac7c596d0bfaf29a8559abd4850656678fdb14",
    "breaking_changes": []
  },
  "quick_translator": {
    "tool_id": "quick_translator",
    "name": "Quick Translator",
    "tool_type": "llm",
    "description": "Direct translation for words and short phrases. Returns immediate results without code generation. For longer translations (paragraphs, documents), use NMT translator or full translation workflow instead.",
    "tags": [
      "translation",
      "quick",
      "words",
      "phrases",
      "llm"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\quick_translator.yaml",
      "llm_tier": "content.tier_2",
      "llm_role": "translator",
      "system_prompt": "You are a translator. Translate text accurately and concisely.\n\nPriority: {priority}\nQuality: {quality_level}\nSpeed: {speed_requirement}\n",
      "prompt_template": "Translate the following from {source_lang} to {target_lang}:\n\n\"{text}\"\n\nProvide ONLY the translation, no explanations or alternatives.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "short",
      "version": "1.0.0",
      "definition_hash": "02034add9dbe7273f045cef95ce70665b96bec3620f013ada661dea869692222",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299812Z"
    },
    "created_at": "2025-11-16T08:22:05.859286Z",
    "usage_count": 3,
    "version": "1.0.0",
    "definition_hash": "02034add9dbe7273f045cef95ce70665b96bec3620f013ada661dea869692222",
    "breaking_changes": []
  },
  "security_auditor": {
    "tool_id": "security_auditor",
    "name": "Security Auditor",
    "tool_type": "llm",
    "description": "Audits code for security vulnerabilities using the most capable model for thorough analysis",
    "tags": [
      "security",
      "audit",
      "vulnerability",
      "powerful-model"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\security_auditor.yaml",
      "llm_tier": "coding.tier_3",
      "llm_role": "powerful",
      "system_prompt": "You are a security expert. Find vulnerabilities and security issues with thorough analysis.\n",
      "prompt_template": "Audit this code for security vulnerabilities:\n\n{code}\n\nCheck for:\n- SQL injection\n- XSS vulnerabilities\n- Command injection\n- Path traversal\n- Authentication/authorization issues\n- Data exposure\n- Cryptography issues\n- Input validation failures\n- OWASP Top 10 vulnerabilities\n\nProvide detailed analysis with severity ratings.\n",
      "cost_tier": "high",
      "speed_tier": "slow",
      "quality_tier": "excellent",
      "max_output_length": "long",
      "version": "1.0.0",
      "definition_hash": "def449ca532cf061505f70335e51d0dead74e9f8daac9f98487efb1f69f7c134",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299816Z"
    },
    "created_at": "2025-11-16T08:22:05.967523Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "def449ca532cf061505f70335e51d0dead74e9f8daac9f98487efb1f69f7c134",
    "breaking_changes": []
  },
  "seo_optimizer": {
    "tool_id": "seo_optimizer",
    "name": "SEO Optimizer",
    "tool_type": "llm",
    "description": "Optimizes technical content for search engines, suggests keywords, meta descriptions, and structure improvements",
    "tags": [
      "seo",
      "keywords",
      "optimization",
      "search",
      "metadata"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\seo_optimizer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "226c4f4d50f287fa9fa06acf1cb82bd833961b3f072324fb59b90e7867f07faa",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299821Z"
    },
    "created_at": "2025-11-16T08:22:06.073599Z",
    "usage_count": 1,
    "version": "1.0.0",
    "definition_hash": "226c4f4d50f287fa9fa06acf1cb82bd833961b3f072324fb59b90e7867f07faa",
    "breaking_changes": []
  },
  "summarizer": {
    "tool_id": "summarizer",
    "name": "Content Summarizer",
    "tool_type": "llm",
    "description": "Summarizes content concisely while capturing all key points. Uses base model for quality.",
    "tags": [
      "summarization",
      "analysis",
      "condensing",
      "key-points"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\summarizer.yaml",
      "llm_tier": "quality.tier_1",
      "llm_role": "base",
      "system_prompt": "You are an expert at creating concise, accurate summaries that capture all essential information.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}\n",
      "prompt_template": "Summarize the following content:\n\n{content}\n\nCapture all key points concisely. Maintain accuracy while being brief.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "8c75f358ef22ec5bfc07f4035ce905033e9a16b34f86b3f0cc6adb756eda1924",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299825Z"
    },
    "created_at": "2025-11-16T08:22:06.179955Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "8c75f358ef22ec5bfc07f4035ce905033e9a16b34f86b3f0cc6adb756eda1924",
    "breaking_changes": []
  },
  "technical_writer": {
    "tool_id": "technical_writer",
    "name": "Technical Article Writer",
    "tool_type": "llm",
    "description": "Writes comprehensive technical articles, tutorials, and blog posts on software development topics",
    "tags": [
      "writing",
      "technical",
      "article",
      "blog",
      "tutorial",
      "documentation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\technical_writer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are an expert technical writer specializing in software development content. You create clear, engaging, and accurate articles that explain complex programming concepts to developers. Your writing is well-structured, includes practical examples, and follows best practices for technical documentation.\n\nWorkflow pressure: {priority}\nQuality target: {quality_level}\nSpeed mode: {speed_requirement}",
      "prompt_template": "Write a technical article on the following topic:\n\n{topic}\n\nWorkflow Context:\n- Priority: {priority} (high=fast draft, low=thorough research)\n- Quality level: {quality_level} (draft/good/publication/perfect)\n- Speed: {speed_requirement} (fast=outline+key points, thorough=full research)\n- Target audience: {audience}\n- Tone: Professional but accessible\n- Length target: {length}\n\nAdjust depth, examples, and polish based on quality_level:\n- draft: Key points, basic examples\n- good: Solid content, working examples\n- publication: Polished, multiple examples, thorough\n- perfect: Comprehensive, exceptional examples, fully researched",
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "f0e539a2ccfe4a18cbb662102fb2716d242e8d45c43d1204acc59d5ebbc93eb0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299829Z"
    },
    "created_at": "2025-11-16T08:22:06.292010Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "f0e539a2ccfe4a18cbb662102fb2716d242e8d45c43d1204acc59d5ebbc93eb0",
    "breaking_changes": []
  },
  "translation_quality_checker": {
    "tool_id": "translation_quality_checker",
    "name": "Translation Quality Validator",
    "tool_type": "llm",
    "description": "Fast quality check for translation output using gemma3_1b. Detects repeated characters, garbled text, encoding errors, and translation failures. MUST be used after nmt_translator to validate output quality.",
    "tags": [
      "translation",
      "validation",
      "quality-check",
      "error-detection",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\translation_quality_checker.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a translation quality validator. Check translated text for common errors. Be fast and concise - your context window is only 2048 tokens.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Validate this translated text for quality issues:\n\nOriginal: {original_text}\nTranslated: {translated_text}\n\nCheck for:\n1. Repeated characters (e.g., 'aaaa', '||||')\n2. Garbled text (random symbols, encoding errors)\n3. Untranslated portions\n4. Missing or corrupted text\n5. Obvious translation failures\n\nRespond with ONLY:\n- 'OK' if translation looks good\n- 'ERROR: <brief description>' if issues found\n\nKeep response under 100 tokens.",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "basic",
      "max_output_length": "short",
      "version": "1.0.1",
      "definition_hash": "7da9d581b2c133f0862929d81fc324e30046e28a234ba4cff20da3457f458d14",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299833Z"
    },
    "created_at": "2025-11-17T01:04:53.796074Z",
    "usage_count": 1,
    "version": "1.0.1",
    "definition_hash": "7da9d581b2c133f0862929d81fc324e30046e28a234ba4cff20da3457f458d14",
    "breaking_changes": []
  },
  "nmt_translator": {
    "tool_id": "nmt_translator",
    "name": "NMT Translation Service",
    "tool_type": "openapi",
    "description": "Neural Machine Translation service for translating text between languages using GET requests. VERY FAST but can be inaccurate - MUST validate output with translation_quality_checker for repeated characters and garbled text. Uses ISO 639 two-letter language codes (e.g., 'en', 'es', 'fr', 'de'). Get supported languages from GET /languages endpoint. API returns 'translations' array. Uses OpenAPI spec from http://localhost:8000/openapi.json.",
    "tags": [
      "translation",
      "nmt",
      "neural",
      "languages",
      "openapi",
      "api"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "openapi\\nmt_translator.yaml",
      "version": "1.0.1",
      "definition_hash": "03abab40b91c5b9a078fe07e557342adf7aa289db5030eaa4560ae04bd81e7af",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299842Z"
    },
    "created_at": "2025-11-16T10:01:30.396360Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "03abab40b91c5b9a078fe07e557342adf7aa289db5030eaa4560ae04bd81e7af",
    "breaking_changes": []
  },
  "tell_a_joke": {
    "tool_id": "tell_a_joke",
    "name": "Python code for generating jokes based on user-provided topics using LLM tools.",
    "tool_type": "workflow",
    "description": "tell a joke",
    "tags": [
      "python",
      "llm",
      "jokes",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299847Z"
    },
    "created_at": "2025-11-16T08:22:06.626335Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "save_input_to_database": {
    "tool_id": "save_input_to_database",
    "name": "Save input to database",
    "tool_type": "workflow",
    "description": "Save input to database",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299850Z"
    },
    "created_at": "2025-11-16T08:22:06.626352Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_code_to_do_one_plus_rand": {
    "tool_id": "write_code_to_do_one_plus_rand",
    "name": "write code to do one plus random number under 50",
    "tool_type": "workflow",
    "description": "write code to do one plus random number under 50",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299854Z"
    },
    "created_at": "2025-11-16T08:22:06.626359Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_10_and_20_1763173231": {
    "tool_id": "add_10_and_20_1763173231",
    "name": "Python function to add two integers with input validation and error handling.",
    "tool_type": "workflow",
    "description": "add 10 and 20",
    "tags": [
      "python",
      "addition",
      "input_validation",
      "error_handling",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299857Z"
    },
    "created_at": "2025-11-16T08:22:06.626365Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "sum_4_and_6": {
    "tool_id": "sum_4_and_6",
    "name": "sum 4 and 6",
    "tool_type": "workflow",
    "description": "sum 4 and 6",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299861Z"
    },
    "created_at": "2025-11-16T08:22:06.626371Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "what_is_1_plus_1": {
    "tool_id": "what_is_1_plus_1",
    "name": "A simple Python function to add two integers.",
    "tool_type": "workflow",
    "description": "what is 1 plus 1",
    "tags": [
      "arithmetic",
      "addition",
      "python",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299864Z"
    },
    "created_at": "2025-11-16T08:22:06.626376Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_5_and_8": {
    "tool_id": "add_5_and_8",
    "name": "Python function to add two numbers with default values of 5 and 8",
    "tool_type": "workflow",
    "description": "add 5 and 8",
    "tags": [
      "python",
      "addition",
      "default-values",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299868Z"
    },
    "created_at": "2025-11-16T08:22:06.626382Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "flake8_linter": {
    "tool_id": "flake8_linter",
    "name": "Flake8 Style Checker",
    "tool_type": "executable",
    "description": "Runs flake8 to check Python code style (PEP 8) and detect common errors",
    "tags": [
      "python",
      "linting",
      "pep8",
      "style",
      "quality"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299871Z"
    },
    "created_at": "2025-11-16T08:22:06.626390Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "multiply_6_and_7_1763228888": {
    "tool_id": "multiply_6_and_7_1763228888",
    "name": "Calculates the product of 6 and 7 and prints the result as JSON.",
    "tool_type": "workflow",
    "description": "multiply 6 and 7",
    "tags": [
      "arithmetic",
      "multiplication",
      "json",
      "basic",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299875Z"
    },
    "created_at": "2025-11-16T08:22:06.626396Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "install_python_package": {
    "tool_id": "install_python_package",
    "name": "Installs Python packages based on JSON input and reports installation status.",
    "tool_type": "workflow",
    "description": "Install Python Package",
    "tags": [
      "python",
      "pip",
      "package_installation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299879Z"
    },
    "created_at": "2025-11-16T08:22:06.626402Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "http_content_fetcher": {
    "tool_id": "http_content_fetcher",
    "name": "HTTP Content Fetcher",
    "tool_type": "api_connector",
    "description": "Comprehensive HTTP client supporting all HTTP methods (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS), all body types (JSON, form-data, multipart, XML, text, binary), various authentication methods (Bearer, API Key, Basic, Digest), and flexible response handling. Designed for seamless integration with DSE workflow system. Can fetch content from any URL and return data in multiple formats.",
    "tags": [
      "http",
      "fetch",
      "content-fetching",
      "web",
      "api",
      "rest",
      "api-connector",
      "http-client",
      "download",
      "upload",
      "json",
      "xml",
      "form-data",
      "authentication",
      "bearer",
      "api-key",
      "workflow-integration"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299883Z"
    },
    "created_at": "2025-11-16T08:22:06.626410Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_100_and_200": {
    "tool_id": "add_100_and_200",
    "name": "Python function to add two numbers with JSON input/output",
    "tool_type": "workflow",
    "description": "add 100 and 200",
    "tags": [
      "python",
      "addition",
      "json",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299886Z"
    },
    "created_at": "2025-11-16T08:22:06.626416Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "model_selector": {
    "tool_id": "model_selector",
    "name": "Model Selector",
    "tool_type": "custom",
    "description": "Intelligently select the best backend and model for a given task. Supports natural language selection like 'use GPT-4' or 'use Claude'. Considers speed, cost, quality, and context window requirements. Available backends: Ollama, OpenAI, Anthropic, Azure, LM Studio.",
    "tags": [
      "selection",
      "optimization",
      "model-management",
      "planning",
      "backend"
    ],
    "parameters": {
      "task_description": {
        "type": "string",
        "description": "Description of the task to perform"
      },
      "constraints": {
        "type": "object",
        "description": "Optional constraints like max_cost, min_speed"
      },
      "backend_preference": {
        "type": "string",
        "description": "Preferred backend (openai, anthropic, azure, etc.)"
      },
      "model_preference": {
        "type": "string",
        "description": "Preferred specific model name"
      },
      "top_k": {
        "type": "number",
        "description": "Number of recommendations to return (default: 3)"
      },
      "query": {
        "type": "string",
        "description": "Conversational query like 'what fast summary models do we have'"
      },
      "filter_by": {
        "type": "object",
        "description": "Optional filters for query_models"
      }
    },
    "metadata": {
      "speed_tier": "very-fast",
      "cost_tier": "free",
      "quality_tier": "excellent",
      "latency_ms": 50,
      "capability": "Model and backend selection with multi-backend support"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:28:19.511951Z"
    },
    "created_at": "2025-11-17T17:28:19.511943Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_technical_article_1763166799": {
    "tool_id": "write_me_a_technical_article_1763166799",
    "name": "write me a technical article",
    "tool_type": "workflow",
    "description": "write me a technical article",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299897Z"
    },
    "created_at": "2025-11-16T08:22:06.626426Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "fast_content_writer": {
    "tool_id": "fast_content_writer",
    "name": "Fast Content Writer",
    "tool_type": "llm",
    "description": "Fast content generation using gemma3:4b. Best for stories, technical articles, essays, documentation, creative writing. Good balance of speed and quality for text generation tasks.",
    "tags": [
      "fast",
      "content",
      "writing",
      "story",
      "article",
      "gemma3"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299901Z"
    },
    "created_at": "2025-11-16T08:22:06.626432Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "tell_me_a_joke": {
    "tool_id": "tell_me_a_joke",
    "name": "Generates a joke based on the input theme or a default joke if no theme is provi",
    "tool_type": "workflow",
    "description": "tell me a joke",
    "tags": [
      "joke generation",
      "NLP",
      "ML",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299904Z"
    },
    "created_at": "2025-11-16T08:22:06.626438Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke_and_translate_to_1763216276": {
    "tool_id": "write_a_joke_and_translate_to_1763216276",
    "name": "Python code for generating a joke in French based on an English input.",
    "tool_type": "workflow",
    "description": "write a joke and translate to french",
    "tags": [
      "python",
      "code generation",
      "joke",
      "translation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299908Z"
    },
    "created_at": "2025-11-16T08:22:06.626443Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem": {
    "tool_id": "write_a_poem",
    "name": "write a poem",
    "tool_type": "workflow",
    "description": "write a poem",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_poem",
      "quality_score": 1.1,
      "latency_ms": 49914,
      "memory_mb_peak": 1.93,
      "created_at": "2025-11-16T13:40:48.563411+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write a poem",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299915Z"
    },
    "created_at": "2025-11-16T13:40:48.563426Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_code_to_do_a_fibonacc": {
    "tool_id": "write_me_code_to_do_a_fibonacc",
    "name": "Python implementation to generate Fibonacci sequence",
    "tool_type": "workflow",
    "description": "write me code to do a fibonacci sequanece",
    "tags": [
      "fibonacci",
      "sequence",
      "python",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299919Z"
    },
    "created_at": "2025-11-16T08:22:06.626456Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke_1763181926": {
    "tool_id": "write_a_joke_1763181926",
    "name": "Generates a joke based on user input (topic and optional setup)",
    "tool_type": "workflow",
    "description": "write a joke",
    "tags": [
      "joke",
      "generation",
      "nlp",
      "content_creation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299922Z"
    },
    "created_at": "2025-11-16T08:22:06.626471Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_technical_article_on_n": {
    "tool_id": "write_a_technical_article_on_n",
    "name": "write a technical article on nodules",
    "tool_type": "workflow",
    "description": "write a technical article on nodules",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299929Z"
    },
    "created_at": "2025-11-16T08:22:06.626478Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_poem_to_french": {
    "tool_id": "translate_the_poem_to_french",
    "name": "Translates an English poem to French while preserving meaning and tone.",
    "tool_type": "workflow",
    "description": "Translate the poem to French",
    "tags": [
      "translation",
      "poem",
      "French",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299933Z"
    },
    "created_at": "2025-11-16T08:22:06.626485Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "exit_1763253889": {
    "tool_id": "exit_1763253889",
    "name": "Python code that prints the string 'exit' when a specific input is provided.",
    "tool_type": "workflow",
    "description": "exit",
    "tags": [
      "python",
      "paradigms",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299936Z"
    },
    "created_at": "2025-11-16T08:22:06.626493Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pylint_checker": {
    "tool_id": "pylint_checker",
    "name": "Pylint Code Quality Checker",
    "tool_type": "executable",
    "description": "Runs pylint static analysis on Python code to check for errors, code style, and potential bugs",
    "tags": [
      "python",
      "static-analysis",
      "quality",
      "linting",
      "pep8"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299940Z"
    },
    "created_at": "2025-11-16T08:22:06.626499Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_5_plus_10": {
    "tool_id": "calculate_5_plus_10",
    "name": "Python implementation to calculate the sum of 5 and 10",
    "tool_type": "workflow",
    "description": "calculate 5 plus 10",
    "tags": [
      "arithmetic",
      "calculation",
      "sum",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299944Z"
    },
    "created_at": "2025-11-16T08:22:06.626508Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_1_5": {
    "tool_id": "add_1_5",
    "name": "Adds two integers or generates a joke about cats",
    "tool_type": "workflow",
    "description": "add 1 + 5",
    "tags": [
      "addition",
      "arithmetic",
      "joke",
      "content_generation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299947Z"
    },
    "created_at": "2025-11-16T08:22:06.626513Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_15_plus_25": {
    "tool_id": "calculate_15_plus_25",
    "name": "calculate 15 plus 25",
    "tool_type": "workflow",
    "description": "calculate 15 plus 25",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299950Z"
    },
    "created_at": "2025-11-16T08:22:06.626520Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_a_fibonaccie_sequenc": {
    "tool_id": "calculate_a_fibonaccie_sequenc",
    "name": "Calculate a Fibonacci sequence up to a specified length.",
    "tool_type": "workflow",
    "description": "calculate a fibonaccie sequence and output the result.",
    "tags": [
      "fibonacci",
      "sequence",
      "python",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299954Z"
    },
    "created_at": "2025-11-16T08:22:06.626524Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem_1763241023": {
    "tool_id": "write_a_poem_1763241023",
    "name": "Write a poem",
    "tool_type": "workflow",
    "description": "Write a poem",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299957Z"
    },
    "created_at": "2025-11-16T08:22:06.626530Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_5_and_3_1763184838": {
    "tool_id": "add_5_and_3_1763184838",
    "name": "add 5 and 3",
    "tool_type": "workflow",
    "description": "add 5 and 3",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299961Z"
    },
    "created_at": "2025-11-16T08:22:06.626536Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_joke": {
    "tool_id": "write_me_a_joke",
    "name": "Generates a joke based on user input topic and tone.",
    "tool_type": "workflow",
    "description": "write me a joke",
    "tags": [
      "joke_generation",
      "natural_language_processing",
      "machine_learning",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299964Z"
    },
    "created_at": "2025-11-16T08:22:06.626541Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_poem_1763255171": {
    "tool_id": "write_me_a_poem_1763255171",
    "name": "Python code that generates a poem based on user input using natural language processing and machine learning techniques.",
    "tool_type": "workflow",
    "description": "write me a poem",
    "tags": [
      "python",
      "nlp",
      "machine-learning",
      "poetry",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299967Z"
    },
    "created_at": "2025-11-16T08:22:06.626546Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "tell_me_a_joke_about_programmi": {
    "tool_id": "tell_me_a_joke_about_programmi",
    "name": "Python code to generate a joke about programming using the content generation LLM tool.",
    "tool_type": "workflow",
    "description": "tell me a joke about programming",
    "tags": [
      "python",
      "llm",
      "content generation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299971Z"
    },
    "created_at": "2025-11-16T08:22:06.626552Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "wtie_mea_joke_about_the_welsh": {
    "tool_id": "wtie_mea_joke_about_the_welsh",
    "name": "wtie mea joke about the welsh and make up a random number.",
    "tool_type": "workflow",
    "description": "wtie mea joke about the welsh and make up a random number.",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299976Z"
    },
    "created_at": "2025-11-16T08:22:06.626558Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_the_fibonacci_sequen": {
    "tool_id": "calculate_the_fibonacci_sequen",
    "name": "Efficient Fibonacci sequence generator",
    "tool_type": "workflow",
    "description": "calculate the fibonacci sequence.",
    "tags": [
      "fibonacci",
      "dynamic programming",
      "iterative",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299980Z"
    },
    "created_at": "2025-11-16T08:22:06.626564Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_the_most_optimal_code_to": {
    "tool_id": "write_the_most_optimal_code_to",
    "name": "Generates and prints the Fibonacci sequence in reverse order starting from 50.",
    "tool_type": "workflow",
    "description": "write the most optimal code to output the fibonacci sequence backwards from 50",
    "tags": [
      "fibonacci",
      "reverse",
      "sequence",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.299984Z"
    },
    "created_at": "2025-11-16T08:22:06.626568Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem_1763277263": {
    "tool_id": "write_a_poem_1763277263",
    "name": "Python code that generates a joke based on user input using natural language processing and machine learning techniques.",
    "tool_type": "workflow",
    "description": "write a poem",
    "tags": [
      "python",
      "natural language processing",
      "machine learning",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300003Z"
    },
    "created_at": "2025-11-16T08:22:06.626577Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_5_plus_5": {
    "tool_id": "calculate_5_plus_5",
    "name": "Calculates 5 + 5 and prints the result as JSON.",
    "tool_type": "workflow",
    "description": "calculate 5 plus 5",
    "tags": [
      "arithmetic",
      "addition",
      "json",
      "simple",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300007Z"
    },
    "created_at": "2025-11-16T08:22:06.626582Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_then_translate_a_poen": {
    "tool_id": "write_then_translate_a_poen",
    "name": "Python code that generates a piece of content using the provided workflow composition and tools.",
    "tool_type": "workflow",
    "description": "write then translate a poen",
    "tags": [
      "python",
      "content generation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300011Z"
    },
    "created_at": "2025-11-16T08:22:06.626589Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_joke_1763182563": {
    "tool_id": "write_me_a_joke_1763182563",
    "name": "Generates a joke based on user input.",
    "tool_type": "workflow",
    "description": "write me a joke",
    "tags": [
      "joke",
      "generation",
      "nlp",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300015Z"
    },
    "created_at": "2025-11-16T08:22:06.626597Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "accept_input_from_user": {
    "tool_id": "accept_input_from_user",
    "name": "Accept input from user",
    "tool_type": "workflow",
    "description": "Accept input from user",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300019Z"
    },
    "created_at": "2025-11-16T08:22:06.626602Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_7_and_9": {
    "tool_id": "add_7_and_9",
    "name": "Calculates the sum of two integers.",
    "tool_type": "workflow",
    "description": "add 7 and 9",
    "tags": [
      "addition",
      "arithmetic",
      "integer",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300022Z"
    },
    "created_at": "2025-11-16T08:22:06.626606Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_haiku_about_coding": {
    "tool_id": "write_a_haiku_about_coding",
    "name": "write a haiku about coding",
    "tool_type": "workflow",
    "description": "write a haiku about coding",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_haiku_about_coding",
      "quality_score": 1.1,
      "latency_ms": 854,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T17:58:30.737629+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write a haiku about coding",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300027Z"
    },
    "created_at": "2025-11-16T17:58:30.737649Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_work_boob_to_f": {
    "tool_id": "translate_the_work_boob_to_f",
    "name": "Translate the input word 'boob' from English to French.",
    "tool_type": "workflow",
    "description": "translate the work 'boob' to french",
    "tags": [
      "python",
      "machine learning",
      "natural language processing",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300031Z"
    },
    "created_at": "2025-11-16T08:22:06.626617Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem_and_translate_it": {
    "tool_id": "write_a_poem_and_translate_it",
    "name": "write a  poem and translate it to french and german",
    "tool_type": "workflow",
    "description": "write a  poem and translate it to french and german",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_poem_and_translate_it",
      "quality_score": 1.1,
      "latency_ms": 45553,
      "memory_mb_peak": 1.93,
      "created_at": "2025-11-16T10:08:59.498311+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write a  poem and translate it to french and german",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300035Z"
    },
    "created_at": "2025-11-16T10:08:59.498332Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke": {
    "tool_id": "write_a_joke",
    "name": "Generates a short, humorous joke based on predefined topics and a random number.",
    "tool_type": "workflow",
    "description": "write a joke",
    "tags": [
      "joke generation",
      "randomization",
      "topic selection",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300042Z"
    },
    "created_at": "2025-11-16T08:22:06.626628Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "get_english_word": {
    "tool_id": "get_english_word",
    "name": "Python code that generates a single English word from an input string, given the user's request \"get english word\".",
    "tool_type": "workflow",
    "description": "get english word",
    "tags": [
      "python",
      "code generation",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300046Z"
    },
    "created_at": "2025-11-16T08:22:06.626633Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_technical_story_and_tr": {
    "tool_id": "write_a_technical_story_and_tr",
    "name": "write a technical story and translate it into french",
    "tool_type": "workflow",
    "description": "write a technical story and translate it into french",
    "tags": [
      "generated",
      "chat",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300050Z"
    },
    "created_at": "2025-11-16T08:22:06.626638Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "review_this_code_usr_bin_en": {
    "tool_id": "review_this_code_usr_bin_en",
    "name": "Python script to review and validate shebang lines for Python interpreters.",
    "tool_type": "workflow",
    "description": "Review this code #!/usr/bin/env python3",
    "tags": [
      "shebang",
      "validation",
      "python",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300054Z"
    },
    "created_at": "2025-11-16T08:22:06.626643Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_poem": {
    "tool_id": "write_me_a_poem",
    "name": "Python code that generates a poem based on user input using LLM tools.",
    "tool_type": "workflow",
    "description": "write me a poem",
    "tags": [
      "python",
      "nlp",
      "machine learning",
      "poetry",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300057Z"
    },
    "created_at": "2025-11-16T08:22:06.626648Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculat_1_1": {
    "tool_id": "calculat_1_1",
    "name": "Calculates 1+1",
    "tool_type": "workflow",
    "description": "CALCULAT 1+1",
    "tags": [
      "arithmetic",
      "addition",
      "calculator",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300060Z"
    },
    "created_at": "2025-11-16T08:22:06.626654Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "multiply_6_by_7": {
    "tool_id": "multiply_6_by_7",
    "name": "Multiply 6 by 7",
    "tool_type": "workflow",
    "description": "multiply 6 by 7",
    "tags": [
      "arithmetic",
      "multiplication",
      "basic",
      "auto-generated"
    ],
    "parameters": {},
    "metadata": {
      "from_rag": true,
      "quality_score": 0.0,
      "usage_count": 0
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300064Z"
    },
    "created_at": "2025-11-16T08:22:06.626659Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_technical_story": {
    "tool_id": "write_a_technical_story",
    "name": "Write a technical story",
    "tool_type": "workflow",
    "description": "Write a technical story",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_technical_story",
      "quality_score": 1.1,
      "latency_ms": 849,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T08:34:44.135374+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a technical story",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300067Z"
    },
    "created_at": "2025-11-16T08:34:44.135406Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_story_into_frenc": {
    "tool_id": "translate_the_story_into_frenc",
    "name": "Translate the story into French",
    "tool_type": "workflow",
    "description": "Translate the story into French",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_story_into_frenc",
      "quality_score": 1.1,
      "latency_ms": 785,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T08:35:30.164164+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the story into French",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300071Z"
    },
    "created_at": "2025-11-16T08:35:30.164181Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_story_into_germa": {
    "tool_id": "translate_the_story_into_germa",
    "name": "Translate the story into German",
    "tool_type": "workflow",
    "description": "Translate the story into German",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_story_into_germa",
      "quality_score": 1.1,
      "latency_ms": 806,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T08:36:09.937792+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the story into German",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300074Z"
    },
    "created_at": "2025-11-16T08:36:09.937813Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_a_work_breakdown_struct": {
    "tool_id": "create_a_work_breakdown_struct",
    "name": "Create a work breakdown structure (WBS)",
    "tool_type": "workflow",
    "description": "Create a work breakdown structure (WBS)",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_a_work_breakdown_struct",
      "quality_score": 1.1,
      "latency_ms": 763,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T09:14:20.219623+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create a work breakdown structure (WBS)",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300078Z"
    },
    "created_at": "2025-11-16T09:14:20.219639Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "develop_a_project_schedule_and": {
    "tool_id": "develop_a_project_schedule_and",
    "name": "Develop a project schedule and timeline",
    "tool_type": "workflow",
    "description": "Develop a project schedule and timeline",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "develop_a_project_schedule_and",
      "quality_score": 1.1,
      "latency_ms": 810,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T09:17:21.481798+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Develop a project schedule and timeline",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300082Z"
    },
    "created_at": "2025-11-16T09:17:21.481820Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "workflow_datastore": {
    "tool_id": "workflow_datastore",
    "name": "Workflow Datastore",
    "tool_type": "executable",
    "description": "Save and retrieve workflow data persistently. Allows workflows to store project schedules, task lists, and other structured data.",
    "tags": [
      "workflow",
      "datastore",
      "persistence",
      "storage",
      "state"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\workflow_datastore.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/workflow_datastore.py",
        "{action}",
        "{key}",
        "{data}"
      ],
      "input_schema": {
        "action": {
          "type": "string",
          "description": "Action to perform: 'save' or 'load'",
          "required": true
        },
        "key": {
          "type": "string",
          "description": "Unique key to store/retrieve data (e.g., 'project_schedule_001')",
          "required": true
        },
        "data": {
          "type": "any",
          "description": "Data to save (for 'save' action only)",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "description": "For 'load': returns stored data. For 'save': returns confirmation."
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "27bdf63bba3cd8e19054304b7bc4db250fc55e555399b2858f02af2cead2df84",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300086Z"
    },
    "created_at": "2025-11-16T09:07:23.454598Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "27bdf63bba3cd8e19054304b7bc4db250fc55e555399b2858f02af2cead2df84",
    "breaking_changes": []
  },
  "define_project_scope_and_goals": {
    "tool_id": "define_project_scope_and_goals",
    "name": "Define project scope and goals",
    "tool_type": "workflow",
    "description": "Define project scope and goals",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "define_project_scope_and_goals",
      "quality_score": 1.1,
      "latency_ms": 921,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T09:12:45.347983+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Define project scope and goals",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300090Z"
    },
    "created_at": "2025-11-16T09:12:45.348005Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_word_boobies_f": {
    "tool_id": "translate_the_word_boobies_f",
    "name": "Translate the word 'boobies' from English to French",
    "tool_type": "workflow",
    "description": "Translate the word 'boobies' from English to French",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_word_boobies_f",
      "quality_score": 1.1,
      "latency_ms": 759,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T09:18:41.770674+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the word 'boobies' from English to French",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300094Z"
    },
    "created_at": "2025-11-16T09:18:41.770690Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "input_long_text": {
    "tool_id": "input_long_text",
    "name": "Input Long Text",
    "tool_type": "workflow",
    "description": "Input Long Text",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "input_long_text",
      "quality_score": 1.1,
      "latency_ms": 881,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T09:25:57.866530+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Input Long Text",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300097Z"
    },
    "created_at": "2025-11-16T09:25:57.866554Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "prepare_input_for_nmt_service": {
    "tool_id": "prepare_input_for_nmt_service",
    "name": "Prepare Input for NMT Service",
    "tool_type": "workflow",
    "description": "Prepare Input for NMT Service",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "prepare_input_for_nmt_service",
      "quality_score": 1.1,
      "latency_ms": 32322,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T09:28:27.164876+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Prepare Input for NMT Service",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300101Z"
    },
    "created_at": "2025-11-16T09:28:27.164898Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_and_output_sentence": {
    "tool_id": "translate_and_output_sentence",
    "name": "Translate and Output Sentence",
    "tool_type": "workflow",
    "description": "Translate and Output Sentence",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_and_output_sentence",
      "quality_score": 1.1,
      "latency_ms": 26129,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T09:29:38.153419+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate and Output Sentence",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300104Z"
    },
    "created_at": "2025-11-16T09:29:38.153439Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "take_in_long_text": {
    "tool_id": "take_in_long_text",
    "name": "Take in long text",
    "tool_type": "workflow",
    "description": "Take in long text",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "take_in_long_text",
      "quality_score": 1.1,
      "latency_ms": 25146,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T09:35:06.567173+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Take in long text",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300109Z"
    },
    "created_at": "2025-11-16T09:35:06.567192Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "nmt_translate": {
    "tool_id": "nmt_translate",
    "name": "NMT Translator",
    "tool_type": "executable",
    "description": "Fast neural machine translation using the NMT service at localhost:8000. Supports many languages. Use format: 'Translate to <language>: <text>' or 'Translate from <src> to <tgt>: <text>'",
    "tags": [
      "translation",
      "nmt",
      "neural",
      "languages",
      "fast",
      "api"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\nmt_translate.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/nmt_translate.py",
        "{prompt}"
      ],
      "input_schema": {
        "prompt": {
          "type": "string",
          "description": "Translation request in natural language. Examples: 'Translate to German: Hello', 'Translate from English to French: Hello, world!'",
          "required": true
        }
      },
      "output_schema": {
        "type": "string",
        "description": "Translated text (plain string) or JSON error object if translation fails"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "3f1eca6cb79d0b7c0586d7354f41de03159e24b7ae0fb8d8dbb255ac7c5f198a",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300112Z"
    },
    "created_at": "2025-11-16T10:01:29.141239Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "3f1eca6cb79d0b7c0586d7354f41de03159e24b7ae0fb8d8dbb255ac7c5f198a",
    "breaking_changes": []
  },
  "random_data_generator": {
    "tool_id": "random_data_generator",
    "name": "Random Test Data Generator",
    "tool_type": "executable",
    "description": "Generates random test data for workflows based on schemas or natural language descriptions. Context-aware for common fields like email, name, age, translation text, etc. Use this when you need test data to validate workflows.",
    "tags": [
      "testing",
      "data",
      "random",
      "generator",
      "workflow",
      "validation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\random_data_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/random_data_generator.py",
        "{prompt}"
      ],
      "input_schema": {
        "prompt": {
          "type": "string",
          "description": "JSON schema or natural language description of the data needed. Examples: '{\"name\": \"string\", \"age\": \"number\"}' or 'Generate test data for translation with text and target language'",
          "required": true
        }
      },
      "output_schema": {
        "type": "object",
        "description": "JSON object containing randomly generated test data matching the requested schema"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "dfcbc9c80c85c4904cb96457ae817f66ad904165a51b3883ad36933a348a29a8",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300116Z"
    },
    "created_at": "2025-11-16T10:01:30.181536Z",
    "usage_count": 25,
    "version": "1.0.0",
    "definition_hash": "dfcbc9c80c85c4904cb96457ae817f66ad904165a51b3883ad36933a348a29a8",
    "breaking_changes": []
  },
  "task_daily_team_meetin": {
    "tool_id": "task_daily_team_meetin",
    "name": "{\n  \"task\": \"Daily Team Meeting\",\n  \"steps\": [\n    {\n      \"stepId\": 1,\n      \"description\": \"Send meeting invite to all team members\"\n    },\n    {\n      \"stepId\": 2,\n      \"description\": \"Prepare and distribute meeting agenda\"\n    },\n    {\n      \"stepId\": 3,\n      \"description\": \"Take minutes during the meeting\"\n    },\n    {\n      \"stepId\": 4,\n      \"description\": \"Send meeting minutes to all team members after the meeting\"\n    }\n  ]\n}",
    "tool_type": "workflow",
    "description": "{\n  \"task\": \"Daily Team Meeting\",\n  \"steps\": [\n    {\n      \"stepId\": 1,\n      \"description\": \"Send meeting invite to all team members\"\n    },\n    {\n      \"stepId\": 2,\n      \"description\": \"Prepare and distribute meeting agenda\"\n    },\n    {\n      \"stepId\": 3,\n      \"description\": \"Take minutes during the meeting\"\n    },\n    {\n      \"stepId\": 4,\n      \"description\": \"Send meeting minutes to all team members after the meeting\"\n    }\n  ]\n}",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "task_daily_team_meetin",
      "quality_score": 1.1,
      "latency_ms": 751,
      "memory_mb_peak": 1.93,
      "created_at": "2025-11-16T10:06:10.391796+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "{\n  \"task\": \"Daily Team Meeting\",\n  \"steps\": [\n    {\n      \"stepId\": 1,\n      \"description\": \"Send meeting invite to all team members\"\n    },\n    {\n      \"stepId\": 2,\n      \"description\": \"Prepare and distribute meeting agenda\"\n    },\n    {\n      \"stepId\": 3,\n      \"description\": \"Take minutes during the meeting\"\n    },\n    {\n      \"stepId\": 4,\n      \"description\": \"Send meeting minutes to all team members after the meeting\"\n    }\n  ]\n}",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300119Z"
    },
    "created_at": "2025-11-16T10:06:10.391814Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_longer_article": {
    "tool_id": "write_a_longer_article",
    "name": "Write a longer article",
    "tool_type": "workflow",
    "description": "Write a longer article",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_longer_article",
      "quality_score": 1.1,
      "latency_ms": 59877,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T10:12:47.223218+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a longer article",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300123Z"
    },
    "created_at": "2025-11-16T10:12:47.223241Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_article_into_fre": {
    "tool_id": "translate_the_article_into_fre",
    "name": "Translate the article into French",
    "tool_type": "workflow",
    "description": "Translate the article into French",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_article_into_fre",
      "quality_score": 1.1,
      "latency_ms": 29327,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T10:14:13.615338+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the article into French",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300126Z"
    },
    "created_at": "2025-11-16T10:14:13.615361Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_article_into_ger": {
    "tool_id": "translate_the_article_into_ger",
    "name": "Translate the article into German",
    "tool_type": "workflow",
    "description": "Translate the article into German",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_article_into_ger",
      "quality_score": 1.1,
      "latency_ms": 765,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T10:15:06.069875+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the article into German",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300130Z"
    },
    "created_at": "2025-11-16T10:15:06.069892Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_some_plausible_sample": {
    "tool_id": "write_me_some_plausible_sample",
    "name": "write me some plausible sample data. It should be in the form of dtails about a person with multiple levels like deails on the persomnm, the address and town, Make it detailed and realisting. (10 items)",
    "tool_type": "workflow",
    "description": "write me some plausible sample data. It should be in the form of dtails about a person with multiple levels like deails on the persomnm, the address and town, Make it detailed and realisting. (10 items)",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_some_plausible_sample",
      "quality_score": 1.1,
      "latency_ms": 738,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T10:42:33.746168+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write me some plausible sample data. It should be in the form of dtails about a person with multiple levels like deails on the persomnm, the address and town, Make it detailed and realisting. (10 items)",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300133Z"
    },
    "created_at": "2025-11-16T10:42:33.746191Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "outputs_andy_patterns": {
    "tool_id": "outputs_andy_patterns",
    "name": "outputs andy patterns.",
    "tool_type": "workflow",
    "description": "outputs andy patterns.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "outputs_andy_patterns",
      "quality_score": 1.2000000000000002,
      "latency_ms": 44,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T11:10:19.359098+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "outputs andy patterns.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300136Z"
    },
    "created_at": "2025-11-16T11:10:19.359123Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "connect_to_signalr_api_at": {
    "tool_id": "connect_to_signalr_api_at",
    "name": "Connect to SignalR API at < > with HUC context <>",
    "tool_type": "workflow",
    "description": "Connect to SignalR API at < > with HUC context <>",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "connect_to_signalr_api_at",
      "quality_score": 1.1,
      "latency_ms": 783,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T11:31:40.692896+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Connect to SignalR API at < > with HUC context <>",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300140Z"
    },
    "created_at": "2025-11-16T11:31:40.692912Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "process_the_josn_contents_into": {
    "tool_id": "process_the_josn_contents_into",
    "name": "process the josn contents into creating a new workflow",
    "tool_type": "workflow",
    "description": "process the josn contents into creating a new workflow",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "process_the_josn_contents_into",
      "quality_score": 1.1,
      "latency_ms": 859,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T11:32:50.990772+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "process the josn contents into creating a new workflow",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300143Z"
    },
    "created_at": "2025-11-16T11:32:50.990789Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "route_this_to_the_most_powerfu": {
    "tool_id": "route_this_to_the_most_powerfu",
    "name": "route this to the most powerful model you have 'what is the meaning of idiocy\"",
    "tool_type": "workflow",
    "description": "route this to the most powerful model you have 'what is the meaning of idiocy\"",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "route_this_to_the_most_powerfu",
      "quality_score": 1.1,
      "latency_ms": 868,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T11:46:37.640755+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "route this to the most powerful model you have 'what is the meaning of idiocy\"",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300148Z"
    },
    "created_at": "2025-11-16T11:46:37.640775Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "connect_to_http_127": {
    "tool_id": "connect_to_http_127",
    "name": "connect to http://127.0.0.1:5116/api/mock/products process the json data and extract the information. then send it to a small llm and describe the data",
    "tool_type": "workflow",
    "description": "connect to http://127.0.0.1:5116/api/mock/products process the json data and extract the information. then send it to a small llm and describe the data",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "connect_to_http_127",
      "quality_score": 1.1,
      "latency_ms": 1280,
      "memory_mb_peak": 1.94,
      "created_at": "2025-11-16T12:20:27.162417+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "connect to http://127.0.0.1:5116/api/mock/products process the json data and extract the information. then send it to a small llm and describe the data",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300152Z"
    },
    "created_at": "2025-11-16T12:20:27.162450Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "buffer": {
    "tool_id": "buffer",
    "name": "Buffer",
    "tool_type": "executable",
    "description": "Buffers data to smooth fast traffic. Batches items and flushes based on size, time, or manual trigger. Perfect for smoothing rapid usage tracking updates to Qdrant or rate-limiting API calls.",
    "tags": [
      "buffer",
      "batching",
      "rate-limiting",
      "smoothing",
      "traffic-control"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\buffer.yaml",
      "command": "python",
      "args": [
        "tools/executable/buffer.py"
      ],
      "input_schema": {
        "operation": {
          "type": "string",
          "description": "Operation: 'write', 'flush', 'status', 'clear'",
          "enum": [
            "write",
            "flush",
            "status",
            "clear"
          ],
          "default": "write",
          "required": true
        },
        "data": {
          "type": "any",
          "description": "Data to write to buffer (for 'write' operation)",
          "required": false
        },
        "buffer_id": {
          "type": "string",
          "description": "Buffer identifier (default: 'default'). Use different IDs for different buffers.",
          "default": "default",
          "required": false
        },
        "max_size": {
          "type": "integer",
          "description": "Max items before auto-flush (default: 100)",
          "default": 100,
          "required": false
        },
        "flush_interval_seconds": {
          "type": "number",
          "description": "Max seconds before auto-flush (default: 5.0)",
          "default": 5.0,
          "required": false
        },
        "flush_strategy": {
          "type": "string",
          "description": "Strategy: 'batched' (wait for size/time), 'immediate' (pass-through), 'manual' (only flush on command)",
          "enum": [
            "batched",
            "immediate",
            "manual"
          ],
          "default": "batched",
          "required": false
        },
        "pass_through_tool": {
          "type": "string",
          "description": "Tool to call when flushing (e.g., 'qdrant_batch_writer')",
          "required": false
        },
        "pass_through_input": {
          "type": "object",
          "description": "Additional input to pass to pass_through_tool",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "description": "Buffer operation result",
        "properties": {
          "operation": {
            "type": "string",
            "description": "Operation performed"
          },
          "buffer_id": {
            "type": "string",
            "description": "Buffer identifier"
          },
          "buffered_count": {
            "type": "integer",
            "description": "Current items in buffer"
          },
          "flushed": {
            "type": "boolean",
            "description": "Whether buffer was flushed"
          },
          "flushed_count": {
            "type": "integer",
            "description": "Number of items flushed (if flushed)"
          },
          "pass_through_result": {
            "type": "any",
            "description": "Result from pass_through_tool (if called)"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "4e36eae8fd350d856249d3d00f2254eede5f9f6d6d068a12ec4489d6b32063a7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300157Z"
    },
    "created_at": "2025-11-16T12:41:08.799526Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "4e36eae8fd350d856249d3d00f2254eede5f9f6d6d068a12ec4489d6b32063a7",
    "breaking_changes": []
  },
  "connect_signalr": {
    "tool_id": "connect_signalr",
    "name": "Connect SignalR (Natural Language)",
    "tool_type": "executable",
    "description": "Simple natural language interface to connect to SignalR hubs. Just say what you want in plain English and it will parse your request, connect to the hub, and automatically create workflows from streaming tasks. Sequential processing - one task at a time.",
    "tags": [
      "signalr",
      "natural-language",
      "streaming",
      "realtime",
      "workflow-generation",
      "training",
      "easy"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\connect_signalr.yaml",
      "command": "python",
      "args": [
        "tools/executable/connect_signalr.py"
      ],
      "input_schema": {
        "request": {
          "type": "string",
          "description": "Natural language request describing the SignalR connection",
          "required": true,
          "examples": [
            "connect to http://localhost:5000/taskhub and create workflows",
            "connect to this signalr api at http://prod:8080/llmhub with hub context LLMTasks and each time a workflow finishes processing feed the json contents into creating a new workflow",
            "listen to http://localhost:5000/hub for 60 seconds and save tasks to tasks.json"
          ]
        }
      },
      "output_schema": {
        "type": "object",
        "description": "Result of SignalR connection and workflow generation",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether connection was successful"
          },
          "hub_url": {
            "type": "string",
            "description": "URL that was connected to"
          },
          "total_messages": {
            "type": "integer",
            "description": "Number of messages received"
          },
          "tasks_received": {
            "type": "integer",
            "description": "Number of tasks processed"
          },
          "tasks": {
            "type": "array",
            "description": "All received tasks"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "realtime",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "3bf44ab0f7e5c27abe93da47b050ca7614507d073e3581e14a2ff2cabde268ac",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300160Z"
    },
    "created_at": "2025-11-16T12:41:08.807420Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "3bf44ab0f7e5c27abe93da47b050ca7614507d073e3581e14a2ff2cabde268ac",
    "breaking_changes": []
  },
  "document_workflow": {
    "tool_id": "document_workflow",
    "name": "Document Workflow",
    "tool_type": "executable",
    "description": "Generates comprehensive 'How to Use' documentation for a workflow and saves it to README.txt in the workflow directory. Analyzes the code, detects inputs/outputs, identifies tool calls, and creates detailed documentation with examples, flowcharts, and usage instructions.",
    "tags": [
      "documentation",
      "workflow",
      "readme",
      "generator",
      "automation",
      "metadata"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\document_workflow.yaml",
      "command": "python",
      "args": [
        "tools/executable/document_workflow.py"
      ],
      "input_schema": {
        "workflow_path": {
          "type": "string",
          "description": "Absolute or relative path to the workflow's main.py file",
          "required": true,
          "example": "nodes/my_workflow/main.py"
        },
        "workflow_name": {
          "type": "string",
          "description": "Optional: Name of the workflow. If not provided, will be derived from directory name.",
          "required": false,
          "example": "Email Validator"
        },
        "description": {
          "type": "string",
          "description": "Optional: High-level description of what the workflow does. If not provided, will be extracted from code docstring.",
          "required": false,
          "example": "Validates email addresses and checks domain matching"
        }
      },
      "output_schema": {
        "type": "object",
        "description": "Result of documentation generation",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether documentation was generated successfully"
          },
          "workflow_name": {
            "type": "string",
            "description": "Name of the documented workflow"
          },
          "documentation_path": {
            "type": "string",
            "description": "Path to the generated README.txt file"
          },
          "documentation_length": {
            "type": "integer",
            "description": "Length of generated documentation in characters"
          },
          "preview": {
            "type": "string",
            "description": "Preview of the first 500 characters of documentation"
          },
          "error": {
            "type": "string",
            "description": "Error message if generation failed (only present on failure)"
          }
        }
      },
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "6da7ffa64247a50ba9fadcddee063b7153b357c0939d6f9454e3f0404029680c",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300164Z"
    },
    "created_at": "2025-11-16T12:41:08.810729Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6da7ffa64247a50ba9fadcddee063b7153b357c0939d6f9454e3f0404029680c",
    "breaking_changes": []
  },
  "internal_test_validator": {
    "tool_id": "internal_test_validator",
    "name": "Internal Test Validator",
    "tool_type": "executable",
    "description": "Internal tool for validating test outputs. Usage tracking disabled since this is internal tooling.",
    "tags": [
      "internal",
      "testing",
      "validation",
      "no-tracking"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\internal_test_validator.yaml",
      "command": "python",
      "args": [
        "tools/executable/internal_test_validator.py"
      ],
      "input_schema": {
        "test_output": {
          "type": "string",
          "description": "Test output to validate",
          "required": true
        },
        "expected_pattern": {
          "type": "string",
          "description": "Regex pattern expected in output",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "valid": {
            "type": "boolean"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "ab0e48815717f1a1a415019ad802f8e83f4910dbea3d3f17c3e9d8e65b60d95d",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300167Z"
    },
    "created_at": "2025-11-16T12:41:08.812165Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ab0e48815717f1a1a415019ad802f8e83f4910dbea3d3f17c3e9d8e65b60d95d",
    "breaking_changes": []
  },
  "signalr_hub_connector": {
    "tool_id": "signalr_hub_connector",
    "name": "SignalR Hub Connector",
    "tool_type": "executable",
    "description": "Connects to a SignalR hub to receive streaming task data. Automatically routes received tasks to the workflow generator for training. Supports real-time task processing and automatic workflow creation from hub messages.",
    "tags": [
      "signalr",
      "streaming",
      "realtime",
      "integration",
      "hub",
      "websocket",
      "training"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\signalr_hub_connector.yaml",
      "command": "python",
      "args": [
        "tools/executable/signalr_hub_connector.py"
      ],
      "input_schema": {
        "hub_url": {
          "type": "string",
          "description": "Full URL to the SignalR hub endpoint",
          "required": true,
          "example": "http://localhost:5000/taskhub"
        },
        "hub_name": {
          "type": "string",
          "description": "Name of the hub method to subscribe to",
          "required": false,
          "default": "TaskHub",
          "example": "TaskHub"
        },
        "duration_seconds": {
          "type": "number",
          "description": "How long to listen for messages (in seconds). If not provided, runs until manually stopped.",
          "required": false,
          "example": 60
        },
        "auto_generate_workflows": {
          "type": "boolean",
          "description": "Whether to automatically generate workflows from received tasks",
          "required": false,
          "default": true
        },
        "output_file": {
          "type": "string",
          "description": "Optional file path to save received tasks as JSON",
          "required": false,
          "example": "received_tasks.json"
        }
      },
      "output_schema": {
        "type": "object",
        "description": "Summary of SignalR connection and received tasks",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether connection was successful"
          },
          "hub_url": {
            "type": "string",
            "description": "URL that was connected to"
          },
          "hub_name": {
            "type": "string",
            "description": "Hub method name"
          },
          "total_messages": {
            "type": "integer",
            "description": "Total number of messages received"
          },
          "tasks_received": {
            "type": "integer",
            "description": "Number of tasks received"
          },
          "errors": {
            "type": "array",
            "description": "Any errors that occurred during connection"
          },
          "tasks": {
            "type": "array",
            "description": "Array of all received task objects"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "realtime",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "4e17b0fca378b52e5c860b6ad560d074a5ad3e3aca65dc0f05e59c2705eec331",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300171Z"
    },
    "created_at": "2025-11-16T12:41:08.831401Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "4e17b0fca378b52e5c860b6ad560d074a5ad3e3aca65dc0f05e59c2705eec331",
    "breaking_changes": []
  },
  "signalr_llmapi_skill": {
    "tool_id": "signalr_llmapi_skill",
    "name": "SignalR LLMApi Skill",
    "tool_type": "executable",
    "description": "Complete skill for interacting with LLMApi SignalR simulator. Manages contexts, controls streaming, and executes SSE streams. This orchestrates calls to signalr_llmapi_management (planning) and sse_stream (streaming).",
    "tags": [
      "signalr",
      "llmapi",
      "stream",
      "skill",
      "orchestrator",
      "executable"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\signalr_llmapi_skill.yaml",
      "command": "python",
      "args": [
        "tools/executable/signalr_llmapi_skill.py"
      ],
      "input_schema": {
        "request": {
          "type": "string",
          "description": "Natural language request (e.g., 'create test-ctx and stream data', 'list contexts', 'stop streaming from test-ctx')",
          "required": true
        },
        "base_url": {
          "type": "string",
          "description": "Base URL of the LLMApi server (default: http://127.0.0.1:5116)",
          "default": "http://127.0.0.1:5116",
          "required": false
        },
        "consumer": {
          "type": "string",
          "description": "Consumer tool for stream data (if streaming). Default: None (just output stream)",
          "required": false
        },
        "max_stream_items": {
          "type": "integer",
          "description": "Maximum stream items to process (0 = unlimited). Default: 0",
          "default": 0,
          "required": false
        },
        "stream_timeout_seconds": {
          "type": "integer",
          "description": "Maximum streaming duration (0 = unlimited). Default: 0",
          "default": 0,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "description": "Results of SignalR LLMApi operations",
        "properties": {
          "operations_executed": {
            "type": "array",
            "description": "List of operations that were executed"
          },
          "http_results": {
            "type": "array",
            "description": "Results from HTTP operations (create, start, stop, etc.)"
          },
          "stream_summary": {
            "type": "object",
            "description": "Summary of streaming (if streaming was performed)"
          },
          "success": {
            "type": "boolean"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "5cd2082d30b1a99ccac67f41d7b2f29be6e38f332c247ceb70494e700a08a7e1",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300175Z"
    },
    "created_at": "2025-11-16T12:41:08.834283Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "5cd2082d30b1a99ccac67f41d7b2f29be6e38f332c247ceb70494e700a08a7e1",
    "breaking_changes": []
  },
  "signalr_websocket_stream": {
    "tool_id": "signalr_websocket_stream",
    "name": "SignalR WebSocket Stream",
    "tool_type": "custom",
    "description": "Connects to a SignalR hub via WebSocket and streams data continuously. Subscribes to a specific hub context/method and yields each message received.",
    "tags": [
      "signalr",
      "websocket",
      "stream",
      "real-time",
      "producer"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\signalr_websocket_stream.yaml",
      "version": "1.0.0",
      "definition_hash": "d191961c03ae2cbef19ad344c7ca12a9577d490159b0dd584b16867a8da97dcc",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300179Z"
    },
    "created_at": "2025-11-16T12:41:08.836868Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "d191961c03ae2cbef19ad344c7ca12a9577d490159b0dd584b16867a8da97dcc",
    "breaking_changes": []
  },
  "sse_stream": {
    "tool_id": "sse_stream",
    "name": "SSE Stream Producer",
    "tool_type": "custom",
    "description": "Connects to a Server-Sent Events (SSE) endpoint and streams data continuously. Simpler and more reliable than WebSocket for one-way streaming.",
    "tags": [
      "sse",
      "server-sent-events",
      "stream",
      "real-time",
      "producer",
      "http"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\sse_stream.yaml",
      "version": "1.0.0",
      "definition_hash": "ee40d38e66d6009f5e841e217fe9d4a78b4bd4fbc894478d9523b59be95ee0df",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300182Z"
    },
    "created_at": "2025-11-16T12:41:08.839875Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ee40d38e66d6009f5e841e217fe9d4a78b4bd4fbc894478d9523b59be95ee0df",
    "breaking_changes": []
  },
  "stream_processor": {
    "tool_id": "stream_processor",
    "name": "Stream Processor",
    "tool_type": "custom",
    "description": "Generic stream processor that connects a stream producer to a consumer tool. Handles filtering, transformation, and routing of stream events.",
    "tags": [
      "stream",
      "processor",
      "consumer",
      "filter",
      "transform",
      "orchestrator"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\stream_processor.yaml",
      "version": "1.0.0",
      "definition_hash": "6bfd08209fd80f81ab3c51ff94b8c4e99adb2d78359a630c4180546d70fe586c",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300186Z"
    },
    "created_at": "2025-11-16T12:41:08.844259Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6bfd08209fd80f81ab3c51ff94b8c4e99adb2d78359a630c4180546d70fe586c",
    "breaking_changes": []
  },
  "signalr_connection_parser": {
    "tool_id": "signalr_connection_parser",
    "name": "SignalR Connection Parser",
    "tool_type": "llm",
    "description": "Parses natural language requests to connect to SignalR hubs and converts them into proper connection configuration. Extracts hub URL, context/method name, and workflow generation settings from conversational input.",
    "tags": [
      "signalr",
      "parser",
      "nlp",
      "configuration",
      "natural-language"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\signalr_connection_parser.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a SignalR configuration parser.\n\nYour task is to extract SignalR connection details from natural language requests.\n\nExtract:\n- Hub URL (full URL to SignalR endpoint)\n- Hub name/context/method (what to subscribe to)\n- Duration (if specified)\n- Auto-generation settings\n\nIMPORTANT: Output ONLY valid JSON, no markdown, no explanations.\n",
      "prompt_template": "Parse this natural language request into SignalR connection configuration:\n\n**User Request:**\n\"{request}\"\n\n**Extract the following:**\n- `hub_url`: Full URL to SignalR hub (e.g., \"http://localhost:5000/taskhub\")\n- `hub_name`: Hub method/context name (default: \"TaskHub\")\n- `duration_seconds`: How long to listen (null = forever)\n- `auto_generate_workflows`: Whether to auto-generate workflows (default: true if mentioned \"create workflow\" or \"process\")\n- `output_file`: Optional file to save tasks\n\n**Output ONLY this JSON format:**\n```json\n{{\n  \"hub_url\": \"extracted URL\",\n  \"hub_name\": \"extracted hub name or TaskHub\",\n  \"duration_seconds\": null or number,\n  \"auto_generate_workflows\": true or false,\n  \"output_file\": \"filename.json\" or null\n}}\n```\n\n**Examples:**\n\nRequest: \"connect to signalr api at http://localhost:5000/taskhub with hub context TaskHub\"\nOutput:\n```json\n{{\n  \"hub_url\": \"http://localhost:5000/taskhub\",\n  \"hub_name\": \"TaskHub\",\n  \"duration_seconds\": null,\n  \"auto_generate_workflows\": false,\n  \"output_file\": null\n}}\n```\n\nRequest: \"connect to this signalr api at http://prod:8080/llmhub with hub context LLMTasks and each time a workflow finishes processing feed the json contents into creating a new workflow\"\nOutput:\n```json\n{{\n  \"hub_url\": \"http://prod:8080/llmhub\",\n  \"hub_name\": \"LLMTasks\",\n  \"duration_seconds\": null,\n  \"auto_generate_workflows\": true,\n  \"output_file\": null\n}}\n```\n\nRequest: \"listen to http://localhost:5000/hub for 60 seconds and save tasks to tasks.json\"\nOutput:\n```json\n{{\n  \"hub_url\": \"http://localhost:5000/hub\",\n  \"hub_name\": \"TaskHub\",\n  \"duration_seconds\": 60,\n  \"auto_generate_workflows\": false,\n  \"output_file\": \"tasks.json\"\n}}\n```\n\nNow parse: \"{request}\"\n\nOutput ONLY the JSON, no explanations, no markdown.\n",
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.1",
      "definition_hash": "840c5e96757b810cbe80efaf888cdd02e9b10dfa54b36ae08387c0c673dec014",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300191Z"
    },
    "created_at": "2025-11-17T01:04:53.469789Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "840c5e96757b810cbe80efaf888cdd02e9b10dfa54b36ae08387c0c673dec014",
    "breaking_changes": []
  },
  "signalr_llmapi_management": {
    "tool_id": "signalr_llmapi_management",
    "name": "SignalR LLMApi Skill",
    "tool_type": "llm",
    "description": "Complete skill for interacting with LLMApi SignalR simulator. Supports context management (create, list, delete), stream control (start/stop), and SSE streaming of API data.",
    "tags": [
      "signalr",
      "llmapi",
      "stream",
      "admin",
      "skill",
      "management"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\signalr_llmapi_management.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a SignalR LLMApi controller. You help users interact with the LLMApi SignalR simulator.\n\n**Available Operations:**\n1. **List Contexts**: GET /api/mock/contexts\n2. **Get Context Details**: GET /api/mock/contexts/{contextName}\n3. **Create Context**: POST /api/mock/contexts (body: {\"name\": \"context-name\"})\n4. **Delete Context**: DELETE /api/mock/contexts/{contextName}\n5. **Start Streaming**: POST /api/mock/contexts/{contextName}/start\n6. **Stop Streaming**: POST /api/mock/contexts/{contextName}/stop\n7. **Stream Data**: Connect to SSE at /api/mock/contexts (once started)\n\n**Your Task:**\n- Parse the user's natural language request\n- Determine which operation(s) to perform\n- Generate the appropriate API calls\n- If streaming is requested, generate SSE stream configuration\n\n**Output Format:**\nReturn JSON with:\n```json\n{\n  \"operations\": [\n    {\n      \"type\": \"http\" | \"sse_stream\",\n      \"method\": \"GET|POST|DELETE\",\n      \"url\": \"full URL\",\n      \"body\": { optional request body },\n      \"description\": \"What this operation does\"\n    }\n  ],\n  \"execution_plan\": \"Human-readable plan\",\n  \"streaming\": true|false\n}\n```\n",
      "prompt_template": "User request: \"{request}\"\n\n**Context Information:**\n- Base URL: http://127.0.0.1:5116\n- SignalR endpoint: /api/mock/contexts\n- Management endpoints: /api/mock/contexts/{contextName}/start, /stop\n\n**Common Patterns:**\n\n1. **\"List all contexts\"**:\n   ```json\n   {\n     \"operations\": [{\n       \"type\": \"http\",\n       \"method\": \"GET\",\n       \"url\": \"http://127.0.0.1:5116/api/mock/contexts\",\n       \"description\": \"List all active API contexts\"\n     }],\n     \"execution_plan\": \"Fetch list of all contexts\",\n     \"streaming\": false\n   }\n   ```\n\n2. **\"Create context named test-context\"**:\n   ```json\n   {\n     \"operations\": [{\n       \"type\": \"http\",\n       \"method\": \"POST\",\n       \"url\": \"http://127.0.0.1:5116/api/mock/contexts\",\n       \"body\": {\"name\": \"test-context\"},\n       \"description\": \"Create new context test-context\"\n     }],\n     \"execution_plan\": \"Create context test-context\",\n     \"streaming\": false\n   }\n   ```\n\n3. **\"Stream data from test-context\"**:\n   ```json\n   {\n     \"operations\": [\n       {\n         \"type\": \"http\",\n         \"method\": \"POST\",\n         \"url\": \"http://127.0.0.1:5116/api/mock/contexts/test-context/start\",\n         \"description\": \"Start streaming for test-context\"\n       },\n       {\n         \"type\": \"sse_stream\",\n         \"url\": \"http://127.0.0.1:5116/api/mock/contexts\",\n         \"description\": \"Connect to SSE stream\"\n       }\n     ],\n     \"execution_plan\": \"Start test-context streaming, then connect to SSE\",\n     \"streaming\": true\n   }\n   ```\n\n4. **\"Stop streaming test-context\"**:\n   ```json\n   {\n     \"operations\": [{\n       \"type\": \"http\",\n       \"method\": \"POST\",\n       \"url\": \"http://127.0.0.1:5116/api/mock/contexts/test-context/stop\",\n       \"description\": \"Stop streaming for test-context\"\n     }],\n     \"execution_plan\": \"Stop test-context streaming\",\n     \"streaming\": false\n   }\n   ```\n\nNow analyze the user request and generate the appropriate operations.\n\nOutput ONLY the JSON, no markdown, no explanations.\n",
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "19896af27c35fda7037633a7380cb3a4e2e37cbaa242abd2d88482b0aa92344b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300194Z"
    },
    "created_at": "2025-11-16T12:41:08.875026Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "19896af27c35fda7037633a7380cb3a4e2e37cbaa242abd2d88482b0aa92344b",
    "breaking_changes": []
  },
  "task_to_workflow_router": {
    "tool_id": "task_to_workflow_router",
    "name": "Task to Workflow Router",
    "tool_type": "llm",
    "description": "Analyzes streaming task data from SignalR hub and automatically generates appropriate workflow code. Routes tasks to correct workflow patterns based on task type (summarize, generate, translate). Creates executable Python workflows for training the system.",
    "tags": [
      "workflow",
      "generator",
      "routing",
      "task",
      "automation",
      "training",
      "llm"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\task_to_workflow_router.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a workflow code generator for the Code Evolver system.\n\nYour task is to analyze incoming task specifications and generate complete,\nexecutable Python workflow code that accomplishes the task.\n\nIMPORTANT RULES:\n- Generate COMPLETE, WORKING Python code\n- Always include proper imports\n- Use node_runtime.call_tool() to invoke LLM tools\n- Read input from stdin as JSON\n- Output results as JSON to stdout\n- Include error handling\n- Add a main() function and if __name__ == \"__main__\"\n- Use appropriate tools based on task type:\n  * summarize → call_tool(\"summarizer\", ...)\n  * generate → call_tool(\"content_generator\", ...)\n  * translate → call_tool(\"quick_translator\", ...) or call_tool(\"nmt_translator\", ...)\n- Do NOT add sys.path.insert() for node_runtime (it's handled by the runtime)\n",
      "prompt_template": "Generate a complete Python workflow for this task:\n\n**Task Data:**\n```json\n{task_json}\n```\n\n**Task Analysis:**\n- Task Type: {task_type}\n- Task Name: {task_name}\n- Priority: {priority}\n- Languages: {languages}\n\n**Generate workflow code that:**\n\n1. Reads input from stdin (JSON with task data)\n2. Calls appropriate tool(s) based on task type:\n   - `summarize` → Use `summarizer` tool\n   - `generate` → Use `content_generator` tool\n   - `translate` → Use `quick_translator` or `nmt_translator` tool\n3. Handles translation languages if provided\n4. Outputs result as JSON to stdout\n5. Includes error handling\n\n**Code Template:**\n```python\nimport json\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent.parent))\nfrom node_runtime import call_tool\n\n\ndef main():\n    # Read input\n    input_data = json.load(sys.stdin)\n\n    # Extract task parameters\n    # [YOUR CODE HERE]\n\n    # Call appropriate tool\n    # [YOUR CODE HERE]\n\n    # Output result\n    print(json.dumps({{\"result\": result, \"task_id\": task_id}}))\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**Output ONLY valid JSON:**\n```json\n{{\n  \"workflow_code\": \"import json\\\\nimport sys\\\\n...\",\n  \"workflow_name\": \"descriptive_workflow_name\",\n  \"suggested_node_id\": \"task_type_brief_description\",\n  \"tools_used\": [\"tool1\", \"tool2\"],\n  \"estimated_complexity\": \"simple|moderate|complex\"\n}}\n```\n\nIMPORTANT: Output ONLY the JSON, no markdown, no explanations.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "af0731fa53b9fa5bb515263873324c31c58f048824afca79610d9b4b8d1def1a",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300198Z"
    },
    "created_at": "2025-11-16T12:41:08.881445Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "af0731fa53b9fa5bb515263873324c31c58f048824afca79610d9b4b8d1def1a",
    "breaking_changes": []
  },
  "workflow_documenter": {
    "tool_id": "workflow_documenter",
    "name": "Workflow Documenter",
    "tool_type": "llm",
    "description": "Generates comprehensive 'How to Use' documentation for workflows by analyzing code, inputs, outputs, and purpose. Creates user-friendly guides for front-end generation and API consumption.",
    "tags": [
      "documentation",
      "workflow",
      "api",
      "guide",
      "tutorial",
      "how-to",
      "frontend"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\workflow_documenter.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are a technical documentation expert specializing in workflow and API documentation.\n\nYour task is to create clear, comprehensive \"How to Use\" documentation for workflows that will:\n1. Be displayed in auto-generated front-ends\n2. Help users understand what the workflow does\n3. Show exactly what inputs are required\n4. Explain what outputs to expect\n5. Provide usage examples\n\nIMPORTANT RULES:\n- Write for non-technical users when possible\n- Be specific about input requirements (types, formats, required vs optional)\n- Include example inputs and expected outputs\n- Mention any limitations or edge cases\n- Keep it concise but complete (max ~3000 words)\n- Use markdown formatting\n- Include code examples where helpful\n- Focus on practical usage over theoretical details\n",
      "prompt_template": "Generate concise \"How to Use\" documentation for this workflow (max 3000 words):\n\n**Workflow Name:** {workflow_name}\n**Description:** {description}\n**Source Code:**\n```python\n{code}\n```\n**Context:** {context}\n\nCreate documentation with these sections (be concise):\n\n## Overview\n[1-2 sentences: what it does and who it's for]\n\n## What It Does\n[2-3 paragraphs: purpose, value, and key features]\n\n## Required Inputs\n[Table format with Field, Type, Required, Description, Example]\n\n## Expected Outputs\n[Table format with Field, Type, Description, Example]\n[Include 1 sample JSON output]\n\n## How to Use\n\n### Quick Start (30 seconds)\n[3-5 bullet points for immediate usage]\n\n### Via API\n```bash\ncurl -X POST http://api.example.com/workflow \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{{\"field1\": \"value\", \"field2\": 123}}'\n```\n\n### Via Python\n```python\nimport json, subprocess\nresult = subprocess.run([\"python\", \"workflow.py\"],\n                      input=json.dumps({{\"field1\": \"value\"}}),\n                      capture_output=True, text=True)\noutput = json.loads(result.stdout)\n```\n\n## Examples\n\n### Example 1: Basic Usage\n**Input:** [JSON]\n**Output:** [JSON]\n**Explanation:** [1-2 sentences]\n\n### Example 2: Advanced (if applicable)\n**Input:** [JSON]\n**Output:** [JSON]\n**Explanation:** [1-2 sentences]\n\n## Process Flow (Mermaid)\n```mermaid\nflowchart TD\n    A[Input] --> B[Process]\n    B --> C[Output]\n```\n[Keep diagram simple - max 5-7 nodes]\n\n## Limitations\n- [List 3-5 key limitations/constraints]\n- [Include performance, input size, accuracy notes]\n\n## Error Handling\n[Table: Error | Cause | Solution]\n[List 3-5 common errors]\n\n## Technical Details\n- **Language**: Python 3.x\n- **Dependencies**: [List if any]\n- **Tools Used**: [From context]\n- **Speed**: [From context]\n\n## FAQ\n[2-3 most common questions with brief answers]\n\nIMPORTANT: Keep total output under 3000 words. Focus on practical usage.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "8151e5d1f02a71d585bf6b1bae91d0dff797500324436a59ec2cde160fb6afa6",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300202Z"
    },
    "created_at": "2025-11-16T12:41:08.887411Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "8151e5d1f02a71d585bf6b1bae91d0dff797500324436a59ec2cde160fb6afa6",
    "breaking_changes": []
  },
  "count_backwares_from_50_in_ben": {
    "tool_id": "count_backwares_from_50_in_ben",
    "name": "count backwares from 50 in bengali",
    "tool_type": "workflow",
    "description": "count backwares from 50 in bengali",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "count_backwares_from_50_in_ben",
      "quality_score": 1.1,
      "latency_ms": 924,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T13:44:17.864342+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "count backwares from 50 in bengali",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300205Z"
    },
    "created_at": "2025-11-16T13:44:17.864365Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "extract_spec_from_file": {
    "tool_id": "extract_spec_from_file",
    "name": "Extract Spec From File",
    "tool_type": "executable",
    "description": "Extracts specifications from text files for overseer planning. Handles large files by summarizing and sectioning.",
    "tags": [
      "spec",
      "file",
      "extraction",
      "overseer",
      "planning"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\extract_spec_from_file.yaml",
      "command": "python",
      "args": [
        "tools/executable/extract_spec_from_file.py"
      ],
      "input_schema": {
        "file_path": {
          "type": "string",
          "description": "Path to specification file (txt, md, etc.)",
          "required": true
        },
        "summarize": {
          "type": "boolean",
          "description": "Create overseer-friendly summary for large files",
          "default": true,
          "required": false
        },
        "max_length": {
          "type": "integer",
          "description": "Maximum length for overseer summary (characters)",
          "default": 10000,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "file_path": {
            "type": "string"
          },
          "file_size": {
            "type": "integer",
            "description": "Size in characters"
          },
          "word_count": {
            "type": "integer"
          },
          "overseer_spec": {
            "type": "string",
            "description": "Summarized spec for overseer (if summarize=true)"
          },
          "full_spec": {
            "type": "string",
            "description": "Full specification text"
          },
          "sections": {
            "type": "object",
            "description": "Extracted sections (requirements, constraints, etc.)"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "2f1c1dc8f61c27c03e4768c9580dbf5dfa7c0422bad31db601f6afa002978f1e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300209Z"
    },
    "created_at": "2025-11-16T14:05:46.456088Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "2f1c1dc8f61c27c03e4768c9580dbf5dfa7c0422bad31db601f6afa002978f1e",
    "breaking_changes": []
  },
  "mark_tool_failure": {
    "tool_id": "mark_tool_failure",
    "name": "Mark Tool Failure",
    "tool_type": "executable",
    "description": "Records tool failures for specific scenarios, enabling demotion in search rankings and tag refinement. Helps the system learn which tools work where.",
    "tags": [
      "failure-tracking",
      "tool-quality",
      "demotion",
      "learning",
      "internal"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\mark_tool_failure.yaml",
      "command": "python",
      "args": [
        "tools/executable/mark_tool_failure.py"
      ],
      "input_schema": {
        "tool_id": {
          "type": "string",
          "description": "ID of the tool that failed",
          "required": true
        },
        "scenario": {
          "type": "string",
          "description": "Description of what was attempted (used for similarity matching in future searches)",
          "required": true
        },
        "error_message": {
          "type": "string",
          "description": "The error message that occurred",
          "required": false,
          "default": "Unknown error"
        },
        "severity": {
          "type": "string",
          "description": "Failure severity: low (minor issue), medium (significant), high (completely broken)",
          "enum": [
            "low",
            "medium",
            "high"
          ],
          "default": "medium",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "failure_id": {
            "type": "string",
            "description": "ID of the failure record"
          },
          "tool_id": {
            "type": "string"
          },
          "scenario": {
            "type": "string"
          },
          "severity": {
            "type": "string"
          },
          "demotion_applied": {
            "type": "boolean",
            "description": "Whether quality score was reduced"
          },
          "new_quality_score": {
            "type": "number",
            "description": "Updated quality score after demotion"
          },
          "tag_refinement": {
            "type": "array",
            "description": "Negative tags added to narrow tool use"
          },
          "total_failures": {
            "type": "integer",
            "description": "Total number of failures for this tool"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "48b8531efb15da48ac64ff6abada97a8ef3db6b69a197295d60633df5f0cfc6e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300212Z"
    },
    "created_at": "2025-11-16T14:05:47.598951Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "48b8531efb15da48ac64ff6abada97a8ef3db6b69a197295d60633df5f0cfc6e",
    "breaking_changes": []
  },
  "resilient_tool_call": {
    "tool_id": "resilient_tool_call",
    "name": "Resilient Tool Call",
    "tool_type": "executable",
    "description": "Self-recovering tool execution. Automatically tries alternative tools when one fails, marking failures and learning from them. Fulfills the prompt at all costs.",
    "tags": [
      "resilience",
      "fallback",
      "auto-recovery",
      "tool-selection",
      "internal"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\resilient_tool_call.yaml",
      "command": "python",
      "args": [
        "tools/executable/resilient_tool_call.py"
      ],
      "input_schema": {
        "scenario": {
          "type": "string",
          "description": "Description of what needs to be done (used to find best tool)",
          "required": true
        },
        "input": {
          "type": "object",
          "description": "Input data to pass to the selected tool",
          "required": false,
          "default": {}
        },
        "tags": {
          "type": "array",
          "description": "Optional tag filters for tool selection (e.g., ['translation', 'api'])",
          "required": false,
          "default": []
        },
        "max_attempts": {
          "type": "integer",
          "description": "Maximum number of tools to try before giving up",
          "default": 5,
          "required": false
        },
        "mark_failures": {
          "type": "boolean",
          "description": "Whether to mark failed tools (enables learning)",
          "default": true,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether any tool succeeded"
          },
          "result": {
            "type": "any",
            "description": "Output from successful tool"
          },
          "tool_id": {
            "type": "string",
            "description": "ID of the tool that succeeded"
          },
          "attempts": {
            "type": "array",
            "description": "List of all attempts made"
          },
          "failed_tools": {
            "type": "array",
            "description": "List of tools that failed"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "cc2c2782b2d7fa68d95c28c4863a7609c43cefa6ab652181108d7fa99955307e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300216Z"
    },
    "created_at": "2025-11-16T14:05:47.896875Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "cc2c2782b2d7fa68d95c28c4863a7609c43cefa6ab652181108d7fa99955307e",
    "breaking_changes": []
  },
  "translate_the_data": {
    "tool_id": "translate_the_data",
    "name": "translate the data",
    "tool_type": "workflow",
    "description": "translate the data",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_data",
      "quality_score": 1.1,
      "latency_ms": 62143,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T14:09:32.745455+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "translate the data",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300220Z"
    },
    "created_at": "2025-11-16T14:09:32.745489Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "evolve_tool": {
    "tool_id": "evolve_tool",
    "name": "Evolve Tool",
    "tool_type": "executable",
    "description": "Evolves a failing tool by regenerating it with fixes and mutations. Creates a promoted version for the current workflow.",
    "tags": [
      "evolution",
      "tool-mutation",
      "code-generation",
      "self-improvement"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\evolve_tool.yaml",
      "command": "python",
      "args": [
        "tools/executable/evolve_tool.py"
      ],
      "input_schema": {
        "tool_id": {
          "type": "string",
          "description": "ID of the tool to evolve",
          "required": true
        },
        "error_message": {
          "type": "string",
          "description": "Error message that occurred",
          "required": false,
          "default": "Unknown error"
        },
        "mutation_hint": {
          "type": "string",
          "description": "User hint for what to fix/change",
          "required": false,
          "default": "Fix the error"
        },
        "dynamic_schema": {
          "type": "boolean",
          "description": "Make output schema dynamic (flexible JSON)",
          "default": false,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "tool_id": {
            "type": "string"
          },
          "original_version": {
            "type": "string"
          },
          "new_version": {
            "type": "string"
          },
          "evolved_file": {
            "type": "string",
            "description": "Path to evolved tool file"
          },
          "promotion_file": {
            "type": "string",
            "description": "Path to promotion config"
          },
          "message": {
            "type": "string"
          },
          "usage": {
            "type": "string",
            "description": "How to use the evolved tool"
          }
        }
      },
      "cost_tier": "medium",
      "speed_tier": "slow",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "3251eeaac4ad00f18e6f149f3e010bfc0827e1ff43d56eacfff022c44e9299c7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300224Z"
    },
    "created_at": "2025-11-16T14:36:50.752511Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "3251eeaac4ad00f18e6f149f3e010bfc0827e1ff43d56eacfff022c44e9299c7",
    "breaking_changes": []
  },
  "api_wrapper_generator": {
    "tool_id": "api_wrapper_generator",
    "name": "API Wrapper Generator",
    "tool_type": "executable",
    "description": "Generates a Flask API wrapper script for any tool or workflow, creating REST endpoints for tool invocation",
    "tags": [
      "api",
      "flask",
      "rest",
      "wrapper",
      "code-generation",
      "web-service"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\api_wrapper_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/api_wrapper_generator.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON configuration with: tool_id (required), port (default: 8080), host (default: 0.0.0.0), enable_cors (default: true)"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "api_script": "str - Generated Flask API wrapper script",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "e4fd3abd7c05934ba73ca5b702ce1cdd828a6b86a25f88b0c7a5bc4ee6bacea4",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300228Z"
    },
    "created_at": "2025-11-16T14:44:34.683195Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "e4fd3abd7c05934ba73ca5b702ce1cdd828a6b86a25f88b0c7a5bc4ee6bacea4",
    "breaking_changes": []
  },
  "config_file_generator": {
    "tool_id": "config_file_generator",
    "name": "Config File Generator",
    "tool_type": "executable",
    "description": "Generates comprehensive config.yaml files with sensible Ollama defaults (gemma3_1b, llama3), detailed documentation, and instructions for changing settings. Supports both Docker and standalone modes.",
    "tags": [
      "configuration",
      "config",
      "yaml",
      "ollama",
      "settings",
      "documentation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\config_file_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/config_file_generator.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON with: tool_id (required), mode ('docker' or 'standalone', default: docker), default_model ('gemma3_1b', 'llama3', 'qwen2.5-coder', 'codellama', default: gemma3_1b)"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "config_yaml": "str - Generated config.yaml with defaults and documentation",
        "instructions": "str - Comprehensive configuration instructions (markdown)",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.1",
      "definition_hash": "763317088c2b47c8c914230037f9ae0ce93d2c6c69d4faf63902c32755fc1948",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300232Z"
    },
    "created_at": "2025-11-17T01:04:52.642072Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "763317088c2b47c8c914230037f9ae0ce93d2c6c69d4faf63902c32755fc1948",
    "breaking_changes": []
  },
  "dependency_analyzer": {
    "tool_id": "dependency_analyzer",
    "name": "Dependency Analyzer",
    "tool_type": "executable",
    "description": "Analyzes tool dependencies using RAG and metadata for tree shaking. Recursively resolves all required tools, files, and packages to create minimal deployments.",
    "tags": [
      "dependencies",
      "tree-shaking",
      "optimization",
      "analysis",
      "packaging",
      "deployment"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\dependency_analyzer.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/dependency_analyzer.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON with: tool_id (required), tools_root (default: code_evolver/tools), include_rag (default: false)"
      },
      "output_schema": {
        "success": "bool - Whether analysis was successful",
        "tool_id": "str - Analyzed tool ID",
        "dependencies": "dict - All dependencies: {tools, tool_files, python_files, python_packages, core_modules, llm_providers, config_files}",
        "requirements_txt": "str - Generated requirements.txt content",
        "file_list": "list - Complete list of files to copy",
        "stats": "dict - Statistics: {total_tools, total_files, total_packages, estimated_size_kb}",
        "error": "str - Error message if analysis failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "244465966523eca60ea8cb33d604e22df926dba3242019235dff57000d64b68b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300235Z"
    },
    "created_at": "2025-11-16T14:44:34.699603Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "244465966523eca60ea8cb33d604e22df926dba3242019235dff57000d64b68b",
    "breaking_changes": []
  },
  "docker_compose_generator": {
    "tool_id": "docker_compose_generator",
    "name": "Docker Compose Generator",
    "tool_type": "executable",
    "description": "Generates docker-compose.yml configuration for containerized tool API wrappers",
    "tags": [
      "docker",
      "docker-compose",
      "orchestration",
      "containerization",
      "devops"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\docker_compose_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/docker_compose_generator.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON configuration with: service_name, image_name, port, env_vars (optional), volumes (optional), depends_on (optional)"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "docker_compose": "str - Generated docker-compose.yml content",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "b0100d77b2c1bf80808fa5cb04831c1b9c1c5562159e1ad7ed3044fe8ab7ab06",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300240Z"
    },
    "created_at": "2025-11-16T14:44:34.701148Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "b0100d77b2c1bf80808fa5cb04831c1b9c1c5562159e1ad7ed3044fe8ab7ab06",
    "breaking_changes": []
  },
  "docker_helper_scripts_generator": {
    "tool_id": "docker_helper_scripts_generator",
    "name": "Docker Helper Scripts Generator",
    "tool_type": "executable",
    "description": "Generates helper scripts (build.sh, run.sh, test.sh, stop.sh) for Docker packages",
    "tags": [
      "docker",
      "scripts",
      "automation",
      "devops",
      "helpers"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\docker_helper_scripts_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/docker_helper_scripts_generator.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON configuration with: service_name, port"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "scripts": "dict - Dictionary of script names to content",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "97dacf94e7fa09ff8c777873b5b3eab927f3cdf227991ae64c2099535f0a2ac3",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300244Z"
    },
    "created_at": "2025-11-16T14:44:34.702597Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "97dacf94e7fa09ff8c777873b5b3eab927f3cdf227991ae64c2099535f0a2ac3",
    "breaking_changes": []
  },
  "env_file_generator": {
    "tool_id": "env_file_generator",
    "name": "Environment File Generator",
    "tool_type": "executable",
    "description": "Generates .env and .env.example files with complete configuration documentation for Docker containers",
    "tags": [
      "environment",
      "configuration",
      "docker",
      "dotenv",
      "settings"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\env_file_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/env_file_generator.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON configuration with: tool_id, port, llm_config (optional dict), additional_vars (optional dict)"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "env_file": "str - Generated .env file content",
        "env_example": "str - Generated .env.example file with documentation",
        "instructions": "str - Detailed configuration instructions",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "56e35ec165238295f541b4bba25bb90e53af9b32d7982bd5a5dbc32b581dcad2",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300247Z"
    },
    "created_at": "2025-11-16T14:44:34.707867Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "56e35ec165238295f541b4bba25bb90e53af9b32d7982bd5a5dbc32b581dcad2",
    "breaking_changes": []
  },
  "package_recovery_tool": {
    "tool_id": "package_recovery_tool",
    "name": "Package Recovery Tool",
    "tool_type": "executable",
    "description": "Automatically detects missing packages from error messages and installs them. Supports Python packages (via pip) and system commands (via apt). Enables self-healing workflows.",
    "tags": [
      "recovery",
      "dependencies",
      "error-handling",
      "self-healing",
      "package-management",
      "resilience"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\package_recovery_tool.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/package_recovery_tool.py",
        "{input_json}"
      ],
      "input_schema": {
        "input_json": "str - JSON with: error_output (error message to analyze), auto_install (bool, default: true), install_system (bool, default: false)"
      },
      "output_schema": {
        "success": "bool - Whether recovery was successful",
        "detected": "dict - Detected missing packages: {python_packages: [...], system_commands: [...]}",
        "installation_results": "dict - Installation results for Python and system packages",
        "message": "str - Status message",
        "error": "str - Error message if recovery failed"
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "c798b362178fbeeda4bc5cbe5a3c8a4302bcf61fcaf2ba72ff89f1eeb5788376",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300250Z"
    },
    "created_at": "2025-11-16T14:44:34.723916Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "c798b362178fbeeda4bc5cbe5a3c8a4302bcf61fcaf2ba72ff89f1eeb5788376",
    "breaking_changes": []
  },
  "selective_file_copier": {
    "tool_id": "selective_file_copier",
    "name": "Selective File Copier",
    "tool_type": "executable",
    "description": "Copies only required files based on dependency analysis for tree-shaken deployments. Maintains directory structure and creates Python package init files.",
    "tags": [
      "file-operations",
      "tree-shaking",
      "optimization",
      "deployment",
      "packaging"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\selective_file_copier.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/selective_file_copier.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON with: file_list (required list of files), source_root (default: .), dest_root (required destination)"
      },
      "output_schema": {
        "success": "bool - Whether copy was successful",
        "copied_files": "list - List of copied files with sizes",
        "failed_files": "list - List of files that failed to copy",
        "created_dirs": "list - Directories created",
        "total_size_bytes": "int - Total bytes copied",
        "stats": "dict - Statistics: {total_files, copied, failed, total_size_mb}",
        "error": "str - Error message if copy failed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "fefab5472da33286a01437417ddc02aab87153a012642ae34b455c509e4ac306",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300254Z"
    },
    "created_at": "2025-11-16T14:44:34.739060Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "fefab5472da33286a01437417ddc02aab87153a012642ae34b455c509e4ac306",
    "breaking_changes": []
  },
  "standalone_exe_compiler": {
    "tool_id": "standalone_exe_compiler",
    "name": "Standalone Executable Compiler",
    "tool_type": "executable",
    "description": "Compiles tools/workflows into standalone executables (.exe, .app) using PyInstaller. Generates wrapper script, spec file, and build instructions",
    "tags": [
      "compiler",
      "executable",
      "pyinstaller",
      "standalone",
      "packaging",
      "distribution"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\standalone_exe_compiler.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/standalone_exe_compiler.py",
        "{config_json}"
      ],
      "input_schema": {
        "config_json": "str - JSON configuration with: tool_id (required), output_name (optional), mode ('cli' or 'api', default: cli), port (for API mode, default: 8080)"
      },
      "output_schema": {
        "success": "bool - Whether generation was successful",
        "wrapper_script": "str - Generated standalone Python wrapper script",
        "spec_file": "str - PyInstaller .spec file",
        "build_instructions": "str - Build instructions in markdown",
        "output_name": "str - Name of the output executable",
        "error": "str - Error message if generation failed"
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "8e20e9e4d3b53916623b1bc339857745babac7a9f0070a5783ded6a32dc71c5f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300257Z"
    },
    "created_at": "2025-11-16T14:44:34.753760Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "8e20e9e4d3b53916623b1bc339857745babac7a9f0070a5783ded6a32dc71c5f",
    "breaking_changes": []
  },
  "dockerfile_generator": {
    "tool_id": "dockerfile_generator",
    "name": "Dockerfile Generator",
    "tool_type": "llm",
    "description": "Generates optimized Dockerfiles for wrapping tools and workflows with best practices including multi-stage builds, security hardening, and layer caching",
    "tags": [
      "docker",
      "dockerfile",
      "containerization",
      "devops",
      "infrastructure",
      "api-wrapper"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\dockerfile_generator.yaml",
      "llm_tier": "coding.tier_2",
      "llm_role": "specialist",
      "system_prompt": "You are a Docker and containerization expert. Generate production-ready Dockerfiles following these best practices:\n\n1. Multi-stage builds to minimize image size\n2. Security hardening (non-root user, minimal base images)\n3. Layer caching optimization (dependencies before code)\n4. Minimal attack surface (only necessary packages)\n5. Health checks and metadata labels\n6. Proper signal handling and graceful shutdown\n7. Build arguments for flexibility\n\nAlways output ONLY the Dockerfile content without markdown code blocks or explanations.\n",
      "prompt_template": "Generate a Dockerfile for the following specification:\n\nBase Image: {base_image}\nApplication Type: {app_type}\nTool/Workflow ID: {tool_id}\nPort: {port}\nDependencies: {dependencies}\nEnvironment Variables: {env_vars}\nAdditional Requirements: {additional_requirements}\n\nThe Dockerfile should:\n- Copy the entire code_evolver directory structure\n- Install all Python dependencies\n- Create a non-root user for running the application\n- Expose the specified port\n- Include health check\n- Set up proper entrypoint for the API server\n",
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "long",
      "version": "1.0.0",
      "definition_hash": "7ec6c88e2243f43fc759e17fa521ffaf1ec78e8c711931787c998862af03f0d0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300261Z"
    },
    "created_at": "2025-11-16T14:44:34.775905Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "7ec6c88e2243f43fc759e17fa521ffaf1ec78e8c711931787c998862af03f0d0",
    "breaking_changes": []
  },
  "fetch_full_biography_data_from": {
    "tool_id": "fetch_full_biography_data_from",
    "name": "Fetch full biography data from API",
    "tool_type": "workflow",
    "description": "Fetch full biography data from API",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "fetch_full_biography_data_from",
      "quality_score": 1.1,
      "latency_ms": 49119,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-16T15:16:33.662203+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Fetch full biography data from API",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300264Z"
    },
    "created_at": "2025-11-16T15:16:33.662222Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_full_biography_data": {
    "tool_id": "translate_full_biography_data",
    "name": "Translate full biography data from API to French",
    "tool_type": "workflow",
    "description": "Translate full biography data from API to French",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_full_biography_data",
      "quality_score": 1.1,
      "latency_ms": 68298,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T15:18:49.659243+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate full biography data from API to French",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300268Z"
    },
    "created_at": "2025-11-16T15:18:49.659263Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "store_code_fix_pattern": {
    "tool_id": "store_code_fix_pattern",
    "name": "Store Code Fix Pattern",
    "tool_type": "executable",
    "description": "Pattern Recognizer with RAG Data Store - Stores code breaks and their fixes as reusable patterns.\n\nStores code fix patterns in a shared RAG-based data store for future retrieval. Each pattern\nincludes the error, broken code, fixed code, and context. Patterns are tagged and embedded\nfor semantic search. The data store scope determines visibility:\n- Store patterns at tool level (tool-specific learning)\n- Store patterns at tool+subtools level (hierarchical learning)\n- Store patterns at hierarchy level (contextual learning)\n- Store patterns globally (universal learning)\n",
    "tags": [
      "learning",
      "code-fix",
      "pattern-storage",
      "error-recovery",
      "self-improvement",
      "rag",
      "data-store",
      "pattern-recognizer"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\store_code_fix_pattern.yaml",
      "command": "python",
      "args": [
        "tools/executable/store_code_fix_pattern.py"
      ],
      "input_schema": {
        "error_message": {
          "type": "string",
          "description": "The error message that occurred",
          "required": true
        },
        "broken_code": {
          "type": "string",
          "description": "The code that caused the error",
          "required": true
        },
        "fixed_code": {
          "type": "string",
          "description": "The corrected code",
          "required": true
        },
        "fix_description": {
          "type": "string",
          "description": "Description of what was wrong and how it was fixed",
          "required": true
        },
        "error_type": {
          "type": "string",
          "description": "Category of error",
          "enum": [
            "syntax",
            "runtime",
            "logic",
            "type",
            "import",
            "undefined",
            "indentation",
            "unicode",
            "json",
            "unknown"
          ],
          "default": "unknown",
          "required": false
        },
        "language": {
          "type": "string",
          "description": "Programming language",
          "default": "python",
          "required": false
        },
        "context": {
          "type": "object",
          "description": "Additional context (tool_id, framework, etc.)",
          "required": false
        },
        "debug_info": {
          "type": "object",
          "description": "Full debug information (stack trace, variables, locals, etc.)",
          "required": false
        },
        "scope": {
          "type": "string",
          "description": "Data store scope - defines pattern visibility/accessibility:\n- \"tool\": Pattern only accessible by the current tool\n- \"tool_subttools\": Accessible by current tool and its sub-tools\n- \"hierarchy\": Accessible by all tools in current hierarchy\n- \"global\": Accessible by all tools (default)\n",
          "enum": [
            "tool",
            "tool_subttools",
            "hierarchy",
            "global"
          ],
          "default": "global",
          "required": false
        },
        "tool_id": {
          "type": "string",
          "description": "Current tool identifier (used with scope tagging)",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "pattern_id": {
            "type": "string",
            "description": "Unique ID for this fix pattern"
          },
          "error_type": {
            "type": "string"
          },
          "tags": {
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "message": {
            "type": "string"
          },
          "searchable_by": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.2",
      "definition_hash": "4d07c6563a4337d1a1d57bb68db6735c332558fd3efc7987c11e86e95709035b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300272Z"
    },
    "created_at": "2025-11-17T13:37:52.065236Z",
    "usage_count": 0,
    "version": "1.0.2",
    "definition_hash": "4d07c6563a4337d1a1d57bb68db6735c332558fd3efc7987c11e86e95709035b",
    "breaking_changes": []
  },
  "check_tool_duplicate": {
    "tool_id": "check_tool_duplicate",
    "name": "Check Tool Duplicate",
    "tool_type": "executable",
    "description": "Searches for semantically similar tools to avoid creating duplicates. Prevents tool proliferation by finding existing tools that match the functionality.",
    "tags": [
      "deduplication",
      "tool-search",
      "semantic-similarity",
      "meta-programming"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\check_tool_duplicate.yaml",
      "command": "python",
      "args": [
        "tools/executable/check_tool_duplicate.py"
      ],
      "input_schema": {
        "tool_description": {
          "type": "string",
          "description": "What the tool does",
          "required": true
        },
        "tool_name": {
          "type": "string",
          "description": "Name of the proposed tool",
          "required": false
        },
        "parameters": {
          "type": "array",
          "description": "List of parameters the tool takes",
          "required": false
        },
        "category": {
          "type": "string",
          "description": "Tool category (math, text, data, conversion, etc.)",
          "required": false
        },
        "similarity_threshold": {
          "type": "number",
          "description": "Minimum similarity to consider a duplicate (0.0-1.0)",
          "default": 0.85,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "has_duplicates": {
            "type": "boolean",
            "description": "Whether similar tools were found"
          },
          "duplicate_count": {
            "type": "integer"
          },
          "best_match": {
            "type": "object",
            "description": "The most similar existing tool",
            "properties": {
              "tool_id": {
                "type": "string"
              },
              "name": {
                "type": "string"
              },
              "description": {
                "type": "string"
              },
              "similarity": {
                "type": "number"
              },
              "usage_count": {
                "type": "integer"
              },
              "quality_score": {
                "type": "number"
              }
            }
          },
          "all_matches": {
            "type": "array",
            "description": "All similar tools found"
          },
          "recommendation": {
            "type": "string",
            "enum": [
              "use_existing_tool",
              "create_new_tool"
            ]
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "2dddef6d78f95092f500c142786273929547085bf011b29fb4e76a4e93b60577",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300275Z"
    },
    "created_at": "2025-11-16T15:46:53.635925Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "2dddef6d78f95092f500c142786273929547085bf011b29fb4e76a4e93b60577",
    "breaking_changes": []
  },
  "find_code_fix_pattern": {
    "tool_id": "find_code_fix_pattern",
    "name": "Find Code Fix Pattern",
    "tool_type": "executable",
    "description": "Pattern Recognizer with RAG Data Store - Searches for similar code errors and suggests proven fixes.\n\nUses a shared RAG-based pattern data store to find code fix patterns that have been successfully\napplied in the past. Returns multiple solutions ranked by usage count (proven effectiveness) and\nsemantic similarity. The data store scope can be configured to search:\n- Only patterns from the current tool\n- Patterns from the current tool and its sub-tools\n- All patterns across the entire tool hierarchy\n",
    "tags": [
      "learning",
      "code-fix",
      "pattern-search",
      "error-recovery",
      "self-improvement",
      "rag",
      "data-store",
      "pattern-recognizer"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\find_code_fix_pattern.yaml",
      "command": "python",
      "args": [
        "tools/executable/find_code_fix_pattern.py"
      ],
      "input_schema": {
        "error_message": {
          "type": "string",
          "description": "The error message to search for",
          "required": true
        },
        "broken_code": {
          "type": "string",
          "description": "The broken code (helps with similarity matching)",
          "required": false
        },
        "error_type": {
          "type": "string",
          "description": "Category of error (helps filter results)",
          "required": false
        },
        "language": {
          "type": "string",
          "description": "Programming language",
          "default": "python",
          "required": false
        },
        "top_k": {
          "type": "integer",
          "description": "Number of similar patterns to return",
          "default": 3,
          "required": false
        },
        "scope": {
          "type": "string",
          "description": "Data store scope - defines which patterns are accessible:\n- \"tool\": Only patterns stored by the current tool\n- \"tool_subttools\": Patterns from current tool and its sub-tools\n- \"hierarchy\": All patterns in the current tool hierarchy\n- \"global\": All patterns across all tools (default)\n",
          "enum": [
            "tool",
            "tool_subttools",
            "hierarchy",
            "global"
          ],
          "default": "global",
          "required": false
        },
        "tool_id": {
          "type": "string",
          "description": "Current tool identifier (used with scope filtering)",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "found": {
            "type": "boolean",
            "description": "Whether any patterns were found"
          },
          "pattern_count": {
            "type": "integer",
            "description": "Number of patterns found"
          },
          "best_match": {
            "type": "object",
            "description": "The highest-ranked fix (by usage + similarity)",
            "properties": {
              "pattern_id": {
                "type": "string"
              },
              "similarity": {
                "type": "number"
              },
              "usage_count": {
                "type": "integer"
              },
              "rank_score": {
                "type": "number"
              },
              "error_message": {
                "type": "string"
              },
              "broken_code": {
                "type": "string"
              },
              "fixed_code": {
                "type": "string"
              },
              "fix_description": {
                "type": "string"
              },
              "debug_info": {
                "type": "object"
              }
            }
          },
          "all_patterns": {
            "type": "array",
            "description": "All matching patterns ranked by effectiveness",
            "items": {
              "type": "object"
            }
          },
          "recommendation": {
            "type": "string"
          },
          "how_to_apply": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.1",
      "definition_hash": "0fd8d435634533419b6255afd50b1a171a9ce8fc5dc48784e50727d12a1665ea",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300279Z"
    },
    "created_at": "2025-11-17T13:37:51.765381Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "0fd8d435634533419b6255afd50b1a171a9ce8fc5dc48784e50727d12a1665ea",
    "breaking_changes": []
  },
  "prompt_genericiser": {
    "tool_id": "prompt_genericiser",
    "name": "Prompt Genericiser",
    "tool_type": "llm",
    "description": "Converts specific prompts into generic, reusable tool descriptions. Prevents unnecessary specialization by identifying the underlying generic pattern.",
    "tags": [
      "generalization",
      "deduplication",
      "pattern-extraction",
      "meta-programming"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\prompt_genericiser.yaml",
      "llm_tier": "triage",
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "a855ec629a92c9f384c9af8f3b7cc8aefc4c2e649774f2955cc79f3e88482787",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300283Z"
    },
    "created_at": "2025-11-16T15:46:53.734260Z",
    "usage_count": 1,
    "version": "1.0.0",
    "definition_hash": "a855ec629a92c9f384c9af8f3b7cc8aefc4c2e649774f2955cc79f3e88482787",
    "breaking_changes": []
  },
  "inline_tool": {
    "tool_id": "inline_tool",
    "name": "Inline Tool",
    "tool_type": "executable",
    "description": "Bakes tool code directly into workflow scripts with version tracking. Enables enterprise reproducibility by embedding dependencies with RAG references.",
    "tags": [
      "enterprise",
      "reproducibility",
      "deployment",
      "dependency-management"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\inline_tool.yaml",
      "command": "python",
      "args": [
        "tools/executable/inline_tool.py"
      ],
      "input_schema": {
        "operation": {
          "type": "string",
          "description": "Operation: 'inline', 'extract', 'update', or 'list'",
          "enum": [
            "inline",
            "extract",
            "update",
            "list"
          ],
          "default": "inline",
          "required": false
        },
        "workflow_file": {
          "type": "string",
          "description": "Path to workflow script to modify",
          "required": true
        },
        "tool_id": {
          "type": "string",
          "description": "ID of tool to inline (required for 'inline' operation)",
          "required": false
        },
        "version": {
          "type": "string",
          "description": "Version to inline (or 'current' for latest)",
          "default": "current",
          "required": false
        },
        "inline_marker_id": {
          "type": "string",
          "description": "Marker ID of inlined section (required for 'extract' and 'update')",
          "required": false
        },
        "position": {
          "type": "string",
          "description": "Where to insert inlined code ('top' or 'bottom')",
          "enum": [
            "top",
            "bottom"
          ],
          "default": "top",
          "required": false
        },
        "pin_version": {
          "type": "boolean",
          "description": "Pin this version in RAG to protect from trimming",
          "default": true,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "tool_id": {
            "type": "string"
          },
          "version": {
            "type": "string"
          },
          "workflow_file": {
            "type": "string"
          },
          "inline_marker_id": {
            "type": "string",
            "description": "Unique marker for this inlined section"
          },
          "position": {
            "type": "string"
          },
          "pinned": {
            "type": "boolean"
          },
          "message": {
            "type": "string"
          },
          "code_size_bytes": {
            "type": "integer"
          },
          "code_size_lines": {
            "type": "integer"
          },
          "inlined_tools": {
            "type": "array",
            "description": "List of inlined tools (for 'list' operation)"
          },
          "extracted_lines": {
            "type": "integer",
            "description": "Lines removed (for 'extract' operation)"
          },
          "update": {
            "type": "object",
            "description": "Update information (for 'update' operation)"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "e97d818682755ea3e8870c0c2ae012e3fa38804b7de477041389536bbe590164",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300287Z"
    },
    "created_at": "2025-11-16T16:37:21.157255Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "e97d818682755ea3e8870c0c2ae012e3fa38804b7de477041389536bbe590164",
    "breaking_changes": []
  },
  "pin_tool_version": {
    "tool_id": "pin_tool_version",
    "name": "Pin Tool Version",
    "tool_type": "executable",
    "description": "Locks a workflow to specific tool versions. Pinned versions are protected from trimming and can be inlined into workflow scripts for enterprise reproducibility.",
    "tags": [
      "enterprise",
      "version-control",
      "dependency-management",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\pin_tool_version.yaml",
      "command": "python",
      "args": [
        "tools/executable/pin_tool_version.py"
      ],
      "input_schema": {
        "operation": {
          "type": "string",
          "description": "Operation: 'pin', 'unpin', or 'list'",
          "enum": [
            "pin",
            "unpin",
            "list"
          ],
          "default": "pin",
          "required": false
        },
        "tool_id": {
          "type": "string",
          "description": "ID of the tool to pin/unpin (required for pin/unpin)",
          "required": false
        },
        "version": {
          "type": "string",
          "description": "Version to pin (or 'current' for latest). Optional for unpin (unpins all versions if not specified)",
          "default": "current",
          "required": false
        },
        "workflow_id": {
          "type": "string",
          "description": "Workflow that depends on this version (optional, enables workflow-specific pins)",
          "required": false
        },
        "reason": {
          "type": "string",
          "description": "Why this version is pinned (documentation)",
          "default": "",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "tool_id": {
            "type": "string"
          },
          "version": {
            "type": "string"
          },
          "workflow_id": {
            "type": "string"
          },
          "pin_key": {
            "type": "string",
            "description": "Unique pin identifier: workflow_id:tool_id@version"
          },
          "message": {
            "type": "string"
          },
          "protected_from_trimming": {
            "type": "boolean"
          },
          "pins": {
            "type": "array",
            "description": "List of pins (for 'list' operation)"
          },
          "unpinned": {
            "type": "integer",
            "description": "Number of pins removed (for 'unpin' operation)"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "71dc551bc528db18de5d6ef42e64e923aa669eacd364fb1d4f61598452caba64",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300290Z"
    },
    "created_at": "2025-11-16T16:37:22.333430Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "71dc551bc528db18de5d6ef42e64e923aa669eacd364fb1d4f61598452caba64",
    "breaking_changes": []
  },
  "trim_tool_versions": {
    "tool_id": "trim_tool_versions",
    "name": "Trim Tool Versions",
    "tool_type": "executable",
    "description": "Keeps tools tidy by retaining only recent versions (2-3 back) plus original. Archives or deletes old versions for rollback capability.",
    "tags": [
      "maintenance",
      "version-control",
      "cleanup",
      "storage-optimization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\trim_tool_versions.yaml",
      "command": "python",
      "args": [
        "tools/executable/trim_tool_versions.py"
      ],
      "input_schema": {
        "tool_id": {
          "type": "string",
          "description": "ID of the tool to trim (or set trim_all: true)",
          "required": false
        },
        "keep_recent": {
          "type": "integer",
          "description": "Number of recent versions to keep",
          "default": 3,
          "required": false
        },
        "archive_old": {
          "type": "boolean",
          "description": "Archive old versions instead of deleting",
          "default": true,
          "required": false
        },
        "dry_run": {
          "type": "boolean",
          "description": "Don't actually delete, just report what would happen",
          "default": false,
          "required": false
        },
        "trim_all": {
          "type": "boolean",
          "description": "Trim versions for all tools",
          "default": false,
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean"
          },
          "tool_id": {
            "type": "string"
          },
          "total_versions": {
            "type": "integer"
          },
          "kept": {
            "type": "integer"
          },
          "trimmed": {
            "type": "integer"
          },
          "kept_versions": {
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "trimmed_files": {
            "type": "array"
          },
          "space_saved_kb": {
            "type": "number"
          },
          "archive_location": {
            "type": "string"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "aca0a2a245584365b597b5da1b1eeb0aec35d61cb36fd867681292d38a0f13a7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300294Z"
    },
    "created_at": "2025-11-16T16:37:23.010156Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "aca0a2a245584365b597b5da1b1eeb0aec35d61cb36fd867681292d38a0f13a7",
    "breaking_changes": []
  },
  "detect_tool_specialization": {
    "tool_id": "detect_tool_specialization",
    "name": "Detect Tool Specialization",
    "tool_type": "llm",
    "description": "Detects when an evolved tool has diverged far enough to become a new specialized tool with its own directory. Prevents tools from evolving beyond their original purpose.",
    "tags": [
      "tool-evolution",
      "specialization",
      "meta-programming",
      "organization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\detect_tool_specialization.yaml",
      "llm_tier": "triage",
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "6288365d06a154b314275cacb81da9c9eaad158c1f792401c3c70fb5e7c1e516",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300298Z"
    },
    "created_at": "2025-11-16T16:37:23.342186Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6288365d06a154b314275cacb81da9c9eaad158c1f792401c3c70fb5e7c1e516",
    "breaking_changes": []
  },
  "write_a_long_form_outline_ab": {
    "tool_id": "write_a_long_form_outline_ab",
    "name": "write a long form outline   about coding",
    "tool_type": "workflow",
    "description": "write a long form outline   about coding",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_long_form_outline_ab",
      "quality_score": 1.1,
      "latency_ms": 880,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-16T18:18:47.459894+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write a long form outline   about coding",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300303Z"
    },
    "created_at": "2025-11-16T18:18:47.459930Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "semantic_comparator": {
    "tool_id": "semantic_comparator",
    "name": "Semantic Comparator",
    "tool_type": "llm",
    "description": "Decides if two prompts have the EXACT same meaning (100% match) or are similar enough for mutation (>50%). Used to prevent inappropriate workflow reuse for creative tasks.",
    "tags": [
      "comparison",
      "semantic",
      "routing",
      "cache-decision"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\semantic_comparator.yaml",
      "llm_tier": "fast",
      "llm_role": "comparator",
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "c126cd344668c2b8335951237903c6dcc4c6437b51b935cd5c3fd7414860450f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300306Z"
    },
    "created_at": "2025-11-16T18:39:13.503483Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "c126cd344668c2b8335951237903c6dcc4c6437b51b935cd5c3fd7414860450f",
    "breaking_changes": []
  },
  "use_the_received_instructions": {
    "tool_id": "use_the_received_instructions",
    "name": "Use the received instructions to generate a new workflow",
    "tool_type": "workflow",
    "description": "Use the received instructions to generate a new workflow",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "use_the_received_instructions",
      "quality_score": 1.1,
      "latency_ms": 77001,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T18:47:31.754777+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Use the received instructions to generate a new workflow",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300310Z"
    },
    "created_at": "2025-11-16T18:47:31.754804Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "fake_data_generator": {
    "tool_id": "fake_data_generator",
    "name": "Fake Data Generator",
    "tool_type": "executable",
    "description": "Generates realistic fake data using Faker library for API testing and data simulation",
    "tags": [
      "testing",
      "data-generation",
      "faker",
      "api-testing",
      "mock-data"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\fake_data_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/fake_data_generator.py"
      ],
      "input_schema": {
        "schema": {
          "type": "object",
          "description": "JSON schema describing the data structure to generate",
          "required": false
        },
        "count": {
          "type": "integer",
          "description": "Number of fake data items to generate (default: 1)",
          "required": false,
          "default": 1
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether generation succeeded"
          },
          "data": {
            "description": "Generated fake data (single item or array based on count)"
          },
          "schema": {
            "type": "object",
            "description": "The schema that was used"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.1",
      "definition_hash": "e887b6fde6f02c2e70ae5a2b7faa0602999d23cd1d9af10000bccd87879332f4",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300313Z"
    },
    "created_at": "2025-11-16T19:12:19.491661Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "e887b6fde6f02c2e70ae5a2b7faa0602999d23cd1d9af10000bccd87879332f4",
    "breaking_changes": []
  },
  "smart_api_parser": {
    "tool_id": "smart_api_parser",
    "name": "Smart API Parser",
    "tool_type": "executable",
    "description": "Intelligently parses OpenAPI specs, generates realistic test data, and tests all endpoints. Can use Faker or LLM for data generation.",
    "tags": [
      "api-testing",
      "openapi",
      "swagger",
      "testing",
      "data-generation",
      "integration-testing"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\smart_api_parser.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/smart_api_parser.py"
      ],
      "input_schema": {
        "openapi_spec": {
          "type": "object",
          "description": "OpenAPI 3.0 specification (JSON object)",
          "required": true
        },
        "use_llm_generator": {
          "type": "boolean",
          "description": "Use LLM for contextual fake data (slower but smarter) vs Faker (faster)",
          "required": false,
          "default": false
        },
        "make_requests": {
          "type": "boolean",
          "description": "Actually make HTTP requests to endpoints (false = dry run with generated data only)",
          "required": false,
          "default": false
        },
        "endpoints": {
          "type": "array",
          "description": "List of endpoint operation IDs to test (null = test all)",
          "required": false,
          "items": {
            "type": "string"
          }
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether parsing succeeded"
          },
          "api_info": {
            "type": "object",
            "description": "API metadata from OpenAPI spec"
          },
          "base_url": {
            "type": "string",
            "description": "Base URL of the API"
          },
          "total_endpoints": {
            "type": "integer",
            "description": "Total number of endpoints in spec"
          },
          "tested_endpoints": {
            "type": "integer",
            "description": "Number of endpoints tested"
          },
          "results": {
            "type": "array",
            "description": "Test results for each endpoint",
            "items": {
              "type": "object",
              "properties": {
                "endpoint": {
                  "type": "string"
                },
                "method": {
                  "type": "string"
                },
                "url": {
                  "type": "string"
                },
                "request_body": {
                  "description": "Generated request body"
                },
                "status_code": {
                  "type": "integer"
                },
                "response_body": {
                  "description": "API response (if make_requests=true)"
                },
                "success": {
                  "type": "boolean"
                },
                "error": {
                  "type": "string"
                }
              }
            }
          },
          "options": {
            "type": "object",
            "description": "Options used for testing"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "medium",
      "quality_tier": "excellent",
      "version": "1.0.1",
      "definition_hash": "10cce07962ea1b717953a7d40d56e9347a89ce5510d3cff883f789d64d48a211",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300317Z"
    },
    "created_at": "2025-11-16T19:12:20.731463Z",
    "usage_count": 0,
    "version": "1.0.1",
    "definition_hash": "10cce07962ea1b717953a7d40d56e9347a89ce5510d3cff883f789d64d48a211",
    "breaking_changes": []
  },
  "llm_fake_data_generator": {
    "tool_id": "llm_fake_data_generator",
    "name": "LLM Fake Data Generator",
    "tool_type": "llm",
    "description": "Uses LLM to generate contextually appropriate fake data based on field names and descriptions. Better for complex, domain-specific data.",
    "tags": [
      "llm",
      "data-generation",
      "testing",
      "api-testing",
      "mock-data",
      "contextual"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\llm_fake_data_generator.yaml",
      "llm_tier": "fast",
      "llm_role": "generator",
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "cdec28117cf095997bf159884b90b16a9e07680392739734b34d97ba502e80fc",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300320Z"
    },
    "created_at": "2025-11-16T18:54:43.788820Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "cdec28117cf095997bf159884b90b16a9e07680392739734b34d97ba502e80fc",
    "breaking_changes": []
  },
  "collect_data_from_remote_api": {
    "tool_id": "collect_data_from_remote_api",
    "name": "Collect data from remote API",
    "tool_type": "workflow",
    "description": "Collect data from remote API",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "collect_data_from_remote_api",
      "quality_score": 1.1,
      "latency_ms": 782,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T19:40:57.911672+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Collect data from remote API",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300324Z"
    },
    "created_at": "2025-11-16T19:40:57.911688Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "save_data_to_disk_with_random": {
    "tool_id": "save_data_to_disk_with_random",
    "name": "Save data to disk with random filename SOMITING-OUT.TXT",
    "tool_type": "workflow",
    "description": "Save data to disk with random filename SOMITING-OUT.TXT",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "save_data_to_disk_with_random",
      "quality_score": 1.1,
      "latency_ms": 856,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T19:42:34.039134+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Save data to disk with random filename SOMITING-OUT.TXT",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300327Z"
    },
    "created_at": "2025-11-16T19:42:34.039153Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_an_efficient_systme_to_b": {
    "tool_id": "write_an_efficient_systme_to_b",
    "name": "Write an efficient systme to build a fractal. Evolve it 3 time suntil it is efficient.",
    "tool_type": "workflow",
    "description": "Write an efficient systme to build a fractal. Evolve it 3 time suntil it is efficient.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_an_efficient_systme_to_b",
      "quality_score": 1.1,
      "latency_ms": 794,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T20:30:38.048858+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write an efficient systme to build a fractal. Evolve it 3 time suntil it is efficient.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300332Z"
    },
    "created_at": "2025-11-16T20:30:38.048887Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "bugcatcher": {
    "tool_id": "bugcatcher",
    "name": "BugCatcher Exception Monitor",
    "tool_type": "executable",
    "description": "Global exception monitoring tool that watches for exceptions and logs them to Loki",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\bugcatcher.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "40977576bc52077d3a62f85c1fe98b4dd1450e966c7b71b5465db0baedf740fb",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300336Z"
    },
    "created_at": "2025-11-16T21:05:17.771074Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "40977576bc52077d3a62f85c1fe98b4dd1450e966c7b71b5465db0baedf740fb",
    "breaking_changes": []
  },
  "http_raw_client": {
    "tool_id": "http_raw_client",
    "name": "HTTP Raw Client",
    "tool_type": "executable",
    "description": "Raw HTTP client that returns content as string without parsing. Perfect for HTML, text files, binary data, or any non-JSON content.",
    "tags": [
      "http",
      "raw",
      "html",
      "scraping",
      "binary",
      "text",
      "client"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\http_raw_client.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/http_raw_client.py"
      ],
      "input_schema": {
        "url": {
          "type": "string",
          "description": "Target URL",
          "required": true,
          "example": "https://example.com/page.html"
        },
        "method": {
          "type": "string",
          "description": "HTTP method",
          "required": false,
          "default": "GET",
          "enum": [
            "GET",
            "POST",
            "PUT",
            "PATCH",
            "DELETE",
            "HEAD",
            "OPTIONS"
          ]
        },
        "headers": {
          "type": "object",
          "description": "HTTP headers",
          "required": false
        },
        "body": {
          "type": "string",
          "description": "Request body (raw string only)",
          "required": false
        },
        "timeout": {
          "type": "integer",
          "description": "Request timeout in seconds",
          "required": false,
          "default": 30
        },
        "encoding": {
          "type": "string",
          "description": "Text encoding (default: utf-8)",
          "required": false,
          "default": "utf-8"
        },
        "return_binary": {
          "type": "boolean",
          "description": "Force base64 encoding of response",
          "required": false,
          "default": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether request succeeded"
          },
          "status_code": {
            "type": "integer",
            "description": "HTTP status code"
          },
          "headers": {
            "type": "object",
            "description": "Response headers"
          },
          "content": {
            "type": "string",
            "description": "Raw content (text or base64)"
          },
          "content_type": {
            "type": "string",
            "description": "Content-Type header value"
          },
          "content_length": {
            "type": "integer",
            "description": "Content length in bytes"
          },
          "is_binary": {
            "type": "boolean",
            "description": "Whether content is base64-encoded binary"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "54dc928854b760f3ffd6a1b4206e195c518b1e16bf74257de08620cce045a3f6",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300339Z"
    },
    "created_at": "2025-11-16T21:05:19.300501Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "54dc928854b760f3ffd6a1b4206e195c518b1e16bf74257de08620cce045a3f6",
    "breaking_changes": []
  },
  "http_rest_client": {
    "tool_id": "http_rest_client",
    "name": "HTTP REST Client",
    "tool_type": "executable",
    "description": "Standard REST API client with automatic JSON parsing. Supports GET, POST, PUT, PATCH, DELETE methods with JSON request/response handling.",
    "tags": [
      "http",
      "rest",
      "api",
      "json",
      "web",
      "client",
      "request"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\http_rest_client.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/http_rest_client.py"
      ],
      "input_schema": {
        "url": {
          "type": "string",
          "description": "Target URL",
          "required": true,
          "example": "https://api.example.com/users"
        },
        "method": {
          "type": "string",
          "description": "HTTP method",
          "required": false,
          "default": "GET",
          "enum": [
            "GET",
            "POST",
            "PUT",
            "PATCH",
            "DELETE",
            "HEAD",
            "OPTIONS"
          ]
        },
        "headers": {
          "type": "object",
          "description": "HTTP headers",
          "required": false,
          "example": {
            "Authorization": "Bearer token123",
            "X-Custom-Header": "value"
          }
        },
        "body": {
          "description": "Request body (dict/list = JSON, string = raw)",
          "required": false
        },
        "timeout": {
          "type": "integer",
          "description": "Request timeout in seconds",
          "required": false,
          "default": 30
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether request succeeded"
          },
          "status_code": {
            "type": "integer",
            "description": "HTTP status code"
          },
          "headers": {
            "type": "object",
            "description": "Response headers"
          },
          "body": {
            "description": "Response body (parsed JSON or raw string)"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          },
          "url": {
            "type": "string",
            "description": "Request URL"
          },
          "method": {
            "type": "string",
            "description": "Request method"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "13481298cb87a6ad9f48e294679f32b382960a4d8b40fa4f4aa3e5937ed9be68",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300343Z"
    },
    "created_at": "2025-11-16T21:05:19.850955Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "13481298cb87a6ad9f48e294679f32b382960a4d8b40fa4f4aa3e5937ed9be68",
    "breaking_changes": []
  },
  "signalr_tool_trigger": {
    "tool_id": "signalr_tool_trigger",
    "name": "SignalR Tool Trigger",
    "tool_type": "executable",
    "description": "Listens to SignalR endpoint and dynamically triggers tools based on incoming messages. Supports direct tool invocation, workflow generation, and dynamic tool creation from API specs.",
    "tags": [
      "signalr",
      "realtime",
      "integration",
      "dynamic",
      "tool-trigger",
      "workflow-generation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\signalr_tool_trigger.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/signalr_tool_trigger.py"
      ],
      "input_schema": {
        "hub_url": {
          "type": "string",
          "description": "SignalR hub URL to connect to",
          "required": true,
          "example": "http://localhost:5000/toolhub"
        },
        "hub_method": {
          "type": "string",
          "description": "Hub method name to subscribe to",
          "required": false,
          "default": "ToolTrigger"
        },
        "duration_seconds": {
          "type": "number",
          "description": "How long to listen (omit for continuous listening)",
          "required": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether connection was successful"
          },
          "hub_url": {
            "type": "string",
            "description": "URL connected to"
          },
          "hub_method": {
            "type": "string",
            "description": "Hub method subscribed to"
          },
          "total_messages": {
            "type": "integer",
            "description": "Total messages received"
          },
          "successful_results": {
            "type": "integer",
            "description": "Number of successfully processed messages"
          },
          "errors": {
            "type": "integer",
            "description": "Number of errors encountered"
          },
          "results": {
            "type": "array",
            "description": "Array of results from triggered tools/workflows"
          },
          "error_details": {
            "type": "array",
            "description": "Details of any errors"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "realtime",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "eebcab7a6c40bb8aba31d3cba1e5193003280098ed6e1b408f43fb6d95b85039",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300346Z"
    },
    "created_at": "2025-11-16T21:05:20.413481Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "eebcab7a6c40bb8aba31d3cba1e5193003280098ed6e1b408f43fb6d95b85039",
    "breaking_changes": []
  },
  "compress_the_image_to_50": {
    "tool_id": "compress_the_image_to_50",
    "name": "Compress the image to 50%",
    "tool_type": "workflow",
    "description": "Compress the image to 50%",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "compress_the_image_to_50",
      "quality_score": 1.2000000000000002,
      "latency_ms": 41,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T22:00:32.057365+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Compress the image to 50%",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300350Z"
    },
    "created_at": "2025-11-16T22:00:32.057386Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "filesystem": {
    "tool_id": "filesystem",
    "name": "Tool-Scoped Filesystem",
    "tool_type": "executable",
    "description": "Isolated filesystem operations for tool-scoped data storage with automatic directory management",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\filesystem.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "d2347b770077b4a508cda89caf9dd6e8e44a40d310c1f26ce79e3f64b1b33e83",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300354Z"
    },
    "created_at": "2025-11-16T22:19:28.154854Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "d2347b770077b4a508cda89caf9dd6e8e44a40d310c1f26ce79e3f64b1b33e83",
    "breaking_changes": []
  },
  "loki": {
    "tool_id": "loki",
    "name": "Loki Log Aggregation",
    "tool_type": "executable",
    "description": "Manages Grafana Loki instance for log aggregation and monitoring (tool/global scope)",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\loki.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "70fef6859e0c8d641c268f0af3ea6ffeec9027a03a6731d3a30cfc7e2842dd0e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300359Z"
    },
    "created_at": "2025-11-16T22:19:29.467347Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "70fef6859e0c8d641c268f0af3ea6ffeec9027a03a6731d3a30cfc7e2842dd0e",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul": {
    "tool_id": "note_this_workflow_may_be_mul",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Aggregate daily production by line: [{\"line\": 1, \"output\": 1016}, {\"line\": 2, \"output\": 787}, {\"line\": 3, \"output\": 1498}, {\"line\": 4, \"output\": 682}] and rank by efficiency\n\nStages:\n1. Summarize and report\n2. Reflect and propose improvements\n3. Plan the approach and outline solution",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Aggregate daily production by line: [{\"line\": 1, \"output\": 1016}, {\"line\": 2, \"output\": 787}, {\"line\": 3, \"output\": 1498}, {\"line\": 4, \"output\": 682}] and rank by efficiency\n\nStages:\n1. Summarize and report\n2. Reflect and propose improvements\n3. Plan the approach and outline solution",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul",
      "quality_score": 1.1,
      "latency_ms": 813,
      "memory_mb_peak": 1.94,
      "created_at": "2025-11-16T23:58:51.200460+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Aggregate daily production by line: [{\"line\": 1, \"output\": 1016}, {\"line\": 2, \"output\": 787}, {\"line\": 3, \"output\": 1498}, {\"line\": 4, \"output\": 682}] and rank by efficiency\n\nStages:\n1. Summarize and report\n2. Reflect and propose improvements\n3. Plan the approach and outline solution",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300362Z"
    },
    "created_at": "2025-11-16T23:58:51.200477Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "determine_labor_cost_16_worke": {
    "tool_id": "determine_labor_cost_16_worke",
    "name": "Determine labor cost: 16 workers × 3 hours × $33/hour",
    "tool_type": "workflow",
    "description": "Determine labor cost: 16 workers × 3 hours × $33/hour",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "determine_labor_cost_16_worke",
      "quality_score": 1.2000000000000002,
      "latency_ms": 56,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T00:02:46.175553+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Determine labor cost: 16 workers × 3 hours × $33/hour",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300366Z"
    },
    "created_at": "2025-11-17T00:02:46.175573Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763337843": {
    "tool_id": "note_this_workflow_may_be_mul_1763337843",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Translate machine manual section 'Emergency shutdown procedure' to Japanese maintaining technical accuracy\n\nStages:\n1. Assess terminology\n2. Document results and assumptions\n3. Run quick validation/tests and fix issues",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Translate machine manual section 'Emergency shutdown procedure' to Japanese maintaining technical accuracy\n\nStages:\n1. Assess terminology\n2. Document results and assumptions\n3. Run quick validation/tests and fix issues",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763337843",
      "quality_score": 1.1,
      "latency_ms": 1401,
      "memory_mb_peak": 1.93,
      "created_at": "2025-11-17T00:06:38.511182+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Translate machine manual section 'Emergency shutdown procedure' to Japanese maintaining technical accuracy\n\nStages:\n1. Assess terminology\n2. Document results and assumptions\n3. Run quick validation/tests and fix issues",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300370Z"
    },
    "created_at": "2025-11-17T00:06:38.511208Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "behave_test_generator": {
    "tool_id": "behave_test_generator",
    "name": "Behave BDD Test Generator",
    "tool_type": "executable",
    "description": "Generate Behave BDD tests with step definitions from Gherkin feature files, tool specs, or workflow definitions with plausible test data",
    "tags": [
      "testing",
      "bdd",
      "behave",
      "test-generation",
      "gherkin",
      "acceptance-testing",
      "behavior-driven",
      "characterization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\behave_test_generator.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/behave_test_generator.py"
      ],
      "input_schema": {
        "feature_file": {
          "type": "string",
          "description": "Path to Gherkin .feature file",
          "required": false
        },
        "feature_content": {
          "type": "string",
          "description": "Inline Gherkin feature content (if feature_file not provided)",
          "required": false
        },
        "tool_spec": {
          "type": "string",
          "description": "Path to tool YAML spec to generate BDD tests for",
          "required": false
        },
        "static_analysis_path": {
          "type": "string",
          "description": "Path to static analysis results for plausible data generation",
          "required": false
        },
        "mode": {
          "type": "string",
          "description": "Mode: 'generate' (create steps), 'run' (execute tests), or 'both'",
          "required": false,
          "default": "both"
        },
        "output_path": {
          "type": "string",
          "description": "Directory where generated step definitions will be saved",
          "required": false,
          "default": "./features/steps"
        },
        "feature_output_path": {
          "type": "string",
          "description": "Directory where feature files will be saved",
          "required": false,
          "default": "./features"
        }
      },
      "output_schema": {
        "steps_file_path": {
          "type": "string",
          "description": "Path to generated step definitions file"
        },
        "feature_file_path": {
          "type": "string",
          "description": "Path to feature file"
        },
        "results": {
          "type": "object",
          "description": "BDD test results (if executed)"
        },
        "scenarios_count": {
          "type": "integer",
          "description": "Number of scenarios generated/tested"
        },
        "success": {
          "type": "boolean",
          "description": "Whether test generation/execution succeeded"
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "9d17af0ef99427bdbdc4134602ff929d70712507cbef51c51e2439385d69e494",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300375Z"
    },
    "created_at": "2025-11-17T00:38:55.143090Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "9d17af0ef99427bdbdc4134602ff929d70712507cbef51c51e2439385d69e494",
    "breaking_changes": []
  },
  "create_behave_spec": {
    "tool_id": "create_behave_spec",
    "name": "Create Behave Spec",
    "tool_type": "executable",
    "description": "Create a Behave BDD specification file for RAG storage and future test generation",
    "tags": [
      "testing",
      "spec-creation",
      "behave",
      "bdd",
      "rag"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\create_behave_spec.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/create_behave_spec.py"
      ],
      "input_schema": {
        "tool_name": {
          "type": "string",
          "description": "Name of the tool to create spec for",
          "required": true
        },
        "description": {
          "type": "string",
          "description": "Tool description",
          "required": false
        },
        "scenarios": {
          "type": "array",
          "description": "List of test scenarios",
          "required": false
        },
        "output_path": {
          "type": "string",
          "description": "Path to save the spec file",
          "required": false,
          "default": "./specs/behave"
        }
      },
      "output_schema": {
        "spec_path": {
          "type": "string",
          "description": "Path to created spec file"
        },
        "feature_path": {
          "type": "string",
          "description": "Path to created feature file"
        },
        "success": {
          "type": "boolean",
          "description": "Whether spec creation succeeded"
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "8132f1dd4b8da433bb59fc66424aa47d5a686a2913bae14d5804d1096fd0ee54",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300378Z"
    },
    "created_at": "2025-11-17T00:38:56.295984Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "8132f1dd4b8da433bb59fc66424aa47d5a686a2913bae14d5804d1096fd0ee54",
    "breaking_changes": []
  },
  "create_locust_spec": {
    "tool_id": "create_locust_spec",
    "name": "Create Locust Spec",
    "tool_type": "executable",
    "description": "Create a Locust load test specification file for RAG storage and future test generation",
    "tags": [
      "testing",
      "spec-creation",
      "locust",
      "performance",
      "rag"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\create_locust_spec.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/create_locust_spec.py"
      ],
      "input_schema": {
        "tool_name": {
          "type": "string",
          "description": "Name of the tool to create spec for",
          "required": true
        },
        "endpoints": {
          "type": "array",
          "description": "List of API endpoints to test",
          "required": false
        },
        "base_url": {
          "type": "string",
          "description": "Base URL for the API",
          "required": false,
          "default": "http://localhost:8000"
        },
        "output_path": {
          "type": "string",
          "description": "Path to save the spec file",
          "required": false,
          "default": "./specs/locust"
        }
      },
      "output_schema": {
        "spec_path": {
          "type": "string",
          "description": "Path to created spec file"
        },
        "success": {
          "type": "boolean",
          "description": "Whether spec creation succeeded"
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "b1dd68868da8e5ce2cf5d9dba73246ebe34cd0798f3dceb0a74cd8b3ac601c76",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300383Z"
    },
    "created_at": "2025-11-17T00:38:56.519374Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "b1dd68868da8e5ce2cf5d9dba73246ebe34cd0798f3dceb0a74cd8b3ac601c76",
    "breaking_changes": []
  },
  "locust_load_tester": {
    "tool_id": "locust_load_tester",
    "name": "Locust Load Test Generator",
    "tool_type": "executable",
    "description": "Generate and execute Locust performance/load tests from API specs, OpenAPI definitions, or BDD scenarios with plausible test data",
    "tags": [
      "testing",
      "load-testing",
      "performance",
      "locust",
      "api-testing",
      "stress-testing",
      "benchmarking",
      "characterization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\locust_load_tester.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/locust_load_tester.py"
      ],
      "input_schema": {
        "spec_file": {
          "type": "string",
          "description": "Path to API spec file (OpenAPI, JSON, or locustfile spec)",
          "required": false
        },
        "spec_content": {
          "type": "string",
          "description": "Inline spec content (if spec_file not provided)",
          "required": false
        },
        "static_analysis_path": {
          "type": "string",
          "description": "Path to static analysis results for plausible data generation",
          "required": false
        },
        "mode": {
          "type": "string",
          "description": "Mode: 'generate' (create locustfile), 'run' (execute tests), or 'both'",
          "required": false,
          "default": "both"
        },
        "output_path": {
          "type": "string",
          "description": "Directory where generated locustfile will be saved",
          "required": false,
          "default": "./locustfiles"
        },
        "users": {
          "type": "integer",
          "description": "Number of concurrent users to simulate",
          "required": false,
          "default": 10
        },
        "spawn_rate": {
          "type": "integer",
          "description": "Rate at which users are spawned (users per second)",
          "required": false,
          "default": 2
        },
        "run_time": {
          "type": "string",
          "description": "Test duration (e.g., '30s', '5m', '1h')",
          "required": false,
          "default": "30s"
        },
        "host": {
          "type": "string",
          "description": "Base URL for the API being tested",
          "required": false,
          "default": "http://localhost:8000"
        }
      },
      "output_schema": {
        "locustfile_path": {
          "type": "string",
          "description": "Path to generated locustfile"
        },
        "results": {
          "type": "object",
          "description": "Load test results (if executed)"
        },
        "stats": {
          "type": "object",
          "description": "Performance statistics (requests/sec, response times, etc.)"
        },
        "success": {
          "type": "boolean",
          "description": "Whether test generation/execution succeeded"
        }
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "fa23dffc04bf9b0e74b18baca765abd728cfd7dd1e1c9e0bee0c5486472d10b1",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300386Z"
    },
    "created_at": "2025-11-17T00:38:56.807759Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "fa23dffc04bf9b0e74b18baca765abd728cfd7dd1e1c9e0bee0c5486472d10b1",
    "breaking_changes": []
  },
  "parse_static_analysis": {
    "tool_id": "parse_static_analysis",
    "name": "Parse Static Analysis Results",
    "tool_type": "executable",
    "description": "Parse and aggregate static analysis results for test data generation and tool optimization",
    "tags": [
      "analysis",
      "static-analysis",
      "parsing",
      "quality-metrics",
      "test-data",
      "optimization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\parse_static_analysis.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/parse_static_analysis.py"
      ],
      "input_schema": {
        "analysis_file": {
          "type": "string",
          "description": "Path to static analysis JSON file",
          "required": false
        },
        "registry_path": {
          "type": "string",
          "description": "Path to registry directory with multiple analysis files",
          "required": false
        },
        "extract_schemas": {
          "type": "boolean",
          "description": "Extract JSON schemas from analysis for data generation",
          "required": false,
          "default": true
        },
        "extract_patterns": {
          "type": "boolean",
          "description": "Extract code patterns and common values",
          "required": false,
          "default": true
        }
      },
      "output_schema": {
        "schemas": {
          "type": "array",
          "description": "Extracted JSON schemas for data generation"
        },
        "patterns": {
          "type": "object",
          "description": "Common code patterns and values"
        },
        "quality_metrics": {
          "type": "object",
          "description": "Aggregated quality metrics"
        },
        "test_hints": {
          "type": "object",
          "description": "Hints for test data generation"
        },
        "success": {
          "type": "boolean",
          "description": "Whether parsing succeeded"
        }
      },
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "40d2c3541d3d2195cfb6ff140a1cece6a9279b5655d868c7d1cc932db71bf2f7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300395Z"
    },
    "created_at": "2025-11-17T00:38:57.017183Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "40d2c3541d3d2195cfb6ff140a1cece6a9279b5655d868c7d1cc932db71bf2f7",
    "breaking_changes": []
  },
  "platform_info": {
    "tool_id": "platform_info",
    "name": "Platform Information",
    "tool_type": "executable",
    "description": "Gathers comprehensive information about the underlying platform including OS, CPU, GPU, memory, disk, processes, and network. Enables decision-making based on platform characteristics like 'when running with low memory' or 'when running on Windows'. Supports multiple detail levels from basic to full.",
    "tags": [
      "platform",
      "system",
      "info",
      "monitoring",
      "cpu",
      "gpu",
      "memory",
      "diagnostic",
      "conditional"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\platform_info.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/platform_info.py"
      ],
      "input_schema": {
        "detail_level": {
          "type": "string",
          "description": "Level of detail to gather. Options: 'basic' (platform and minimal info), 'standard' (+ CPU, memory, disk, GPU), 'detailed' (+ usage stats), 'full' (everything including processes and network)",
          "required": false,
          "default": "standard",
          "enum": [
            "basic",
            "standard",
            "detailed",
            "full"
          ]
        },
        "include_processes": {
          "type": "boolean",
          "description": "Include information about running processes (top 10 by CPU and memory)",
          "required": false,
          "default": false
        },
        "include_network": {
          "type": "boolean",
          "description": "Include network interface information",
          "required": false,
          "default": false
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "timestamp": {
            "type": "string",
            "description": "ISO timestamp when information was gathered"
          },
          "detail_level": {
            "type": "string",
            "description": "The detail level that was used"
          },
          "platform": {
            "type": "object",
            "description": "Basic platform information (OS, architecture, hostname, etc.)"
          },
          "cpu": {
            "type": "object",
            "description": "CPU information (cores, frequency, usage)"
          },
          "memory": {
            "type": "object",
            "description": "Memory information (total, available, used, swap)"
          },
          "gpu": {
            "type": "object",
            "description": "GPU information (devices, memory, utilization)"
          },
          "disk": {
            "type": "object",
            "description": "Disk information (partitions, usage, I/O stats)"
          },
          "processes": {
            "type": "object",
            "description": "Running processes information (if requested)"
          },
          "network": {
            "type": "object",
            "description": "Network interface information (if requested)"
          },
          "summary": {
            "type": "object",
            "description": "Summary for decision making (platform_type, memory_status, has_gpu, etc.)"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "3e6f1b2aac46001abf480d209f502763bc0896eac8a5faac7cf395f99a9d7570",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300398Z"
    },
    "created_at": "2025-11-17T00:38:57.227864Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "3e6f1b2aac46001abf480d209f502763bc0896eac8a5faac7cf395f99a9d7570",
    "breaking_changes": []
  },
  "schedule_task": {
    "tool_id": "schedule_task",
    "name": "schedule_task",
    "tool_type": "executable",
    "description": "Schedule a task to run at specific times using cron expressions or natural language descriptions.\n\nThis tool is IMMUTABLE - scheduled tasks persist across sessions and run automatically\nin the background. Use this for polling events, periodic checks, or recurring operations.\n\nExamples:\n- \"Check for new emails every 5 minutes\"\n- \"Generate report every Sunday at noon\"\n- \"Backup data daily at 2am\"\n\nThe scheduler uses low priority execution to avoid interfering with active workflows.\n",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\schedule_task.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "a269b0f013cbe544ccc6511968cfcec546d88989ec7a9bde6bad2085fda255b2",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300402Z"
    },
    "created_at": "2025-11-17T00:38:57.499268Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "a269b0f013cbe544ccc6511968cfcec546d88989ec7a9bde6bad2085fda255b2",
    "breaking_changes": []
  },
  "write_incident_report_summary": {
    "tool_id": "write_incident_report_summary",
    "name": "Write incident report summary for quality issue",
    "tool_type": "workflow",
    "description": "Write incident report summary for quality issue",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_incident_report_summary",
      "quality_score": 1.2000000000000002,
      "latency_ms": 67,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T00:51:06.562810+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write incident report summary for quality issue",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300406Z"
    },
    "created_at": "2025-11-17T00:51:06.562840Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763340974": {
    "tool_id": "note_this_workflow_may_be_mul_1763340974",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about pinch points for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Run quick validation/tests and fix issues\n4. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about pinch points for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Run quick validation/tests and fix issues\n4. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763340974",
      "quality_score": 1.1,
      "latency_ms": 1147,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T00:57:11.169605+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about pinch points for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Run quick validation/tests and fix issues\n4. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300409Z"
    },
    "created_at": "2025-11-17T00:57:11.169630Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763341104": {
    "tool_id": "note_this_workflow_may_be_mul_1763341104",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Run quick validation/tests and fix issues",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Run quick validation/tests and fix issues",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763341104",
      "quality_score": 1.1,
      "latency_ms": 925,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T00:59:55.097021+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Run quick validation/tests and fix issues",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300413Z"
    },
    "created_at": "2025-11-17T00:59:55.097042Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "identify_the_safety_warning_te": {
    "tool_id": "identify_the_safety_warning_te",
    "name": "Identify the safety warning text",
    "tool_type": "workflow",
    "description": "Identify the safety warning text",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "identify_the_safety_warning_te",
      "quality_score": 1.1,
      "latency_ms": 882,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T01:02:19.707995+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Identify the safety warning text",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300416Z"
    },
    "created_at": "2025-11-17T01:02:19.708052Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_product_label_to": {
    "tool_id": "translate_the_product_label_to",
    "name": "Translate the product label to Spanish",
    "tool_type": "workflow",
    "description": "Translate the product label to Spanish",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_product_label_to",
      "quality_score": 1.1,
      "latency_ms": 995,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T01:59:56.117086+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translate the product label to Spanish",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300420Z"
    },
    "created_at": "2025-11-17T01:59:56.117103Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "conversation_manager": {
    "tool_id": "conversation_manager",
    "name": "conversation_manager",
    "tool_type": "executable",
    "description": "Manages intelligent conversations with multi-chat context memory, auto-summarization,\nand semantic search. Provides context-aware conversations that optimize for response\nspeed while maintaining accuracy.\n\nFeatures:\n- Multi-chat context memory (remembers previous conversations)\n- Auto-summarization based on context window size\n- Volatile Qdrant storage for semantic search\n- Related context retrieval from past conversations\n- Performance tracking (response time, tokens, etc.)\n- Intent detection (distinguishes conversation from dialogue generation)\n\nUse this tool for:\n- Starting/ending conversational sessions\n- Managing conversation context\n- Detecting user intent to converse\n- Retrieving related conversation history\n",
    "tags": [
      "conversation",
      "context-memory",
      "semantic-search",
      "summarization",
      "intent-detection",
      "qdrant"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\conversation_manager.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/conversation_manager.py"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "84cb4f195a7eb87b9b7db3e9a56849f6370b33a1da721f17399c0f03906190c0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300423Z"
    },
    "created_at": "2025-11-17T02:01:13.536751Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "84cb4f195a7eb87b9b7db3e9a56849f6370b33a1da721f17399c0f03906190c0",
    "breaking_changes": []
  },
  "cron_deconstructor": {
    "tool_id": "cron_deconstructor",
    "name": "cron_deconstructor",
    "tool_type": "executable",
    "description": "Deconstructs cron expressions into rich structured metadata for semantic embedding.\n\nThis tool analyzes a cron expression and generates detailed metadata including:\n- Human-readable description\n- Frequency classification (daily, weekly, monthly, etc.)\n- Time of day categorization (morning, afternoon, evening, night)\n- Day names (Monday, Tuesday, etc.)\n- Next scheduled run times\n- Semantic tags for RAG embedding\n- Inferred task grouping (reports, backups, monitoring, etc.)\n\nThe structured output is designed to be embedded in RAG storage for better\nsemantic search and grouping of scheduled tasks.\n",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\cron_deconstructor.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/cron_deconstructor.py"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "f3be829b53a8f3d62eb3fd09cd4fbf84ce3ea77ae18bc08343f5e0256d924d7e",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300427Z"
    },
    "created_at": "2025-11-17T02:01:13.548173Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "f3be829b53a8f3d62eb3fd09cd4fbf84ce3ea77ae18bc08343f5e0256d924d7e",
    "breaking_changes": []
  },
  "cron_querier": {
    "tool_id": "cron_querier",
    "name": "cron_querier",
    "tool_type": "executable",
    "description": "Converts natural language queries about scheduled tasks into structured search filters.\n\nThis tool enables intuitive querying of scheduled tasks using plain English instead\nof complex filter syntax. It parses queries to extract:\n- Task groups (reports, backups, monitoring, etc.)\n- Frequency (daily, weekly, hourly, etc.)\n- Time windows (\"next 3 hours\", \"tonight\", \"tomorrow\")\n- Time of day (morning, afternoon, evening, night)\n- Day names (Monday, Tuesday, etc.)\n\nThe structured output can be used directly with the task search system.\n",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\cron_querier.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/cron_querier.py"
      ],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "22c9cc069e12f70eedec803c6689189f2624d7dfa333a4100b9fc778acb5d8f3",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300431Z"
    },
    "created_at": "2025-11-17T02:01:13.554693Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "22c9cc069e12f70eedec803c6689189f2624d7dfa333a4100b9fc778acb5d8f3",
    "breaking_changes": []
  },
  "optimize_cluster": {
    "tool_id": "optimize_cluster",
    "name": "Optimize Cluster",
    "tool_type": "executable",
    "description": "Optimize RAG artifact clusters using iterative self-optimization loop. Can optimize specific workflows, functions, prompts, or entire node types. Supports conversational usage: 'optimize this workflow' or CLI: '/optimize workflow_name'",
    "tags": [],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\optimize_cluster.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "de4cdb75b2f4991ee71cdf9bb9c689e74ada7d6b57cde3002a552479fb437b50",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300436Z"
    },
    "created_at": "2025-11-17T02:01:13.610702Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "de4cdb75b2f4991ee71cdf9bb9c689e74ada7d6b57cde3002a552479fb437b50",
    "breaking_changes": []
  },
  "smart_faker": {
    "tool_id": "smart_faker",
    "name": "Smart Faker",
    "tool_type": "executable",
    "description": "Intelligent fake data generator that accepts plain English, code, JSON schemas, or any LLM-interpretable input. Supports multiple output formats including streaming, arrays, and CSV.",
    "tags": [
      "testing",
      "data-generation",
      "faker",
      "llm",
      "flexible",
      "smart",
      "csv",
      "streaming"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\smart_faker.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/smart_faker.py"
      ],
      "input_schema": {
        "prompt": {
          "type": "string",
          "description": "Plain English description of data to generate, OR JSON schema, OR code snippet, OR JSON file content - anything describable",
          "required": true
        },
        "count": {
          "type": "integer",
          "description": "Number of items to generate (default: 1)",
          "required": false,
          "default": 1
        },
        "output_format": {
          "type": "string",
          "description": "Output format: 'json' (default), 'csv', 'jsonl' (JSON Lines for streaming), or 'array'",
          "required": false,
          "default": "json",
          "enum": [
            "json",
            "csv",
            "jsonl",
            "array"
          ]
        },
        "stream": {
          "type": "boolean",
          "description": "If true, output items one at a time (for large datasets). Only works with jsonl format.",
          "required": false,
          "default": false
        },
        "seed": {
          "type": "integer",
          "description": "Random seed for reproducible data generation",
          "required": false
        },
        "llm_model": {
          "type": "string",
          "description": "LLM model to use for interpretation (default: gemma2:2b)",
          "required": false,
          "default": "gemma2:2b"
        },
        "additional_context": {
          "type": "string",
          "description": "Additional context or constraints for data generation",
          "required": false,
          "default": ""
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether generation succeeded"
          },
          "data": {
            "description": "Generated data in requested format"
          },
          "format": {
            "type": "string",
            "description": "Output format used"
          },
          "count": {
            "type": "integer",
            "description": "Number of items generated"
          },
          "schema": {
            "type": "object",
            "description": "Inferred schema used for generation"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "fc41f530847458b0a132e7ff68c8f7c3dd0af9d1b26efeb376a84c175d3901a0",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300441Z"
    },
    "created_at": "2025-11-17T02:01:13.659419Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "fc41f530847458b0a132e7ff68c8f7c3dd0af9d1b26efeb376a84c175d3901a0",
    "breaking_changes": []
  },
  "rag_cluster_optimizer": {
    "tool_id": "rag_cluster_optimizer",
    "name": "RAG Cluster Optimizer",
    "tool_type": "llm",
    "description": "Iterative self-optimization loop for artifact clusters. Explores variants, generates candidates, validates them through tests and benchmarks, and promotes fitter implementations while preserving lineage. The system learns patterns and converges toward high-fitness implementations over time.",
    "tags": [
      "optimization",
      "rag",
      "clustering",
      "self-improvement",
      "evolution",
      "fitness",
      "variants"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\rag_cluster_optimizer.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": "You are the RAG Cluster Optimizer - a system that performs iterative self-optimization\non artifact clusters. Your role is to evolve code artifacts toward higher fitness by\nexploring variants, learning patterns, and making intelligent optimization decisions.\n\n🧠 CORE CONCEPT: ITERATIVE SELF-OPTIMIZATION LOOP\n\nInstead of just picking one \"best\" version, you move outward from the core function,\ntesting alternates, folding in their performance data, and converging toward a fitter\ncanonical artifact.\n\nWORKFLOW PHASES:\n\nPHASE 1: CORE FUNCTION ANCHOR\n1. Identify current \"best\" implementation (canonical artifact)\n2. Treat it as the root of the optimization tree\n3. Establish baseline fitness metrics\n\nPHASE 2: ALTERNATE EXPLORATION\n1. Pull all close variants (≥0.96 similarity cluster)\n2. Extract semantic deltas:\n   - Algorithm tweaks\n   - Error handling improvements\n   - Refactoring patterns\n   - Performance optimizations\n3. Analyze perf data + usage stats for each alternate\n\nPHASE 3: ITERATION LOOP (REPEAT UP TO MAX_ITERATIONS)\n\nStep 1: GENERATE CANDIDATE\n- Combine alternates + perf insights\n- Apply learned patterns\n- Use strategy: BEST_OF_BREED, INCREMENTAL, RADICAL, or HYBRID\n- Create new candidate variant\n\nStep 2: VALIDATE CANDIDATE\n- Run functional tests\n- Execute performance benchmarks\n- Perform mutation tests\n- Measure fitness score\n\nStep 3: COMPARE FITNESS\n- Compare candidate fitness vs canonical fitness\n- Compare against cluster median\n- Calculate improvement delta\n\nStep 4: PROMOTE IF FITTER\n- If fitness improvement > threshold:\n  * Archive old canonical (preserve lineage)\n  * Promote candidate to new canonical\n  * Archive weak variants (fitness < candidate - 0.1)\n  * Update parent-child relationships\n- Else:\n  * Keep current canonical\n  * Stop iteration if no improvement\n\nStep 5: EXPAND OUTWARD\n- If promoted: explore next layer of alternates\n- If not promoted: stop iterations\n- Re-run loop with updated cluster\n\nPHASE 4: SELF-OPTIMIZATION & LEARNING\n1. Learn patterns from successful promotions:\n   - \"error handling improvements reduce latency spikes\"\n   - \"hack-style obfuscations correlate with regressions\"\n   - \"algorithm optimizations improve memory usage\"\n2. Store learned patterns in cluster metadata\n3. Use patterns to prioritize future deltas\n4. Track optimization history\n\n🧭 GUILD ANALOGY:\nYou're like a guild master refining a ritual: start with the core chant, then test\nvariations from apprentices. Each cycle, keep the strongest elements, discard the weak,\nand the ritual evolves. Over time, the guild's library becomes a living lineage of\never-stronger spells.\n\n⚡ EXAMPLE FLOW:\n\nCore function: Cron parser v1\nAlternates:\n- v1.1 (better error handling)\n- v1.2 (faster regex)\n- v1.3 (memory-optimized)\n\nIteration 1:\n1. Generate v2 by combining regex speed + error handling robustness\n2. Validate → coverage +5%, latency −12%\n3. Promote v2 as canonical\n4. Archive v1.x variants with lineage pointers\n\nIteration 2:\n1. Explore v2's cluster for further refinements\n2. Generate v2.1 with memory optimizations\n3. Validate → memory −8%, success rate +2%\n4. Promote v2.1 as canonical\n\nOUTPUT FORMAT:\n```\n## RAG Cluster Optimization Report\n\n### Cluster: {cluster_id}\n- Status: {completed|no_iterations|stopped_early}\n- Total Iterations: {N}\n- Total Promotions: {M}\n- Total Archived: {P}\n\n### Summary\n- Initial Fitness: {X.XXX}\n- Final Fitness: {Y.XXY}\n- Total Improvement: {+Z.Z%}\n\n### Optimization Strategy\n- Strategy: {BEST_OF_BREED|INCREMENTAL|RADICAL|HYBRID}\n- Similarity Threshold: {0.96}\n- Fitness Improvement Threshold: {0.05}\n\n### Iterations\n\n#### Iteration 1\n- Candidate: {variant_id}\n- Fitness: {X.XXX}\n- Promoted: {Yes/No}\n- Insights:\n  * {insight 1}\n  * {insight 2}\n\n#### Iteration 2\n...\n\n### Learned Patterns\n- error_handling: Average improvement +{X.X%} ({N} samples)\n- algorithm: Average improvement +{Y.Y%} ({M} samples)\n\n### Final Canonical Variant\n- Variant ID: {variant_id}\n- Version: {version}\n- Fitness: {X.XXX}\n- Performance:\n  * Latency: {X.XX}ms\n  * Memory: {Y.YY}MB\n  * Success Rate: {Z.ZZ%}\n  * Test Coverage: {W.WW%}\n\n### Cluster Statistics\n- Total Variants: {N}\n- Active Variants: {M}\n- Archived Variants: {P}\n- Median Fitness: {X.XXX}\n\n### Lineage Tree\nv1 → v2 → v2.1 (current canonical)\n ├─ v1.1 (archived)\n ├─ v1.2 (archived)\n └─ v1.3 (archived)\n```\n",
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "32a5a40941939b105f6eb5631e8f172aae5d7d0401003406f2ffb0c9e4942886",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300445Z"
    },
    "created_at": "2025-11-17T02:01:13.709755Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "32a5a40941939b105f6eb5631e8f172aae5d7d0401003406f2ffb0c9e4942886",
    "breaking_changes": []
  },
  "aggregate_daily_production_by": {
    "tool_id": "aggregate_daily_production_by",
    "name": "Aggregate daily production by line: [{\"line\": 1, \"output\": 1152}, {\"line\": 2, \"output\": 770}, {\"line\": 3, \"output\": 746}, {\"line\": 4, \"output\": 607}] and rank by efficiency",
    "tool_type": "workflow",
    "description": "Aggregate daily production by line: [{\"line\": 1, \"output\": 1152}, {\"line\": 2, \"output\": 770}, {\"line\": 3, \"output\": 746}, {\"line\": 4, \"output\": 607}] and rank by efficiency",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "aggregate_daily_production_by",
      "quality_score": 1.1,
      "latency_ms": 919,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T02:08:33.381316+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Aggregate daily production by line: [{\"line\": 1, \"output\": 1152}, {\"line\": 2, \"output\": 770}, {\"line\": 3, \"output\": 746}, {\"line\": 4, \"output\": 607}] and rank by efficiency",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300449Z"
    },
    "created_at": "2025-11-17T02:08:33.381337Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_safety_notice_about_ch": {
    "tool_id": "write_a_safety_notice_about_ch",
    "name": "Write a safety notice about chemical spills for factory floor bulletin board",
    "tool_type": "workflow",
    "description": "Write a safety notice about chemical spills for factory floor bulletin board",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_safety_notice_about_ch",
      "quality_score": 1.1,
      "latency_ms": 868,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T02:12:13.663948+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a safety notice about chemical spills for factory floor bulletin board",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300453Z"
    },
    "created_at": "2025-11-17T02:12:13.663970Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_machine_utilization": {
    "tool_id": "calculate_machine_utilization",
    "name": "Calculate machine utilization: 502 hours used / 720 hours available",
    "tool_type": "workflow",
    "description": "Calculate machine utilization: 502 hours used / 720 hours available",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_machine_utilization",
      "quality_score": 1.1,
      "latency_ms": 937,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T02:25:32.423207+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculate machine utilization: 502 hours used / 720 hours available",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300456Z"
    },
    "created_at": "2025-11-17T02:25:32.423226Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "remove_unused_node_runtime_import": {
    "tool_id": "remove_unused_node_runtime_import",
    "name": "Remove Unused node_runtime Import",
    "tool_type": "executable",
    "description": "Detects and removes unused 'from node_runtime import call_tool' imports and related\npath setup code when call_tool is not actually used in the code.\n\nThis fixes the common error where generated code imports node_runtime but never calls\nany tools, causing ModuleNotFoundError in tests.\n\nThe tool:\n- Checks if call_tool() is actually called in the code\n- If NOT used, removes:\n  * from node_runtime import call_tool\n  * from pathlib import Path (if only for node_runtime)\n  * sys.path.insert(...) for node_runtime\n  * import logging (if only added by repair system)\n  * logging.basicConfig(...)\n  * logging.debug(...) calls\n  * try/except wrappers added by repair system\n- If used, keeps everything intact\n",
    "tags": [
      "code-cleanup",
      "import",
      "node_runtime",
      "unused",
      "static-analysis",
      "autofix"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\remove_unused_node_runtime_import.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/remove_unused_node_runtime_import.py"
      ],
      "input_schema": {
        "code": {
          "type": "string",
          "required": true,
          "description": "Python source code to analyze and clean"
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether the operation succeeded"
          },
          "original_code": {
            "type": "string",
            "description": "The original input code"
          },
          "cleaned_code": {
            "type": "string",
            "description": "The cleaned code with unused imports removed"
          },
          "changes": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "List of changes made"
          },
          "was_modified": {
            "type": "boolean",
            "description": "Whether any changes were made"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "version": "1.0.0",
      "definition_hash": "77fbca0319c92b77b8850d10daa732b9d90efb11b5b9925e25266240e0c9c453",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300460Z"
    },
    "created_at": "2025-11-17T02:43:19.957840Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "77fbca0319c92b77b8850d10daa732b9d90efb11b5b9925e25266240e0c9c453",
    "breaking_changes": []
  },
  "process_production_metrics_fro": {
    "tool_id": "process_production_metrics_fro",
    "name": "Process production metrics from shift report: {\"line_1\": 1158, \"line_2\": 730} and generate summary statistics",
    "tool_type": "workflow",
    "description": "Process production metrics from shift report: {\"line_1\": 1158, \"line_2\": 730} and generate summary statistics",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "process_production_metrics_fro",
      "quality_score": 1.2000000000000002,
      "latency_ms": 54,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T02:59:48.804478+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Process production metrics from shift report: {\"line_1\": 1158, \"line_2\": 730} and generate summary statistics",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300463Z"
    },
    "created_at": "2025-11-17T02:59:48.804498Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763348473": {
    "tool_id": "note_this_workflow_may_be_mul_1763348473",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 908, \"line_2\": 983} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 908, \"line_2\": 983} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763348473",
      "quality_score": 1.2000000000000002,
      "latency_ms": 43,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T03:03:34.975647+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 908, \"line_2\": 983} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300467Z"
    },
    "created_at": "2025-11-17T03:03:34.975666Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "determine_labor_cost_44_worke": {
    "tool_id": "determine_labor_cost_44_worke",
    "name": "Determine labor cost: 44 workers × 24 hours × $17/hour",
    "tool_type": "workflow",
    "description": "Determine labor cost: 44 workers × 24 hours × $17/hour",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "determine_labor_cost_44_worke",
      "quality_score": 1.2000000000000002,
      "latency_ms": 48,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T03:12:49.892450+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Determine labor cost: 44 workers × 24 hours × $17/hour",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300470Z"
    },
    "created_at": "2025-11-17T03:12:49.892467Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_incident_report_summary_1763349262": {
    "tool_id": "write_incident_report_summary_1763349262",
    "name": "Write incident report summary for near miss",
    "tool_type": "workflow",
    "description": "Write incident report summary for near miss",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_incident_report_summary_1763349262",
      "quality_score": 1.1,
      "latency_ms": 1614,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T03:16:24.099813+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write incident report summary for near miss",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300474Z"
    },
    "created_at": "2025-11-17T03:16:24.099833Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_safety_notice_about_pi": {
    "tool_id": "write_a_safety_notice_about_pi",
    "name": "Write a safety notice about pinch points for factory floor bulletin board",
    "tool_type": "workflow",
    "description": "Write a safety notice about pinch points for factory floor bulletin board",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_safety_notice_about_pi",
      "quality_score": 1.1,
      "latency_ms": 894,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T03:28:03.846705+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a safety notice about pinch points for factory floor bulletin board",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300477Z"
    },
    "created_at": "2025-11-17T03:28:03.846725Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "what_is_the_proper_lockout_tag": {
    "tool_id": "what_is_the_proper_lockout_tag",
    "name": "What is the proper lockout/tagout procedure for forklift?",
    "tool_type": "workflow",
    "description": "What is the proper lockout/tagout procedure for forklift?",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "what_is_the_proper_lockout_tag",
      "quality_score": 1.1,
      "latency_ms": 837,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T03:42:55.443220+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "What is the proper lockout/tagout procedure for forklift?",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300481Z"
    },
    "created_at": "2025-11-17T03:42:55.443249Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "draft_announcement_for_new_saf": {
    "tool_id": "draft_announcement_for_new_saf",
    "name": "Draft announcement for new safety policy implementation",
    "tool_type": "workflow",
    "description": "Draft announcement for new safety policy implementation",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "draft_announcement_for_new_saf",
      "quality_score": 1.1,
      "latency_ms": 891,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T04:09:12.761241+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Draft announcement for new safety policy implementation",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300484Z"
    },
    "created_at": "2025-11-17T04:09:12.761259Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763352827": {
    "tool_id": "note_this_workflow_may_be_mul_1763352827",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Compute inventory levels: starting 3894 units, produced 379, shipped 325\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Compute inventory levels: starting 3894 units, produced 379, shipped 325\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763352827",
      "quality_score": 1.2000000000000002,
      "latency_ms": 45,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T04:16:08.569015+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Compute inventory levels: starting 3894 units, produced 379, shipped 325\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300487Z"
    },
    "created_at": "2025-11-17T04:16:08.569034Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763353061": {
    "tool_id": "note_this_workflow_may_be_mul_1763353061",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create automation script to monitor temperature and alert if exceeds 4\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create automation script to monitor temperature and alert if exceeds 4\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763353061",
      "quality_score": 1.1,
      "latency_ms": 877,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T04:24:30.592741+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create automation script to monitor temperature and alert if exceeds 4\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300491Z"
    },
    "created_at": "2025-11-17T04:24:30.592758Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_shift_log_entry_for_swi": {
    "tool_id": "create_shift_log_entry_for_swi",
    "name": "Create shift log entry for Swing shift on 2025-11-17 with 9 events",
    "tool_type": "workflow",
    "description": "Create shift log entry for Swing shift on 2025-11-17 with 9 events",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_shift_log_entry_for_swi",
      "quality_score": 1.1,
      "latency_ms": 930,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T04:30:31.083547+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create shift log entry for Swing shift on 2025-11-17 with 9 events",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300494Z"
    },
    "created_at": "2025-11-17T04:30:31.083564Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763354130": {
    "tool_id": "note_this_workflow_may_be_mul_1763354130",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create shift log entry for Swing shift on 2025-11-17 with 4 events\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create shift log entry for Swing shift on 2025-11-17 with 4 events\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763354130",
      "quality_score": 1.2000000000000002,
      "latency_ms": 46,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T04:36:53.081521+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Create shift log entry for Swing shift on 2025-11-17 with 4 events\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300498Z"
    },
    "created_at": "2025-11-17T04:36:53.081537Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763354290": {
    "tool_id": "note_this_workflow_may_be_mul_1763354290",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 1161 units produced from 1136 raw materials (percentage)\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 1161 units produced from 1136 raw materials (percentage)\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763354290",
      "quality_score": 1.2000000000000002,
      "latency_ms": 41,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T04:39:23.751201+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 1161 units produced from 1136 raw materials (percentage)\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Analyze requirements and clarify constraints\n3. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300501Z"
    },
    "created_at": "2025-11-17T04:39:23.751217Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_training_material_intro": {
    "tool_id": "create_training_material_intro",
    "name": "Create training material introduction for new press machine operators",
    "tool_type": "workflow",
    "description": "Create training material introduction for new press machine operators",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_training_material_intro",
      "quality_score": 1.1,
      "latency_ms": 1046,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T04:48:59.559227+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create training material introduction for new press machine operators",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300504Z"
    },
    "created_at": "2025-11-17T04:48:59.559249Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "compute_inventory_levels_star": {
    "tool_id": "compute_inventory_levels_star",
    "name": "Compute inventory levels: starting 1873 units, produced 238, shipped 101",
    "tool_type": "workflow",
    "description": "Compute inventory levels: starting 1873 units, produced 238, shipped 101",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "compute_inventory_levels_star",
      "quality_score": 1.1,
      "latency_ms": 872,
      "memory_mb_peak": 1.94,
      "created_at": "2025-11-17T04:55:16.638547+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Compute inventory levels: starting 1873 units, produced 238, shipped 101",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300508Z"
    },
    "created_at": "2025-11-17T04:55:16.638562Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763355521": {
    "tool_id": "note_this_workflow_may_be_mul_1763355521",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write function to calculate OEE (Overall Equipment Effectiveness) from availability, performance, quality metrics\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test\n3. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write function to calculate OEE (Overall Equipment Effectiveness) from availability, performance, quality metrics\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test\n3. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763355521",
      "quality_score": 1.1,
      "latency_ms": 984,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T05:01:49.442314+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write function to calculate OEE (Overall Equipment Effectiveness) from availability, performance, quality metrics\n\nStages:\n1. Plan the approach and outline solution\n2. Run example and test\n3. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300511Z"
    },
    "created_at": "2025-11-17T05:01:49.442342Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763356097": {
    "tool_id": "note_this_workflow_may_be_mul_1763356097",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Draft announcement for new environmental policy implementation\n\nStages:\n1. Plan the approach and outline solution\n2. Brainstorm ideas\n3. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Draft announcement for new environmental policy implementation\n\nStages:\n1. Plan the approach and outline solution\n2. Brainstorm ideas\n3. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763356097",
      "quality_score": 1.1,
      "latency_ms": 974,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T05:09:10.754321+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Draft announcement for new environmental policy implementation\n\nStages:\n1. Plan the approach and outline solution\n2. Brainstorm ideas\n3. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300516Z"
    },
    "created_at": "2025-11-17T05:09:10.754336Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "convert_the_numeric_value_to_m": {
    "tool_id": "convert_the_numeric_value_to_m",
    "name": "Convert the numeric value to meters",
    "tool_type": "workflow",
    "description": "Convert the numeric value to meters",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "convert_the_numeric_value_to_m",
      "quality_score": 1.1,
      "latency_ms": 854,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T05:38:47.388781+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Convert the numeric value to meters",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300519Z"
    },
    "created_at": "2025-11-17T05:38:47.388798Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_total_production_for": {
    "tool_id": "calculate_total_production_for",
    "name": "Calculate total production for 2327 units at 150 units/hour over 12 hours",
    "tool_type": "workflow",
    "description": "Calculate total production for 2327 units at 150 units/hour over 12 hours",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_total_production_for",
      "quality_score": 1.2000000000000002,
      "latency_ms": 49,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T05:41:09.183060+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculate total production for 2327 units at 150 units/hour over 12 hours",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300524Z"
    },
    "created_at": "2025-11-17T05:41:09.183086Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763358158": {
    "tool_id": "note_this_workflow_may_be_mul_1763358158",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Design API/logic\n2. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Design API/logic\n2. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763358158",
      "quality_score": 1.1,
      "latency_ms": 944,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T05:49:10.690619+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Design API/logic\n2. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300527Z"
    },
    "created_at": "2025-11-17T05:49:10.690635Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "identify_the_operations_in_the": {
    "tool_id": "identify_the_operations_in_the",
    "name": "Identify the operations in the task",
    "tool_type": "workflow",
    "description": "Identify the operations in the task",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "identify_the_operations_in_the",
      "quality_score": 1.1,
      "latency_ms": 819,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T05:58:47.567838+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Identify the operations in the task",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300531Z"
    },
    "created_at": "2025-11-17T05:58:47.567855Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "count_the_number_of_distinct_o": {
    "tool_id": "count_the_number_of_distinct_o",
    "name": "Count the number of distinct operations in the task",
    "tool_type": "workflow",
    "description": "Count the number of distinct operations in the task",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "count_the_number_of_distinct_o",
      "quality_score": 1.1,
      "latency_ms": 865,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:03:46.677807+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Count the number of distinct operations in the task",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300534Z"
    },
    "created_at": "2025-11-17T06:03:46.677831Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763359687": {
    "tool_id": "note_this_workflow_may_be_mul_1763359687",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format inventory table with columns: SKU, Description, Quantity, Location, Status\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Plan the approach and outline solution\n4. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format inventory table with columns: SKU, Description, Quantity, Location, Status\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Plan the approach and outline solution\n4. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763359687",
      "quality_score": 1.1,
      "latency_ms": 988,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:12:10.021246+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format inventory table with columns: SKU, Description, Quantity, Location, Status\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements\n3. Plan the approach and outline solution\n4. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300539Z"
    },
    "created_at": "2025-11-17T06:12:10.021269Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_training_material_intro_1763360014": {
    "tool_id": "create_training_material_intro_1763360014",
    "name": "Create training material introduction for new press machine operators",
    "tool_type": "workflow",
    "description": "Create training material introduction for new press machine operators",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_training_material_intro_1763360014",
      "quality_score": 1.1,
      "latency_ms": 893,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:15:21.982176+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create training material introduction for new press machine operators",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300542Z"
    },
    "created_at": "2025-11-17T06:15:21.982195Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763360512": {
    "tool_id": "note_this_workflow_may_be_mul_1763360512",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about falling objects for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Document results and assumptions\n4. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about falling objects for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Document results and assumptions\n4. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763360512",
      "quality_score": 1.1,
      "latency_ms": 871,
      "memory_mb_peak": 1.94,
      "created_at": "2025-11-17T06:22:57.460834+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write a safety notice about falling objects for factory floor bulletin board\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Document results and assumptions\n4. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300545Z"
    },
    "created_at": "2025-11-17T06:22:57.460855Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763360668": {
    "tool_id": "note_this_workflow_may_be_mul_1763360668",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763360668",
      "quality_score": 1.1,
      "latency_ms": 908,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:34:06.435071+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate state machine for assembly line with states: idle, loading, processing, unloading, error\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300549Z"
    },
    "created_at": "2025-11-17T06:34:06.435092Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763361323": {
    "tool_id": "note_this_workflow_may_be_mul_1763361323",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 337°F to Celsius for oven temperature specification\n\nStages:\n1. Identify units\n2. Identify units\n3. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 337°F to Celsius for oven temperature specification\n\nStages:\n1. Identify units\n2. Identify units\n3. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763361323",
      "quality_score": 1.1,
      "latency_ms": 814,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:36:16.533938+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 337°F to Celsius for oven temperature specification\n\nStages:\n1. Identify units\n2. Identify units\n3. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300552Z"
    },
    "created_at": "2025-11-17T06:36:16.533953Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "aggregate_daily_production_by_1763361729": {
    "tool_id": "aggregate_daily_production_by_1763361729",
    "name": "Aggregate daily production by line: [{}]",
    "tool_type": "workflow",
    "description": "Aggregate daily production by line: [{}]",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "aggregate_daily_production_by_1763361729",
      "quality_score": 1.1,
      "latency_ms": 803,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:46:35.472402+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Aggregate daily production by line: [{}]",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300556Z"
    },
    "created_at": "2025-11-17T06:46:35.472419Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763362212": {
    "tool_id": "note_this_workflow_may_be_mul_1763362212",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 806 units produced from 1346 raw materials (percentage)\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Verify computations",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 806 units produced from 1346 raw materials (percentage)\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Verify computations",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763362212",
      "quality_score": 1.2000000000000002,
      "latency_ms": 47,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T06:57:23.474650+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Calculate efficiency: 806 units produced from 1346 raw materials (percentage)\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Verify computations",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300559Z"
    },
    "created_at": "2025-11-17T06:57:23.474669Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763363759": {
    "tool_id": "note_this_workflow_may_be_mul_1763363759",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 1154, Efficiency: 97%\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 1154, Efficiency: 97%\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763363759",
      "quality_score": 1.2000000000000002,
      "latency_ms": 48,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T07:19:28.135934+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 1154, Efficiency: 97%\n\nStages:\n1. Plan the approach and outline solution\n2. Plan the approach and outline solution\n3. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300563Z"
    },
    "created_at": "2025-11-17T07:19:28.135956Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "draft_announcement_for_new_qua": {
    "tool_id": "draft_announcement_for_new_qua",
    "name": "Draft announcement for new quality policy implementation",
    "tool_type": "workflow",
    "description": "Draft announcement for new quality policy implementation",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "draft_announcement_for_new_qua",
      "quality_score": 1.1,
      "latency_ms": 955,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T07:27:54.821002+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Draft announcement for new quality policy implementation",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300566Z"
    },
    "created_at": "2025-11-17T07:27:54.821020Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763364799": {
    "tool_id": "note_this_workflow_may_be_mul_1763364799",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write incident report summary for minor injury\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write incident report summary for minor injury\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763364799",
      "quality_score": 1.2000000000000002,
      "latency_ms": 42,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T07:36:21.626747+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Write incident report summary for minor injury\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300570Z"
    },
    "created_at": "2025-11-17T07:36:21.626770Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "how_should_operators_respond_t_1763365255": {
    "tool_id": "how_should_operators_respond_t_1763365255",
    "name": "How should operators respond to quality alarm?",
    "tool_type": "workflow",
    "description": "How should operators respond to quality alarm?",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "how_should_operators_respond_t_1763365255",
      "quality_score": 1.2000000000000002,
      "latency_ms": 44,
      "memory_mb_peak": 2.03,
      "created_at": "2025-11-17T07:41:50.257734+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "How should operators respond to quality alarm?",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300573Z"
    },
    "created_at": "2025-11-17T07:41:50.257749Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "transform_sensor_readings_380": {
    "tool_id": "transform_sensor_readings_380",
    "name": "Transform sensor readings [380, 404, 248, 1010, 617, 723, 589, 427, 599, 292] to normalized 0-100 scale",
    "tool_type": "workflow",
    "description": "Transform sensor readings [380, 404, 248, 1010, 617, 723, 589, 427, 599, 292] to normalized 0-100 scale",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "transform_sensor_readings_380",
      "quality_score": 1.2000000000000002,
      "latency_ms": 43,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T07:46:26.725587+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Transform sensor readings [380, 404, 248, 1010, 617, 723, 589, 427, 599, 292] to normalized 0-100 scale",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300577Z"
    },
    "created_at": "2025-11-17T07:46:26.725606Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "draft_announcement_for_new_qua_1763365912": {
    "tool_id": "draft_announcement_for_new_qua_1763365912",
    "name": "Draft announcement for new quality policy implementation",
    "tool_type": "workflow",
    "description": "Draft announcement for new quality policy implementation",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "draft_announcement_for_new_qua_1763365912",
      "quality_score": 1.1,
      "latency_ms": 901,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T07:53:41.948118+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Draft announcement for new quality policy implementation",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300580Z"
    },
    "created_at": "2025-11-17T07:53:41.948140Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "identify_operations_in_the_tas": {
    "tool_id": "identify_operations_in_the_tas",
    "name": "Identify operations in the task",
    "tool_type": "workflow",
    "description": "Identify operations in the task",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "identify_operations_in_the_tas",
      "quality_score": 1.2000000000000002,
      "latency_ms": 42,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T08:13:14.546452+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Identify operations in the task",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300584Z"
    },
    "created_at": "2025-11-17T08:13:14.546483Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_machine_utilization_1763367763": {
    "tool_id": "calculate_machine_utilization_1763367763",
    "name": "Calculate machine utilization: 670 hours used / 720 hours available",
    "tool_type": "workflow",
    "description": "Calculate machine utilization: 670 hours used / 720 hours available",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_machine_utilization_1763367763",
      "quality_score": 1.2000000000000002,
      "latency_ms": 41,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T08:24:17.437141+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculate machine utilization: 670 hours used / 720 hours available",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300587Z"
    },
    "created_at": "2025-11-17T08:24:17.437156Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763367963": {
    "tool_id": "note_this_workflow_may_be_mul_1763367963",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 4413 pounds to kilograms for shipping documentation\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 4413 pounds to kilograms for shipping documentation\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763367963",
      "quality_score": 1.2000000000000002,
      "latency_ms": 46,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T08:26:56.768424+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 4413 pounds to kilograms for shipping documentation\n\nStages:\n1. Plan the approach and outline solution\n2. Reflect and propose improvements",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300592Z"
    },
    "created_at": "2025-11-17T08:26:56.768446Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "generate_state_machine_for_ass": {
    "tool_id": "generate_state_machine_for_ass",
    "name": "Generate state machine for assembly line with states: idle, loading, processing, unloading, error",
    "tool_type": "workflow",
    "description": "Generate state machine for assembly line with states: idle, loading, processing, unloading, error",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "generate_state_machine_for_ass",
      "quality_score": 1.1,
      "latency_ms": 982,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T08:38:28.375457+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Generate state machine for assembly line with states: idle, loading, processing, unloading, error",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300596Z"
    },
    "created_at": "2025-11-17T08:38:28.375475Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763368827": {
    "tool_id": "note_this_workflow_may_be_mul_1763368827",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate Python script to parse production log format: timestamp|line_id|product_id|quantity|status\n\nStages:\n1. Design API/logic\n2. Run example and test\n3. Plan the approach and outline solution\n4. Run example and test",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate Python script to parse production log format: timestamp|line_id|product_id|quantity|status\n\nStages:\n1. Design API/logic\n2. Run example and test\n3. Plan the approach and outline solution\n4. Run example and test",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763368827",
      "quality_score": 1.2000000000000002,
      "latency_ms": 49,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T08:43:28.639526+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Generate Python script to parse production log format: timestamp|line_id|product_id|quantity|status\n\nStages:\n1. Design API/logic\n2. Run example and test\n3. Plan the approach and outline solution\n4. Run example and test",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300600Z"
    },
    "created_at": "2025-11-17T08:43:28.639559Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763369117": {
    "tool_id": "note_this_workflow_may_be_mul_1763369117",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 365 RPM to rad/s for motor control calculations\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Double-check results\n3. Document results and assumptions",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 365 RPM to rad/s for motor control calculations\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Double-check results\n3. Document results and assumptions",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763369117",
      "quality_score": 1.2000000000000002,
      "latency_ms": 48,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T08:46:02.217884+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Convert 365 RPM to rad/s for motor control calculations\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Double-check results\n3. Document results and assumptions",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300603Z"
    },
    "created_at": "2025-11-17T08:46:02.217903Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "aggregate_daily_production_by_1763369310": {
    "tool_id": "aggregate_daily_production_by_1763369310",
    "name": "Aggregate daily production by line: [{\"line\": 1, \"output\": 551}, {\"line\": 2, \"output\": 913}, {\"line\": 3, \"output\": 795}, {\"line\": 4, \"output\": 1121}] and rank by efficiency",
    "tool_type": "workflow",
    "description": "Aggregate daily production by line: [{\"line\": 1, \"output\": 551}, {\"line\": 2, \"output\": 913}, {\"line\": 3, \"output\": 795}, {\"line\": 4, \"output\": 1121}] and rank by efficiency",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "aggregate_daily_production_by_1763369310",
      "quality_score": 1.1,
      "latency_ms": 885,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T08:50:01.442046+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Aggregate daily production by line: [{\"line\": 1, \"output\": 551}, {\"line\": 2, \"output\": 913}, {\"line\": 3, \"output\": 795}, {\"line\": 4, \"output\": 1121}] and rank by efficiency",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300606Z"
    },
    "created_at": "2025-11-17T08:50:01.442066Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763369988": {
    "tool_id": "note_this_workflow_may_be_mul_1763369988",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 951, Efficiency: 79%\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Format output\n3. Run quick validation/tests and fix issues",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 951, Efficiency: 79%\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Format output\n3. Run quick validation/tests and fix issues",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763369988",
      "quality_score": 1.2000000000000002,
      "latency_ms": 50,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T09:04:34.420731+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 5, Output: 951, Efficiency: 79%\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Format output\n3. Run quick validation/tests and fix issues",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300610Z"
    },
    "created_at": "2025-11-17T09:04:34.420760Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763371076": {
    "tool_id": "note_this_workflow_may_be_mul_1763371076",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 822, \"line_2\": 881} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 822, \"line_2\": 881} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763371076",
      "quality_score": 1.1,
      "latency_ms": 933,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T09:19:06.231196+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Process production metrics from shift report: {\"line_1\": 822, \"line_2\": 881} and generate summary statistics\n\nStages:\n1. Analyze requirements and clarify constraints\n2. Run quick validation/tests and fix issues",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300613Z"
    },
    "created_at": "2025-11-17T09:19:06.231216Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "note_this_workflow_may_be_mul_1763372373": {
    "tool_id": "note_this_workflow_may_be_mul_1763372373",
    "name": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 1, Output: 849, Efficiency: 91%\n\nStages:\n1. Plan the approach and outline solution\n2. Validate formatting",
    "tool_type": "workflow",
    "description": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 1, Output: 849, Efficiency: 91%\n\nStages:\n1. Plan the approach and outline solution\n2. Validate formatting",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "note_this_workflow_may_be_mul_1763372373",
      "quality_score": 1.1,
      "latency_ms": 887,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T09:41:10.255602+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Note: This workflow may be multi-stage. If a 'Stages:' section is present, execute the stages sequentially, keeping responses concise per stage and a short final summary.\n\nTask: Format production report: Date: 2025-11-17, Line: Line 1, Output: 849, Efficiency: 91%\n\nStages:\n1. Plan the approach and outline solution\n2. Validate formatting",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300617Z"
    },
    "created_at": "2025-11-17T09:41:10.255625Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_motivational_message_fo_1763373025": {
    "tool_id": "create_motivational_message_fo_1763373025",
    "name": "Create motivational message for certification achievement",
    "tool_type": "workflow",
    "description": "Create motivational message for certification achievement",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_motivational_message_fo_1763373025",
      "quality_score": 1.1,
      "latency_ms": 911,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T09:51:29.792193+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create motivational message for certification achievement",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300620Z"
    },
    "created_at": "2025-11-17T09:51:29.792214Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "convert_215_feet_to_inches": {
    "tool_id": "convert_215_feet_to_inches",
    "name": " Convert 215 feet to inches",
    "tool_type": "workflow",
    "description": " Convert 215 feet to inches",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "convert_215_feet_to_inches",
      "quality_score": 1.2000000000000002,
      "latency_ms": 47,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T09:57:55.118987+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": " Convert 215 feet to inches",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300623Z"
    },
    "created_at": "2025-11-17T09:57:55.119005Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "convert_215_inches_to_meters": {
    "tool_id": "convert_215_inches_to_meters",
    "name": " Convert 215 inches to meters",
    "tool_type": "workflow",
    "description": " Convert 215 inches to meters",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "convert_215_inches_to_meters",
      "quality_score": 1.2000000000000002,
      "latency_ms": 39,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T10:00:42.922571+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": " Convert 215 inches to meters",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300627Z"
    },
    "created_at": "2025-11-17T10:00:42.922588Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "create_training_material_intro_1763373886": {
    "tool_id": "create_training_material_intro_1763373886",
    "name": "Create training material introduction for new forklift operators",
    "tool_type": "workflow",
    "description": "Create training material introduction for new forklift operators",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_training_material_intro_1763373886",
      "quality_score": 1.1,
      "latency_ms": 1068,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T10:15:02.840286+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create training material introduction for new forklift operators",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300630Z"
    },
    "created_at": "2025-11-17T10:15:02.840305Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "what_is_the_correct_procedure": {
    "tool_id": "what_is_the_correct_procedure",
    "name": "What is the correct procedure for calibration?",
    "tool_type": "workflow",
    "description": "What is the correct procedure for calibration?",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "what_is_the_correct_procedure",
      "quality_score": 1.2000000000000002,
      "latency_ms": 44,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T10:18:33.923464+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "What is the correct procedure for calibration?",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300634Z"
    },
    "created_at": "2025-11-17T10:18:33.923485Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "convert_491_rpm_to_rad_s_for_m": {
    "tool_id": "convert_491_rpm_to_rad_s_for_m",
    "name": "Convert 491 RPM to rad/s for motor control calculations",
    "tool_type": "workflow",
    "description": "Convert 491 RPM to rad/s for motor control calculations",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "convert_491_rpm_to_rad_s_for_m",
      "quality_score": 1.2000000000000002,
      "latency_ms": 44,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T10:30:18.677945+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Convert 491 RPM to rad/s for motor control calculations",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300637Z"
    },
    "created_at": "2025-11-17T10:30:18.677963Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_plc_ladder_logic_funct": {
    "tool_id": "write_a_plc_ladder_logic_funct",
    "name": "Write a PLC ladder logic function to control conveyor belt with sensor_1, sensor_2, sensor_3, sensor_4, sensor_5 sensors",
    "tool_type": "workflow",
    "description": "Write a PLC ladder logic function to control conveyor belt with sensor_1, sensor_2, sensor_3, sensor_4, sensor_5 sensors",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_plc_ladder_logic_funct",
      "quality_score": 1.2000000000000002,
      "latency_ms": 47,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T10:38:16.236079+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a PLC ladder logic function to control conveyor belt with sensor_1, sensor_2, sensor_3, sensor_4, sensor_5 sensors",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300640Z"
    },
    "created_at": "2025-11-17T10:38:16.236098Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "identify_operations_in_the_tas_1763377030": {
    "tool_id": "identify_operations_in_the_tas_1763377030",
    "name": "Identify operations in the task",
    "tool_type": "workflow",
    "description": "Identify operations in the task",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "identify_operations_in_the_tas_1763377030",
      "quality_score": 1.1,
      "latency_ms": 900,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T11:00:21.662351+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Identify operations in the task",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300644Z"
    },
    "created_at": "2025-11-17T11:00:21.662368Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "circular_import_fixer": {
    "tool_id": "circular_import_fixer",
    "name": "Circular Import Fixer",
    "tool_type": "executable",
    "description": "Detects and automatically fixes circular import errors in generated Python code.\n\nCommon pattern fixed:\n- main.py containing \"from main import ...\" (circular import)\n- This happens when the LLM copies test file imports into the main code\n\nUsage:\n  echo '{\"code\": \"<python_code>\", \"filename\": \"main.py\"}' | python circular_import_fixer.py\n\nReturns:\n  - fixed: true/false\n  - removed_imports: list of removed import lines\n  - fixed_code: cleaned code\n  - message: summary of what was fixed\n",
    "tags": [
      "fix",
      "error_handler",
      "circular_import",
      "import_error",
      "code_repair",
      "auto_fix",
      "tdd",
      "code_generation"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\circular_import_fixer.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "611caf58c3f9375701a598144f3498c38618784a42b1f3cf60afc225cc3a88f7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300648Z"
    },
    "created_at": "2025-11-17T13:00:34.696302Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "611caf58c3f9375701a598144f3498c38618784a42b1f3cf60afc225cc3a88f7",
    "breaking_changes": []
  },
  "content_splitter": {
    "tool_id": "content_splitter",
    "name": "Content Splitter",
    "tool_type": "executable",
    "description": "Splits large content into chunks for progressive summarization.\n\nStrategies:\n- paragraph: Split on paragraph boundaries (default)\n- sentence: Split on sentence boundaries (more granular)\n- fixed: Fixed-size chunks (simple, may break sentences)\n\nRespects max chunk size while maintaining readability.\n",
    "tags": [
      "content_processing",
      "splitting",
      "chunking",
      "summarization",
      "utility"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\content_splitter.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "ab932694ded27e30e2f3287bc4da81ef24d9db35991fd52d8a94b0418b02f892",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300652Z"
    },
    "created_at": "2025-11-17T13:00:36.146962Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ab932694ded27e30e2f3287bc4da81ef24d9db35991fd52d8a94b0418b02f892",
    "breaking_changes": []
  },
  "content_summarizer": {
    "tool_id": "content_summarizer",
    "name": "Content Summarizer",
    "tool_type": "workflow",
    "description": "Smart content summarizer that automatically selects best tier and strategy.\n\nFeatures:\n- Automatic tier selection (fast/medium/large)\n- Progressive summarization for large content\n- Split-summarize-merge for very large docs\n- Mantra-aware (respects speed/quality hints)\n- Caching of results\n\nThis is the HIGH WEIGHT tool that should be used for all summarization.\n",
    "tags": [
      "summarization",
      "smart_routing",
      "high_priority",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\content_summarizer.yaml",
      "version": "1.0.0",
      "definition_hash": "13427c1b98f8777bfc5ffaf57482ed7c8ebc9d84124cd310f2c5a3bb6f697b84",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300656Z"
    },
    "created_at": "2025-11-17T13:00:36.522966Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "13427c1b98f8777bfc5ffaf57482ed7c8ebc9d84124cd310f2c5a3bb6f697b84",
    "breaking_changes": []
  },
  "prompt_generator": {
    "tool_id": "prompt_generator",
    "name": "Layered Prompt Generator",
    "tool_type": "llm",
    "description": "Generates sophisticated layered prompts with weight adjustment and model selection. Supports conversational model queries and dynamic tool creation. Uses tiered architecture with roles (system, role, context, task, constraints, output, examples).",
    "tags": [
      "prompt-engineering",
      "prompt-generation",
      "layered",
      "dynamic",
      "tool-creation",
      "model-selection"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\prompt_generator.yaml",
      "llm_tier": "default.tier_2",
      "llm_role": "base",
      "system_prompt": "You are a prompt engineering specialist. You create sophisticated, layered prompts\nthat maximize LLM performance for specific tasks.\n\nYour expertise:\n- Layered prompt architecture (system, role, context, task, constraints, output, examples)\n- Weight adjustment for section emphasis\n- Model selection based on task requirements\n- Dynamic tool creation from descriptions\n\nWhen generating prompts:\n1. Analyze the task type and complexity\n2. Select appropriate layers and weights\n3. Suggest suitable models\n4. Format clearly and effectively\n",
      "prompt_template": "{request}\n\nGenerate a layered prompt structure. Consider:\n- Task type: {task_type}\n- Complexity tier: {tier}\n- Desired emphasis: {emphasis}\n\nProvide structured output with all prompt layers.\n",
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "abcd620276ee1827c0b8bb4defa6aa619aadc9a48e357b737040e04eaf2f16ef",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300659Z"
    },
    "created_at": "2025-11-17T13:00:36.746512Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "abcd620276ee1827c0b8bb4defa6aa619aadc9a48e357b737040e04eaf2f16ef",
    "breaking_changes": []
  },
  "summarizer_fast": {
    "tool_id": "summarizer_fast",
    "name": "Fast Summarizer",
    "tool_type": "llm",
    "description": "Quick content summarization with small, fast model.\n\nUse when:\n- User says \"quickly summarize\"\n- Speed is priority\n- Basic quality is acceptable\n- Content < 8k tokens\n\nModel: gemma2:2b (very fast, 8k context)\n",
    "tags": [
      "summarization",
      "fast",
      "small_context",
      "gemma"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\summarizer_fast.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "9aacd684c779532d49ce01da2e476194cf06cad74643667a971d5ac02b4c8f11",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300665Z"
    },
    "created_at": "2025-11-17T13:00:36.966897Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "9aacd684c779532d49ce01da2e476194cf06cad74643667a971d5ac02b4c8f11",
    "breaking_changes": []
  },
  "summarizer_large": {
    "tool_id": "summarizer_large",
    "name": "Large Context Summarizer",
    "tool_type": "llm",
    "description": "High-quality summarization with large context window.\n\nUse when:\n- User says \"carefully summarize\" or \"thoroughly\"\n- Quality is critical\n- Content 32k-128k tokens\n- Complex documents\n- Books, research papers\n\nModel: mistral-nemo (large, 128k context)\n",
    "tags": [
      "summarization",
      "high_quality",
      "large_context",
      "mistral"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\summarizer_large.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "7b1fad46a35b2c6f8690e40720d4e2d4c02fb0cf1c9b1074006bb1f6ca70b4bb",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300668Z"
    },
    "created_at": "2025-11-17T13:00:37.166446Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "7b1fad46a35b2c6f8690e40720d4e2d4c02fb0cf1c9b1074006bb1f6ca70b4bb",
    "breaking_changes": []
  },
  "summarizer_medium": {
    "tool_id": "summarizer_medium",
    "name": "Medium Summarizer",
    "tool_type": "llm",
    "description": "Balanced summarization with medium-sized model.\n\nUse when:\n- Quality matters\n- Reasonable speed needed\n- Content 8k-32k tokens\n- Need comprehensive summary\n\nModel: llama3 (balanced, 32k context)\n",
    "tags": [
      "summarization",
      "balanced",
      "medium_context",
      "llama"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\summarizer_medium.yaml",
      "llm_tier": null,
      "llm_role": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium",
      "version": "1.0.0",
      "definition_hash": "e1824bf73ad6262198844a293ccee41b22245323a3b4b0fa13cd9dc493368b4f",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300672Z"
    },
    "created_at": "2025-11-17T13:00:37.370311Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "e1824bf73ad6262198844a293ccee41b22245323a3b4b0fa13cd9dc493368b4f",
    "breaking_changes": []
  },
  "create_the_tools_required_to_r_1763384526": {
    "tool_id": "create_the_tools_required_to_r_1763384526",
    "name": "Create the tools required to run do this workflow. It should have optional steps for translations.",
    "tool_type": "workflow",
    "description": "Create the tools required to run do this workflow. It should have optional steps for translations.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "create_the_tools_required_to_r_1763384526",
      "quality_score": 1.1,
      "latency_ms": 81140,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-17T13:04:46.704314+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Create the tools required to run do this workflow. It should have optional steps for translations.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300675Z"
    },
    "created_at": "2025-11-17T13:04:46.704336Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "ask_user": {
    "tool_id": "ask_user",
    "name": "Ask User",
    "tool_type": "custom",
    "description": "Interactive user input tool for CLI workflows. Prompts the user for input when running in interactive mode, otherwise asks the overseer LLM to make decisions. Enables workflows to get feedback and confirmation without blocking non-interactive execution. Supports yes/no questions, text input, and multiple choice.",
    "tags": [
      "user-input",
      "interactive",
      "confirmation",
      "prompt",
      "cli",
      "decision",
      "feedback"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "custom\\ask_user.yaml",
      "version": "1.0.0",
      "definition_hash": "4c30d21e4b4f6e3f5848938a283aeb1d8a79231bad397b3dfbba602ec87c2f54",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300679Z"
    },
    "created_at": "2025-11-17T13:37:50.170997Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "4c30d21e4b4f6e3f5848938a283aeb1d8a79231bad397b3dfbba602ec87c2f54",
    "breaking_changes": []
  },
  "git": {
    "tool_id": "git",
    "name": "Git",
    "tool_type": "custom",
    "description": "Powerful yet safe Git integration tool. Provides access to git operations with authentication from config.yaml. Supports status, log, diff, clone, fetch, pull, push, branch, checkout, and more. Includes safety checks for destructive operations.",
    "tags": [
      "git",
      "version-control",
      "vcs",
      "repository",
      "source-control",
      "scm"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "custom\\git.yaml",
      "version": "1.0.0",
      "definition_hash": "dc20e5a2497e4819348ea364448c6be6cf6f7c76dcd4acd570c2b72ab566e7f6",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300682Z"
    },
    "created_at": "2025-11-17T13:37:51.251431Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "dc20e5a2497e4819348ea364448c6be6cf6f7c76dcd4acd570c2b72ab566e7f6",
    "breaking_changes": []
  },
  "github": {
    "tool_id": "github",
    "name": "GitHub",
    "tool_type": "custom",
    "description": "GitHub integration tool for PR management, issue tracking, and repository operations. Works with Git tool for complete GitHub workflow. Supports checking PR status, merge state, comments, reviews, and more. Uses authentication from config.yaml.",
    "tags": [
      "github",
      "git",
      "pr",
      "pull-request",
      "issue",
      "repository",
      "code-review",
      "vcs"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "custom\\github.yaml",
      "version": "1.0.0",
      "definition_hash": "ecc130fcde3bc788b9db33dbb12fe882784b22aa84ae747d8840c3cd2181ffb7",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300685Z"
    },
    "created_at": "2025-11-17T13:37:51.489353Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ecc130fcde3bc788b9db33dbb12fe882784b22aa84ae747d8840c3cd2181ffb7",
    "breaking_changes": []
  },
  "workflow_diagram": {
    "tool_id": "workflow_diagram",
    "name": "Workflow Diagram Generator",
    "tool_type": "executable",
    "description": "Generates visual workflow diagrams showing tool flow and decisions.\n\nCreates beautiful Mermaid diagrams or ASCII art showing:\n- Tool dependencies and flow\n- Decision points and conditions\n- Tool types (LLM, executable, workflow)\n- Complete workflow visualization\n\nPerfect for understanding complex workflows at a glance.\n",
    "tags": [
      "visualization",
      "workflow",
      "diagram",
      "documentation",
      "mermaid",
      "ascii"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\workflow_diagram.yaml",
      "command": null,
      "args": [],
      "input_schema": null,
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "0a302b140973d76d0d6b4b0d3f0e707c75ba026b875768f331b378985029d763",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300689Z"
    },
    "created_at": "2025-11-17T13:37:52.281086Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "0a302b140973d76d0d6b4b0d3f0e707c75ba026b875768f331b378985029d763",
    "breaking_changes": []
  },
  "workflow_runner": {
    "tool_id": "workflow_runner",
    "name": "Workflow Runner",
    "tool_type": "executable",
    "description": "Generates a combined Python script from a workflow with all dependencies inlined.\nThe goal is to reduce the workflow to JUST the required code with all imports properly resolved.\nAnalyzes workflow steps, extracts tool implementations, and generates a standalone script.\n",
    "tags": [
      "workflow",
      "code-generation",
      "dependency-resolution",
      "inline",
      "standalone"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\workflow_runner.yaml",
      "command": "python",
      "args": [
        "{tool_dir}/workflow_runner.py",
        "{input_json}"
      ],
      "input_schema": {
        "workflow_id": {
          "type": "string",
          "required": true,
          "description": "The workflow ID or name to generate a combined script for"
        },
        "tools_root": {
          "type": "string",
          "required": false,
          "description": "Path to tools directory (auto-detected if not specified)",
          "default": "code_evolver/tools"
        },
        "code_evolver_root": {
          "type": "string",
          "required": false,
          "description": "Path to code_evolver root directory (auto-detected if not specified)",
          "default": "code_evolver"
        }
      },
      "output_schema": {
        "success": {
          "type": "boolean",
          "description": "Whether the script generation succeeded"
        },
        "workflow_id": {
          "type": "string",
          "description": "The workflow ID that was processed"
        },
        "script": {
          "type": "string",
          "description": "The generated combined Python script with all dependencies inlined"
        },
        "workflow_spec": {
          "type": "object",
          "description": "The original workflow specification"
        },
        "dependencies": {
          "type": "object",
          "description": "Analyzed dependencies including tools, types, and parallel task info"
        },
        "stats": {
          "type": "object",
          "description": "Statistics about the generated script (lines, imports, tools, etc.)"
        },
        "error": {
          "type": "string",
          "description": "Error message if generation failed"
        }
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "83758b2d6134aedcb3f22fa51514127fcdd5723f000126b9155ec3420d8f0d34",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300693Z"
    },
    "created_at": "2025-11-17T13:37:52.483609Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "83758b2d6134aedcb3f22fa51514127fcdd5723f000126b9155ec3420d8f0d34",
    "breaking_changes": []
  },
  "explainer": {
    "tool_id": "explainer",
    "name": "Explainer",
    "tool_type": "llm",
    "description": "Fast AI explainer tool that generates quick, concise descriptions of what's happening in workflows, tools, and system stages. Uses a 1B-class LLM for instant responses. Stage-aware and context-sensitive. Perfect for real-time explanations during tool generation and workflow execution.",
    "tags": [
      "explanation",
      "documentation",
      "help",
      "describe",
      "clarify",
      "stage-aware",
      "workflow",
      "real-time"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\explainer.yaml",
      "llm_tier": "veryfast",
      "llm_role": "code",
      "system_prompt": "You are a concise technical explainer for a code evolution system.\n\nYour role:\n- Explain what's happening in workflows, tools, and system stages\n- Be EXTREMELY concise (1-3 sentences max)\n- Focus on the \"what\" and \"why\", not implementation details\n- Use clear, simple language\n- Be stage-aware (understand context: planning, executing, testing, etc.)\n\nGuidelines:\n- **Brevity is critical** - No fluff, just facts\n- **Action-oriented** - \"Generating code...\", \"Testing implementation...\", etc.\n- **Context-aware** - Reference the stage or phase when relevant\n- **Technical but accessible** - Use terms developers understand\n\nExamples:\n- \"Generating test cases using pytest framework to validate the calculator function.\"\n- \"Analyzing code complexity with radon to identify optimization opportunities.\"\n- \"Executing workflow step 3/5: Deploying to staging environment.\"\n",
      "prompt_template": "Explain what's happening:\n\n{query}\n\n{% if context %}\nContext: {{context}}\n{% endif %}\n\n{% if stage %}\nCurrent Stage: {{stage}}\n{% endif %}\n\nProvide a concise 1-2 sentence explanation focusing on what's happening and why.\n",
      "cost_tier": "very-low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "short",
      "version": "1.0.0",
      "definition_hash": "6677703e8b6e068371b8f76ce321954a16cf77b11c93d552540b0ab3b655e478",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300696Z"
    },
    "created_at": "2025-11-17T13:37:52.704599Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6677703e8b6e068371b8f76ce321954a16cf77b11c93d552540b0ab3b655e478",
    "breaking_changes": []
  },
  "write_me_a_diary_entry_that_lo": {
    "tool_id": "write_me_a_diary_entry_that_lo",
    "name": "write me a diary entry that looks like one my younger self would write.",
    "tool_type": "workflow",
    "description": "write me a diary entry that looks like one my younger self would write.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_diary_entry_that_lo",
      "quality_score": 1.1,
      "latency_ms": 67016,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T13:40:44.344568+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write me a diary entry that looks like one my younger self would write.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300700Z"
    },
    "created_at": "2025-11-17T13:40:44.344585Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "make_a_workflow_where_it_gener": {
    "tool_id": "make_a_workflow_where_it_gener",
    "name": "make a workflow where it generates a document on the ability of ai to slef optimize' that should be a well structured article 4 pages long in content. Then in parell translate it to german, french and spanish amd save it to disk as markdown docs.",
    "tool_type": "workflow",
    "description": "make a workflow where it generates a document on the ability of ai to slef optimize' that should be a well structured article 4 pages long in content. Then in parell translate it to german, french and spanish amd save it to disk as markdown docs.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "make_a_workflow_where_it_gener",
      "quality_score": 1.1,
      "latency_ms": 120431,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T13:47:46.147830+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "make a workflow where it generates a document on the ability of ai to slef optimize' that should be a well structured article 4 pages long in content. Then in parell translate it to german, french and spanish amd save it to disk as markdown docs.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300703Z"
    },
    "created_at": "2025-11-17T13:47:46.147854Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_workflow_where_it_make": {
    "tool_id": "write_a_workflow_where_it_make",
    "name": "write a workflow where it makes a rosetta stone document with a boting technical bit in english then all the eu languages in the coument with translations below ot (use paralell translation when you can)",
    "tool_type": "workflow",
    "description": "write a workflow where it makes a rosetta stone document with a boting technical bit in english then all the eu languages in the coument with translations below ot (use paralell translation when you can)",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_workflow_where_it_make",
      "quality_score": 1.1,
      "latency_ms": 111654,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-17T13:53:59.916256+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write a workflow where it makes a rosetta stone document with a boting technical bit in english then all the eu languages in the coument with translations below ot (use paralell translation when you can)",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300707Z"
    },
    "created_at": "2025-11-17T13:53:59.916283Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "no_this_is_wrong_fix_the_tool": {
    "tool_id": "no_this_is_wrong_fix_the_tool",
    "name": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
    "tool_type": "workflow",
    "description": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "no_this_is_wrong_fix_the_tool",
      "quality_score": 1.1,
      "latency_ms": 83335,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T14:04:02.389334+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300710Z"
    },
    "created_at": "2025-11-17T14:04:02.389357Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "no_this_is_wrong_fix_the_tool_1763388526": {
    "tool_id": "no_this_is_wrong_fix_the_tool_1763388526",
    "name": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
    "tool_type": "workflow",
    "description": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "no_this_is_wrong_fix_the_tool_1763388526",
      "quality_score": 1.1,
      "latency_ms": 924,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T14:18:25.175706+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "no this is wrong, fix the tool to actually have the translated languagges in the document Running workflow...\n\n================================================================================\n  YOUR RESULT  \n================================================================================\n\n### de\nTranslation:\n\n\"This is a sample text (both technical and non-technical information).\"\n\nNote: The \"(boting)\" part appears to be a typo or a mistake, as \"boting\" doesn't seem to make sense in the context. Assuming it was meant to say \"(both)\", I've translated accordingly.\n\n### fr\nPlease provide the original French text, and I'll be happy to translate it for you.\n\n### es\nHere is the translation:\n\n\"This is a sample text (boting technical bits)\"\n\n### it\nBased on the provided information, I will translate your text with the following settings:\n\n* Priority: Not specified\n* Quality: Normal\n* Speed: Average\n\nHere's my translation of the given text:",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300714Z"
    },
    "created_at": "2025-11-17T14:18:25.175722Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "duplicate_style": {
    "tool_id": "duplicate_style",
    "name": "duplicate_style",
    "tool_type": "executable",
    "description": "Analyzes writing style from a directory of content and creates a comprehensive\nstyle guide. Uses tiered summarization to efficiently process large amounts of content.\n\nFeatures:\n- Recursive directory scanning with smart file filtering\n- Tiered LLM selection based on content size (gemma2:2b, llama3, mistral-nemo)\n- Context-aware chunking and progressive summarization\n- Incremental style analysis that builds understanding across files\n- Optional review and refinement for higher quality output\n\nUse cases:\n- Extract writing style from documentation to replicate in new docs\n- Analyze code comment style for consistency\n- Create style guides from existing content\n- Understand voice and tone patterns\n",
    "tags": [
      "style-analysis",
      "documentation",
      "content-analysis",
      "summarization"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\duplicate_style.yaml",
      "command": "python",
      "args": [
        "code_evolver/tools/executable/duplicate_style.py"
      ],
      "input_schema": {
        "type": "object",
        "required": [
          "directory"
        ],
        "properties": {
          "directory": {
            "type": "string",
            "description": "Path to directory containing content to analyze"
          },
          "file_patterns": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "File patterns to match (e.g., ['*.md', '*.txt']). Default: text and code files"
          },
          "max_files": {
            "type": "integer",
            "description": "Maximum number of files to analyze (optional)"
          },
          "quality_requirement": {
            "type": "number",
            "minimum": 0,
            "maximum": 1,
            "description": "Quality requirement for LLM tier selection (0-1, default: 0.8)"
          },
          "review_and_refine": {
            "type": "boolean",
            "description": "Whether to review and refine the style guide (default: false)"
          }
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "style_guide": {
            "type": "string",
            "description": "Comprehensive style guide extracted from content"
          },
          "files_analyzed": {
            "type": "integer",
            "description": "Number of files successfully analyzed"
          },
          "total_content_length": {
            "type": "integer",
            "description": "Total content length in characters"
          },
          "success": {
            "type": "boolean",
            "description": "Whether the operation succeeded"
          },
          "message": {
            "type": "string",
            "description": "Status message"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "6115665d948791391b31d596171871132c344f22c84a6ce79c610003c7c4673b",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300717Z"
    },
    "created_at": "2025-11-17T15:56:06.087059Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "6115665d948791391b31d596171871132c344f22c84a6ce79c610003c7c4673b",
    "breaking_changes": []
  },
  "write_markdown_doc": {
    "tool_id": "write_markdown_doc",
    "name": "write_markdown_doc",
    "tool_type": "executable",
    "description": "Generates well-formatted markdown documentation with optional style matching.\nUses tiered LLM selection for optimal quality/speed balance.\n\nFeatures:\n- Smart LLM tier selection (gemma2:2b for quick, llama3 for balanced, mistral-nemo for high-quality)\n- Optional style guide matching (works with output from duplicate_style)\n- Review and refinement capability for higher quality\n- Proper markdown formatting with validation\n- Configurable length (short ~500 words, medium ~1500 words, long ~3000 words)\n- Security guardrails (enforces output only to 'output/' directory)\n\nSecurity:\n- All output paths are validated to be under output/ directory\n- Cannot escape with ../ or absolute paths\n- Only .md files allowed\n\nUse cases:\n- Generate documentation matching existing style\n- Create technical articles and guides\n- Write README files and tutorials\n- Generate API documentation\n",
    "tags": [
      "documentation",
      "markdown",
      "content-generation",
      "style-matching"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\write_markdown_doc.yaml",
      "command": "python",
      "args": [
        "code_evolver/tools/executable/write_markdown_doc.py"
      ],
      "input_schema": {
        "type": "object",
        "required": [
          "topic",
          "output_file"
        ],
        "properties": {
          "topic": {
            "type": "string",
            "description": "What to write about"
          },
          "output_file": {
            "type": "string",
            "description": "Relative path for output file under output/ directory (e.g., 'docs/readme.md')"
          },
          "style_guide": {
            "type": "string",
            "description": "Optional style guide to match (from duplicate_style skill)"
          },
          "outline": {
            "type": "string",
            "description": "Optional outline to follow"
          },
          "length": {
            "type": "string",
            "enum": [
              "short",
              "medium",
              "long"
            ],
            "description": "Target length: short (~500 words), medium (~1500 words), long (~3000 words)",
            "default": "medium"
          },
          "quality_requirement": {
            "type": "number",
            "minimum": 0,
            "maximum": 1,
            "description": "Quality requirement for LLM tier selection (0-1, default: 0.8)"
          },
          "review_and_refine": {
            "type": "boolean",
            "description": "Whether to review and refine the generated content (default: true)"
          }
        }
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "file_path": {
            "type": "string",
            "description": "Absolute path where file was written"
          },
          "content_length": {
            "type": "integer",
            "description": "Content length in characters"
          },
          "word_count": {
            "type": "integer",
            "description": "Approximate word count"
          },
          "validation": {
            "type": "object",
            "description": "Markdown validation results",
            "properties": {
              "valid": {
                "type": "boolean"
              },
              "issues": {
                "type": "array",
                "items": {
                  "type": "string"
                }
              },
              "has_headers": {
                "type": "boolean"
              },
              "has_lists": {
                "type": "boolean"
              },
              "word_count": {
                "type": "integer"
              }
            }
          },
          "success": {
            "type": "boolean",
            "description": "Whether the operation succeeded"
          },
          "message": {
            "type": "string",
            "description": "Status message"
          },
          "error": {
            "type": "string",
            "description": "Error message if failed"
          }
        }
      },
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "ba473a50c054ce2cb99bd04b85c7bbffc21e2d8a258dc64b364327859c451e08",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300721Z"
    },
    "created_at": "2025-11-17T15:56:06.293161Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "ba473a50c054ce2cb99bd04b85c7bbffc21e2d8a258dc64b364327859c451e08",
    "breaking_changes": []
  },
  "write_a_small_book_about_scotl": {
    "tool_id": "write_a_small_book_about_scotl",
    "name": "Write a small book about Scotland",
    "tool_type": "workflow",
    "description": "Write a small book about Scotland",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_small_book_about_scotl",
      "quality_score": 1.1,
      "latency_ms": 42484,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-17T16:04:50.402676+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a small book about Scotland",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300725Z"
    },
    "created_at": "2025-11-17T16:04:50.402693Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_poem_conversation": {
    "tool_id": "write_me_a_poem_conversation",
    "name": "write me a poem\n\n[Conversation Context:\n- tool interaction with python_syntax_validator: Tool Interaction: python_syntax_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/python_syntax_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no\n- tool interaction with node_runtime_import_validator: Tool Interaction: node_runtime_import_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/node_runtime_import_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\"\n- tool interaction with undefined_name_checker: Tool Interaction: undefined_name_checker\n\nType: tool\n\nInput:\n{\"command\": \"flake8 --select=F821,F401,F811,E999 --format=pylint nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no_\n- llm interaction with general: Tool Interaction: general\n\nType: llm\n\nInput:\n{\"prompt\": \"You are implementing code based on this DETAILED SPECIFICATION:\\n\\n**Problem Definition**\\n\\nThe task is to create a workflow that generates a \n- write a small book about scotland: User: write a small book about scotland\nProcessed successfully in 511.44s]",
    "tool_type": "workflow",
    "description": "write me a poem\n\n[Conversation Context:\n- tool interaction with python_syntax_validator: Tool Interaction: python_syntax_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/python_syntax_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no\n- tool interaction with node_runtime_import_validator: Tool Interaction: node_runtime_import_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/node_runtime_import_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\"\n- tool interaction with undefined_name_checker: Tool Interaction: undefined_name_checker\n\nType: tool\n\nInput:\n{\"command\": \"flake8 --select=F821,F401,F811,E999 --format=pylint nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no_\n- llm interaction with general: Tool Interaction: general\n\nType: llm\n\nInput:\n{\"prompt\": \"You are implementing code based on this DETAILED SPECIFICATION:\\n\\n**Problem Definition**\\n\\nThe task is to create a workflow that generates a \n- write a small book about scotland: User: write a small book about scotland\nProcessed successfully in 511.44s]",
    "tags": [
      "generated",
      "chat",
      "formatting",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_poem_conversation",
      "quality_score": 1.1,
      "latency_ms": 44633,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-17T16:22:40.447768+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "write me a poem\n\n[Conversation Context:\n- tool interaction with python_syntax_validator: Tool Interaction: python_syntax_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/python_syntax_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no\n- tool interaction with node_runtime_import_validator: Tool Interaction: node_runtime_import_validator\n\nType: tool\n\nInput:\n{\"command\": \"python tools\\\\executable/node_runtime_import_validator.py nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\"\n- tool interaction with undefined_name_checker: Tool Interaction: undefined_name_checker\n\nType: tool\n\nInput:\n{\"command\": \"flake8 --select=F821,F401,F811,E999 --format=pylint nodes\\\\no_this_is_wrong_fix_the_tool\\\\main.py\", \"source_file\": \"nodes\\\\no_\n- llm interaction with general: Tool Interaction: general\n\nType: llm\n\nInput:\n{\"prompt\": \"You are implementing code based on this DETAILED SPECIFICATION:\\n\\n**Problem Definition**\\n\\nThe task is to create a workflow that generates a \n- write a small book about scotland: User: write a small book about scotland\nProcessed successfully in 511.44s]",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300729Z"
    },
    "created_at": "2025-11-17T16:22:40.447794Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "module_not_found_fixer": {
    "tool_id": "module_not_found_fixer",
    "name": "ModuleNotFoundError Fixer",
    "tool_type": "executable",
    "description": "Fixes ModuleNotFoundError by adding sys.path setup before imports.\n\nThis tool has ENCAPSULATED validation:\n- fix() method: Applies the fix to the code\n- validate() method: Validates the fix was actually applied\n\nCommon patterns handled:\n- Adds path setup (sys.path.insert) before imports\n- Removes unused imports that cause the error\n- Validates all changes are actually in the fixed code\n",
    "tags": [
      "fix",
      "error_handler",
      "module_error",
      "import_error",
      "auto_fix",
      "tdd",
      "validated"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\module_not_found_fixer.yaml",
      "command": null,
      "args": [],
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "enum": [
              "fix",
              "validate"
            ],
            "default": "fix"
          },
          "code": {
            "type": "string",
            "description": "The failing code"
          },
          "filename": {
            "type": "string",
            "default": "main.py"
          },
          "error_message": {
            "type": "string",
            "description": "The ModuleNotFoundError message"
          },
          "original_code": {
            "type": "string"
          },
          "fixed_code": {
            "type": "string"
          },
          "fix_result": {
            "type": "object"
          }
        }
      },
      "output_schema": null,
      "cost_tier": "free",
      "speed_tier": "medium",
      "quality_tier": "good",
      "version": "1.0.0",
      "definition_hash": "4fe8fcbaa2c5e461f4e0ad6c62fc2916eb0a3e11f160b44a816e57050d6fc1b3",
      "breaking_changes": []
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-17T17:27:48.300735Z"
    },
    "created_at": "2025-11-17T17:21:44.296401Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "4fe8fcbaa2c5e461f4e0ad6c62fc2916eb0a3e11f160b44a816e57050d6fc1b3",
    "breaking_changes": []
  }
}