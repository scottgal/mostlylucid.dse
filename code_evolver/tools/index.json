{
  "general": {
    "tool_id": "general",
    "name": "General Code Generator",
    "tool_type": "llm",
    "description": "General purpose code generation for any programming task. Used as fallback when no specialized tool matches. Handles complex logic, multi-step workflows, and sophisticated algorithms.",
    "tags": [
      "general",
      "fallback",
      "code-generation",
      "any-task",
      "complex"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "codellama",
      "llm_endpoint": null,
      "system_prompt": "You are an expert software engineer proficient in python and paradigms. You write clean, efficient, well factored and, well-documented code following best practices. Your code is production-ready with proper error handling and testing considerations.\n\nIMPORTANT: For content generation tasks (stories, articles, jokes), write Python code that DIRECTLY creates the content as a string in the main() function. DO NOT use call_tool() or try to orchestrate workflows.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Generate code for the following task:\n\n{task}\n\nWorkflow Context:\n- Priority: {priority} (determines speed vs quality tradeoff)\n- Quality level: {quality_level} (draft/good/production/perfect)\n- Speed: {speed_requirement} (fast/balanced/thorough)\n\nRequirements:\n- Match the quality level specified above\n- Adjust detail/documentation based on priority\n- Proper error handling (depth based on quality level)\n- Follow language best practices\n- Include type hints/annotations for production+ quality\n\nSPECIAL NOTE FOR CONTENT GENERATION:\nIf the task involves generating text content (stories, articles, jokes, etc.):\n- Write a simple main() function that DIRECTLY creates the content\n- DO NOT use call_tool() - that function doesn't exist in the runtime\n- Just create the content as a string variable and output it\n- Example: content = \"Once upon a time...\" then print(json.dumps({{\"result\": content}}))",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "very-long"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356532Z"
    },
    "created_at": "2025-11-15T23:05:48.995172Z",
    "usage_count": 12,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "code_reviewer": {
    "tool_id": "code_reviewer",
    "name": "Code Reviewer",
    "tool_type": "llm",
    "description": "Reviews code for quality, bugs, and best practices",
    "tags": [
      "review",
      "quality"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": "You are an expert code reviewer with deep knowledge of software engineering best practices, design patterns, and common pitfalls. Your role is to review code for quality, bugs, security issues, and maintainability.",
      "prompt_template": "Review the following code:\n\n{code}\n\nProvide:\n1. Overall quality assessment (1-10)\n2. Specific issues found (bugs, security, performance)\n3. Best practice violations\n4. Improvement suggestions\n5. Positive aspects of the code",
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356543Z"
    },
    "created_at": "2025-11-15T23:05:48.995188Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "security_auditor": {
    "tool_id": "security_auditor",
    "name": "Security Auditor",
    "tool_type": "llm",
    "description": "Audits code for security vulnerabilities",
    "tags": [
      "security",
      "audit"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356549Z"
    },
    "created_at": "2025-11-15T23:05:48.995193Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "performance_optimizer": {
    "tool_id": "performance_optimizer",
    "name": "Performance Optimizer",
    "tool_type": "llm",
    "description": "Suggests performance optimizations",
    "tags": [
      "performance",
      "optimization"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "codellama",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356554Z"
    },
    "created_at": "2025-11-15T23:05:48.995198Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "doc_generator": {
    "tool_id": "doc_generator",
    "name": "Documentation Generator",
    "tool_type": "llm",
    "description": "Generates comprehensive code documentation",
    "tags": [
      "documentation",
      "docs"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356557Z"
    },
    "created_at": "2025-11-15T23:05:48.995202Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "technical_writer": {
    "tool_id": "technical_writer",
    "name": "Technical Article Writer",
    "tool_type": "llm",
    "description": "Writes comprehensive technical articles, tutorials, and blog posts on software development topics",
    "tags": [
      "writing",
      "technical",
      "article",
      "blog",
      "tutorial",
      "documentation"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": "You are an expert technical writer specializing in software development content. You create clear, engaging, and accurate articles that explain complex programming concepts to developers. Your writing is well-structured, includes practical examples, and follows best practices for technical documentation.\n\nWorkflow pressure: {priority}\nQuality target: {quality_level}\nSpeed mode: {speed_requirement}",
      "prompt_template": "Write a technical article on the following topic:\n\n{topic}\n\nWorkflow Context:\n- Priority: {priority} (high=fast draft, low=thorough research)\n- Quality level: {quality_level} (draft/good/publication/perfect)\n- Speed: {speed_requirement} (fast=outline+key points, thorough=full research)\n- Target audience: {audience}\n- Tone: Professional but accessible\n- Length target: {length}\n\nAdjust depth, examples, and polish based on quality_level:\n- draft: Key points, basic examples\n- good: Solid content, working examples\n- publication: Polished, multiple examples, thorough\n- perfect: Comprehensive, exceptional examples, fully researched",
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356561Z"
    },
    "created_at": "2025-11-15T23:05:48.995206Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "article_analyzer": {
    "tool_id": "article_analyzer",
    "name": "Article Content Analyzer",
    "tool_type": "llm",
    "description": "Analyzes blog posts and articles for clarity, technical accuracy, SEO, and readability. Provides improvement suggestions.",
    "tags": [
      "analysis",
      "blog",
      "seo",
      "readability",
      "content",
      "review"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356565Z"
    },
    "created_at": "2025-11-15T23:05:48.995211Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "seo_optimizer": {
    "tool_id": "seo_optimizer",
    "name": "SEO Optimizer",
    "tool_type": "llm",
    "description": "Optimizes technical content for search engines, suggests keywords, meta descriptions, and structure improvements",
    "tags": [
      "seo",
      "keywords",
      "optimization",
      "search",
      "metadata"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356569Z"
    },
    "created_at": "2025-11-15T23:05:48.995215Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "code_explainer": {
    "tool_id": "code_explainer",
    "name": "Code Concept Explainer",
    "tool_type": "llm",
    "description": "Explains complex programming concepts in simple terms for blog articles and tutorials. Creates analogies and examples.",
    "tags": [
      "explanation",
      "tutorial",
      "teaching",
      "concepts",
      "examples"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356572Z"
    },
    "created_at": "2025-11-15T23:05:48.995220Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "outline_generator": {
    "tool_id": "outline_generator",
    "name": "Article Outline Generator",
    "tool_type": "llm",
    "description": "Creates detailed outlines for technical articles based on topics. Structures content logically.",
    "tags": [
      "outline",
      "structure",
      "planning",
      "article",
      "organization"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356576Z"
    },
    "created_at": "2025-11-15T23:05:48.995224Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "proofreader": {
    "tool_id": "proofreader",
    "name": "Technical Proofreader",
    "tool_type": "llm",
    "description": "Proofreads technical content for grammar, style, consistency, and technical accuracy",
    "tags": [
      "proofreading",
      "grammar",
      "style",
      "editing",
      "quality"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": "You are an expert proofreader specializing in technical content. You have a keen eye for grammar, style, consistency, and technical accuracy. You provide constructive feedback while preserving the author's voice and intent.",
      "prompt_template": "Proofread the following technical content:\n\n{content}\n\nCheck for:\n1. Grammar and spelling errors\n2. Technical accuracy\n3. Consistency in terminology\n4. Clarity and readability\n5. Code example correctness\n\nProvide corrected version and list of changes made.",
      "cost_tier": "medium",
      "speed_tier": "medium",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356579Z"
    },
    "created_at": "2025-11-15T23:05:48.995229Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_technical_story_and_tr": {
    "tool_id": "write_a_technical_story_and_tr",
    "name": "write a technical story and translate it into french",
    "tool_type": "workflow",
    "description": "write a technical story and translate it into french",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_technical_story_and_tr",
      "quality_score": 1.2000000000000002,
      "latency_ms": 21,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T00:29:22.121997+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356583Z"
    },
    "created_at": "2025-11-15T00:29:22.122018Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_technical_article_1763166799": {
    "tool_id": "write_me_a_technical_article_1763166799",
    "name": "write me a technical article",
    "tool_type": "workflow",
    "description": "write me a technical article",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_technical_article_1763166799",
      "quality_score": 1.2000000000000002,
      "latency_ms": 21,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T00:33:43.019118+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356587Z"
    },
    "created_at": "2025-11-15T00:33:43.019137Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_5_and_8": {
    "tool_id": "add_5_and_8",
    "name": "Python function to add two numbers with default values of 5 and 8",
    "tool_type": "workflow",
    "description": "add 5 and 8",
    "tags": [
      "python",
      "addition",
      "default-values",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_5_and_8",
      "quality_score": 1.1,
      "latency_ms": 700,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T00:45:30.312376+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356590Z"
    },
    "created_at": "2025-11-15T00:45:30.312391Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pylint_checker": {
    "tool_id": "pylint_checker",
    "name": "Pylint Code Quality Checker",
    "tool_type": "executable",
    "description": "Runs pylint static analysis on Python code to check for errors, code style, and potential bugs",
    "tags": [
      "python",
      "static-analysis",
      "quality",
      "linting",
      "pep8"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "pylint",
      "args": [
        "--output-format=text",
        "--score=yes",
        "{source_file}"
      ],
      "install_command": "pip install pylint"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356594Z"
    },
    "created_at": "2025-11-15T23:05:48.995234Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "mypy_type_checker": {
    "tool_id": "mypy_type_checker",
    "name": "MyPy Type Checker",
    "tool_type": "executable",
    "description": "Runs mypy type checking on Python code to find type errors before runtime",
    "tags": [
      "python",
      "type-checking",
      "static-analysis",
      "types"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "mypy",
      "args": [
        "--strict",
        "--show-error-codes",
        "{source_file}"
      ],
      "install_command": "pip install mypy"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356598Z"
    },
    "created_at": "2025-11-15T23:05:48.995240Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "flake8_linter": {
    "tool_id": "flake8_linter",
    "name": "Flake8 Style Checker",
    "tool_type": "executable",
    "description": "Runs flake8 to check Python code style (PEP 8) and detect common errors",
    "tags": [
      "python",
      "linting",
      "pep8",
      "style",
      "quality"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "flake8",
      "args": [
        "--max-line-length=120",
        "--statistics",
        "{source_file}"
      ],
      "install_command": "pip install flake8"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356601Z"
    },
    "created_at": "2025-11-15T23:05:48.995245Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "black_formatter": {
    "tool_id": "black_formatter",
    "name": "Black Code Formatter",
    "tool_type": "executable",
    "description": "Runs black formatter to check if Python code follows black style (with --check flag)",
    "tags": [
      "python",
      "formatting",
      "style",
      "black"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "black",
      "args": [
        "--check",
        "--diff",
        "{source_file}"
      ],
      "install_command": "pip install black"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356605Z"
    },
    "created_at": "2025-11-15T23:05:48.995249Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "bandit_security": {
    "tool_id": "bandit_security",
    "name": "Bandit Security Scanner",
    "tool_type": "executable",
    "description": "Runs bandit security scanner to find common security issues in Python code",
    "tags": [
      "python",
      "security",
      "vulnerability",
      "scanning"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "bandit",
      "args": [
        "-r",
        "{source_file}"
      ],
      "install_command": "pip install bandit"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356608Z"
    },
    "created_at": "2025-11-15T23:05:48.995255Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pytest_runner": {
    "tool_id": "pytest_runner",
    "name": "Pytest Test Runner",
    "tool_type": "executable",
    "description": "Runs pytest unit tests with coverage reporting",
    "tags": [
      "python",
      "testing",
      "pytest",
      "unit-tests"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "pytest",
      "args": [
        "-v",
        "--tb=short",
        "{test_file}"
      ],
      "install_command": "pip install pytest"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356611Z"
    },
    "created_at": "2025-11-15T23:05:48.995259Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pytest_coverage": {
    "tool_id": "pytest_coverage",
    "name": "Pytest with Coverage",
    "tool_type": "executable",
    "description": "Runs pytest with code coverage analysis",
    "tags": [
      "python",
      "testing",
      "coverage",
      "pytest"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "pytest",
      "args": [
        "--cov={source_module}",
        "--cov-report=term-missing",
        "-v",
        "{test_file}"
      ],
      "install_command": "pip install pytest pytest-cov"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356614Z"
    },
    "created_at": "2025-11-15T23:05:48.995264Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "radon_complexity": {
    "tool_id": "radon_complexity",
    "name": "Radon Complexity Analyzer",
    "tool_type": "executable",
    "description": "Analyzes code complexity metrics (cyclomatic complexity, maintainability index)",
    "tags": [
      "python",
      "complexity",
      "metrics",
      "maintainability"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "radon",
      "args": [
        "cc",
        "-s",
        "-a",
        "{source_file}"
      ],
      "install_command": "pip install radon"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356618Z"
    },
    "created_at": "2025-11-15T23:05:48.995268Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "vulture_deadcode": {
    "tool_id": "vulture_deadcode",
    "name": "Vulture Dead Code Finder",
    "tool_type": "executable",
    "description": "Finds unused code (dead code) in Python projects",
    "tags": [
      "python",
      "dead-code",
      "optimization",
      "cleanup"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "vulture",
      "args": [
        "{source_file}"
      ],
      "install_command": "pip install vulture"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356621Z"
    },
    "created_at": "2025-11-15T23:05:48.995272Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pydocstyle_checker": {
    "tool_id": "pydocstyle_checker",
    "name": "Pydocstyle Docstring Checker",
    "tool_type": "executable",
    "description": "Checks docstring style and completeness according to PEP 257",
    "tags": [
      "python",
      "documentation",
      "docstrings",
      "pep257"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "pydocstyle",
      "args": [
        "{source_file}"
      ],
      "install_command": "pip install pydocstyle"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356624Z"
    },
    "created_at": "2025-11-15T23:05:48.995276Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "isort_import_checker": {
    "tool_id": "isort_import_checker",
    "name": "Isort Import Checker",
    "tool_type": "executable",
    "description": "Checks if Python imports are sorted correctly",
    "tags": [
      "python",
      "imports",
      "style",
      "organization"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "isort",
      "args": [
        "--check-only",
        "--diff",
        "{source_file}"
      ],
      "install_command": "pip install isort"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356628Z"
    },
    "created_at": "2025-11-15T23:05:48.995280Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "quick_feedback": {
    "tool_id": "quick_feedback",
    "name": "Quick Feedback Checker",
    "tool_type": "llm",
    "description": "Fast spellcheck, grammar, and syntax error checker using tinyllama (2048 token context). Automatically chunks large text into logical segments. Gives quick feedback on generated text/code so generators can fix issues rapidly.",
    "tags": [
      "spellcheck",
      "grammar",
      "syntax",
      "quick-feedback",
      "fast",
      "proofreading",
      "chunking"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "tinyllama",
      "llm_endpoint": null,
      "system_prompt": "You are a fast proofreader. Check for spelling errors, grammar mistakes, and syntax issues. Be concise - your context window is small (2048 tokens). If you receive a chunk of text, check just that chunk and report issues found in it.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Quick check this text for errors:\n\n{text}\n\nFind:\n- Spelling errors\n- Grammar mistakes  \n- Syntax issues\n- Structure problems\n\nProvide a brief list of issues found (keep under 400 tokens). If no major issues, just say 'OK'. NOTE: You may be seeing a chunk of larger text - just check this portion.",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "basic",
      "max_output_length": "short"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356631Z"
    },
    "created_at": "2025-11-15T23:05:48.995177Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "summarizer": {
    "tool_id": "summarizer",
    "name": "Content Summarizer",
    "tool_type": "llm",
    "description": "Summarizes long content, code, documentation, or conversations using Gemma2:2b model with 8192 token context window. Efficient for condensing information.",
    "tags": [
      "summarization",
      "condensing",
      "analysis",
      "extraction",
      "efficient"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "gemma2:2b",
      "llm_endpoint": null,
      "system_prompt": "You are an expert at creating concise, accurate summaries. Extract key points and present them clearly. Your context window is 8192 tokens.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Summarize the following content:\n\n{content}\n\nSummary requirements:\n- Capture all key points\n- Be concise but complete\n- Prioritize most important information\n- Target length: {target_length}\n\nProvide a well-structured summary.",
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356634Z"
    },
    "created_at": "2025-11-15T23:05:48.995183Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "nmt_translator": {
    "tool_id": "nmt_translator",
    "name": "NMT Translation Service",
    "tool_type": "openapi",
    "description": "Neural Machine Translation service for translating text between languages. VERY FAST but can be inaccurate - MUST validate output with translation_quality_checker for repeated characters and garbled text. Uses OpenAPI spec from http://localhost:8000/openapi.json.",
    "tags": [
      "translation",
      "nmt",
      "neural",
      "languages",
      "openapi",
      "api"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "api_base_url": "http://localhost:8000",
      "operations_count": 18,
      "capabilities": "API: NMT Translation Service\nBase URL: http://localhost:8000\n\nAvailable Operations (18):\n\n- root_redirect__get:\n  Method: GET /\n  Summary: Root Redirect\n  Description: Redirects to the interactive demo UI\n\n- healthz_healthz_get:\n  Method: GET /healthz\n  Summary: Health Check\n  Description: Returns health status\n\n- readyz_readyz_get:\n  Method: GET /readyz\n  Summary: Readiness Check\n  Description: Returns readiness status with device and queue info\n\n- cache_status_cache_get:\n  Method: GET /cache\n  Summary: Cache Status\n  Description: Returns the currently cached translation pipelines and queue info\n\n- model_name_model_name_get:\n  Method: GET /model_name\n  Summary: Model Name\n  Description: Returns the name of the loaded model and configuration snapshot\n\n- discover_opus_mt_discover_opus_mt_get:\n  Method: GET /discover/opus-mt\n  Summary: Discover Opus-MT Pairs\n  Description: Discovers all available Opus-MT language pairs from Hugging Face. Results are cached for 1 hour.\n  Parameters: force_refresh (query)\n\n- discover_mbart50_discover_mbart50_get:\n  Method: GET /discover/mbart50\n  Summary: Discover mBART50 Pairs\n  Description: Returns all available mBART50 language pairs (all-to-all for 50 languages).\n\n- discover_m2m100_discover_m2m100_get:\n  Method: GET /discover/m2m100\n  Summary: Discover M2M100 Pairs\n  Description: Returns all available M2M100 language pairs (all-to-all for 100 languages).\n\n- discover_all_discover_all_get:\n  Method: GET /discover/all\n  Summary: Discover All Models\n  Description: Discovers all available language pairs for all model families.\n  Parameters: force_refresh (query)\n\n- clear_discovery_cache_discover_clear_cache_post:\n  Method: POST /discover/clear-cache\n  Summary: Clear Discovery Cache\n  Description: Clears the model discovery cache. Next discovery request will fetch fresh data.\n\n- lang_pairs_lang_pairs_get:\n  Method: GET /lang_pairs\n  Summary: Lang Pairs\n  Description: Returns the language pairs from the model\n:return:\n\n- get_languages_get_languages_get:\n  Method: GET /get_languages\n  Summary: Get Languages\n  Description: Returns the languages the model supports\n:param source_lang: Optional. Only return languages with this language as source\n:param target_lang: Optional. Only return languages with this language as target\n:return:\n  Parameters: source_lang (query), target_lang (query)\n\n- compat_translate_get_endpoint_compat_translate_get:\n  Method: GET /compat/translate\n  Summary: EasyNMT GET /translate (compat)\n  Parameters: target_lang (query) (required), text (query), source_lang (query), beam_size (query), perform_sentence_splitting (query)\n\n- compat_translate_post_endpoint_compat_translate_post:\n  Method: POST /compat/translate\n  Summary: EasyNMT POST /translate (compat)\n\n- translate_get_endpoint_translate_get:\n  Method: GET /translate\n  Summary: Translate\n  Description: Translates the text to the given target language.\n:param text: Text that should be translated\n:param target_lang: Target language\n:param source_lang: Language of text. Optional, if empty: Automatic language detection\n:param beam_size: Beam size. Optional\n:param perform_sentence_splitting: Split longer documents into individual sentences for translation. Optional\n:return: Returns a json with the translated text\n  Parameters: target_lang (query) (required), text (query), source_lang (query), beam_size (query), perform_sentence_splitting (query)\n\n- translate_post_endpoint_translate_post:\n  Method: POST /translate\n  Summary: Translate Post\n  Description: Post method for translation\n:return:\n\n- language_detection_get_endpoint_language_detection_get:\n  Method: GET /language_detection\n  Summary: Language Detection\n  Description: Detects the language for the provided text\n:param text: A single text for which we want to know the language\n:return: The detected language\n  Parameters: text (query) (required)\n\n- language_detection_post_endpoint_language_detection_post:\n  Method: POST /language_detection\n  Summary: Language Detection Post\n  Description: Pass a json that has a 'text' key. The 'text' element can either be a string, a list of strings, or\na dict.\n:return: Languages detected",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "long",
      "code_template": "# Example: How to use the NMT Translation Service\nimport requests\nimport json\n\ndef translate_text(text, source_lang=\"en\", target_lang=\"es\"):\n    \"\"\"\n    Translate text using the NMT service.\n\n    Args:\n        text: Text to translate\n        source_lang: Source language code (e.g., 'en', 'es', 'fr')\n        target_lang: Target language code\n\n    Returns:\n        Translated text\n    \"\"\"\n    url = \"http://localhost:8000/translate\"\n\n    payload = {\n        \"text\": text,\n        \"source_lang\": source_lang,\n        \"target_lang\": target_lang\n    }\n\n    response = requests.post(url, json=payload)\n    response.raise_for_status()\n\n    result = response.json()\n    return result.get(\"translated_text\", \"\")\n\n# Usage example:\n# translated = translate_text(\"Hello, world!\", source_lang=\"en\", target_lang=\"es\")\n# print(translated)  # Output: \"Hola, mundo!\"\n"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356638Z"
    },
    "created_at": "2025-11-15T23:05:49.011665Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translation_quality_checker": {
    "tool_id": "translation_quality_checker",
    "name": "Translation Quality Validator",
    "tool_type": "llm",
    "description": "Fast quality check for translation output using tinyllama. Detects repeated characters, garbled text, encoding errors, and translation failures. MUST be used after nmt_translator to validate output quality.",
    "tags": [
      "translation",
      "validation",
      "quality-check",
      "error-detection",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "tinyllama",
      "llm_endpoint": null,
      "system_prompt": "You are a translation quality validator. Check translated text for common errors. Be fast and concise - your context window is only 2048 tokens.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Validate this translated text for quality issues:\n\nOriginal: {original_text}\nTranslated: {translated_text}\n\nCheck for:\n1. Repeated characters (e.g., 'aaaa', '||||')\n2. Garbled text (random symbols, encoding errors)\n3. Untranslated portions\n4. Missing or corrupted text\n5. Obvious translation failures\n\nRespond with ONLY:\n- 'OK' if translation looks good\n- 'ERROR: <brief description>' if issues found\n\nKeep response under 100 tokens.",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "basic",
      "max_output_length": "short"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356643Z"
    },
    "created_at": "2025-11-15T23:05:49.011690Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_100_and_200": {
    "tool_id": "add_100_and_200",
    "name": "Python function to add two numbers with JSON input/output",
    "tool_type": "workflow",
    "description": "add 100 and 200",
    "tags": [
      "python",
      "addition",
      "json",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_100_and_200",
      "quality_score": 1.1,
      "latency_ms": 1025,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T01:17:53.285092+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356646Z"
    },
    "created_at": "2025-11-15T01:17:53.285112Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "long_form_writer": {
    "tool_id": "long_form_writer",
    "name": "Long-Form Content Writer",
    "tool_type": "llm",
    "description": "Specialized for writing long-form content (novels, books, long articles) using mistral-nemo's massive 128K context window. Best for creative writing, story generation, and content that requires maintaining continuity over many pages. Use with summarizer for ultra-long content.",
    "tags": [
      "creative-writing",
      "novel",
      "story",
      "long-form",
      "article",
      "book",
      "large-context"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "mistral-nemo",
      "llm_endpoint": null,
      "system_prompt": "You are a creative writer specializing in long-form content. You have a massive 128K token context window, allowing you to maintain consistency and continuity across very long texts. Write engaging, well-structured content that flows naturally.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "{prompt}\n\nPrevious context (if continuing):\n{context}\n\nGenerate the next section maintaining consistency with previous content.",
      "cost_tier": "high",
      "speed_tier": "slow",
      "quality_tier": "excellent",
      "max_output_length": "very-long"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356650Z"
    },
    "created_at": "2025-11-15T23:05:49.011698Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_code_to_do_a_fibonacc": {
    "tool_id": "write_me_code_to_do_a_fibonacc",
    "name": "Python implementation to generate Fibonacci sequence",
    "tool_type": "workflow",
    "description": "write me code to do a fibonacci sequanece",
    "tags": [
      "fibonacci",
      "sequence",
      "python",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_code_to_do_a_fibonacc",
      "quality_score": 1.2000000000000002,
      "latency_ms": 23,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T01:45:38.026091+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356654Z"
    },
    "created_at": "2025-11-15T01:45:38.026107Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "code_translation_validator": {
    "tool_id": "code_translation_validator",
    "name": "Code Translation Validator",
    "tool_type": "llm",
    "description": "Fast validator that ensures translation hasn't corrupted Python code blocks. Checks that code syntax remains valid, only comments are translated, and no code keywords were mistranslated. Use AFTER translating documents containing code.",
    "tags": [
      "code",
      "validation",
      "translation",
      "syntax-check",
      "fast"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "tinyllama",
      "llm_endpoint": null,
      "system_prompt": "You are a code validator. Check that Python code remains syntactically valid after translation. ONLY comments should be translated, never code itself.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Validate this translated code:\n\n{translated_code}\n\nCheck:\n1. Python syntax is still valid\n2. Only comments were translated (not keywords, variables, functions)\n3. Code structure is unchanged\n4. No code keywords mistranslated (def, class, import, if, for, etc.)\n\nRespond with:\n- 'OK' if code is valid\n- 'ERROR: <list of issues>' if problems found\n\nBe concise (under 100 tokens).",
      "cost_tier": "low",
      "speed_tier": "very-fast",
      "quality_tier": "good",
      "max_output_length": "short"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356657Z"
    },
    "created_at": "2025-11-15T23:05:49.011706Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_10_and_20_1763173231": {
    "tool_id": "add_10_and_20_1763173231",
    "name": "Python function to add two integers with input validation and error handling.",
    "tool_type": "workflow",
    "description": "add 10 and 20",
    "tags": [
      "python",
      "addition",
      "input_validation",
      "error_handling",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_10_and_20_1763173231",
      "quality_score": 1.1,
      "latency_ms": 897,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T02:21:46.594116+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356660Z"
    },
    "created_at": "2025-11-15T02:21:46.594132Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "what_is_1_plus_1": {
    "tool_id": "what_is_1_plus_1",
    "name": "A simple Python function to add two integers.",
    "tool_type": "workflow",
    "description": "what is 1 plus 1",
    "tags": [
      "arithmetic",
      "addition",
      "python",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "what_is_1_plus_1",
      "quality_score": 1.1,
      "latency_ms": 670,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T02:30:39.242591+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356664Z"
    },
    "created_at": "2025-11-15T02:30:39.242608Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_the_fibonacci_sequen": {
    "tool_id": "calculate_the_fibonacci_sequen",
    "name": "Efficient Fibonacci sequence generator",
    "tool_type": "workflow",
    "description": "calculate the fibonacci sequence.",
    "tags": [
      "fibonacci",
      "dynamic programming",
      "iterative",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_the_fibonacci_sequen",
      "quality_score": 1.2000000000000002,
      "latency_ms": 25,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T03:01:26.867688+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356667Z"
    },
    "created_at": "2025-11-15T03:01:26.867706Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "sum_4_and_6": {
    "tool_id": "sum_4_and_6",
    "name": "sum 4 and 6",
    "tool_type": "workflow",
    "description": "sum 4 and 6",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "sum_4_and_6",
      "quality_score": 1.1,
      "latency_ms": 679,
      "memory_mb_peak": 1.92,
      "created_at": "2025-11-15T03:43:47.333768+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356670Z"
    },
    "created_at": "2025-11-15T03:43:47.333782Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_a_fibonaccie_sequenc": {
    "tool_id": "calculate_a_fibonaccie_sequenc",
    "name": "Calculate a Fibonacci sequence up to a specified length.",
    "tool_type": "workflow",
    "description": "calculate a fibonaccie sequence and output the result.",
    "tags": [
      "fibonacci",
      "sequence",
      "python",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_a_fibonaccie_sequenc",
      "quality_score": 1.1,
      "latency_ms": 695,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T03:10:01.000384+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356674Z"
    },
    "created_at": "2025-11-15T03:10:01.000404Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_5_plus_10": {
    "tool_id": "calculate_5_plus_10",
    "name": "Python implementation to calculate the sum of 5 and 10",
    "tool_type": "workflow",
    "description": "calculate 5 plus 10",
    "tags": [
      "arithmetic",
      "calculation",
      "sum",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_5_plus_10",
      "quality_score": 1.2000000000000002,
      "latency_ms": 30,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T03:20:30.324251+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356677Z"
    },
    "created_at": "2025-11-15T03:20:30.324266Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_the_most_optimal_code_to": {
    "tool_id": "write_the_most_optimal_code_to",
    "name": "Generates and prints the Fibonacci sequence in reverse order starting from 50.",
    "tool_type": "workflow",
    "description": "write the most optimal code to output the fibonacci sequence backwards from 50",
    "tags": [
      "fibonacci",
      "reverse",
      "sequence",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_the_most_optimal_code_to",
      "quality_score": 1.2000000000000002,
      "latency_ms": 34,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T03:27:58.780987+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356680Z"
    },
    "created_at": "2025-11-15T03:27:58.781005Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "tell_me_a_joke": {
    "tool_id": "tell_me_a_joke",
    "name": "Generates a joke based on the input theme or a default joke if no theme is provi",
    "tool_type": "workflow",
    "description": "tell me a joke",
    "tags": [
      "joke generation",
      "NLP",
      "ML",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "tell_me_a_joke",
      "quality_score": 1.1,
      "latency_ms": 688,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T03:37:23.056574+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356684Z"
    },
    "created_at": "2025-11-15T03:37:23.056616Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "fast_code_generator": {
    "tool_id": "fast_code_generator",
    "name": "Fast Code Generator",
    "tool_type": "llm",
    "description": "Fast code generation for simple tasks using gemma3:4b. Best for basic arithmetic, simple functions, straightforward algorithms. NOT suitable for complex logic, multi-step workflows, or sophisticated algorithms.",
    "tags": [
      "fast",
      "simple",
      "basic",
      "code-generation",
      "gemma3"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "gemma3:4b",
      "llm_endpoint": null,
      "system_prompt": "You are a fast code generator for SIMPLE tasks. You have a good context window. Generate clean, working Python code for basic tasks.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Generate Python code for this SIMPLE task:\n\n{task}\n\nRequirements:\n- Keep code simple and focused\n- Focus on correctness and clarity\n- Proper error handling\n- Must work for the specific task\n- Follow Python best practices\n\nGenerate clean, well-structured code.",
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "very-good",
      "max_output_length": "medium"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356688Z"
    },
    "created_at": "2025-11-15T23:05:48.995158Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "save_to_disk": {
    "tool_id": "save_to_disk",
    "name": "Save to Disk",
    "tool_type": "executable",
    "description": "Saves content to a file in the ./output/ directory (for safety). Use for saving stories, specifications, code, documentation, or any generated content. CRITICAL: Only saves to ./output/ directory to prevent accidental overwrites.",
    "tags": [
      "file-io",
      "save",
      "write",
      "disk",
      "output",
      "storage"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "python",
      "args": [
        "-c",
        "import sys, json, pathlib; data=json.load(sys.stdin); path=pathlib.Path('output')/data['filename']; path.parent.mkdir(parents=True, exist_ok=True); path.write_text(data['content']); print(json.dumps({'status': 'saved', 'path': str(path)}))"
      ],
      "install_command": null
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356691Z"
    },
    "created_at": "2025-11-15T23:05:49.011712Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "load_from_disk": {
    "tool_id": "load_from_disk",
    "name": "Load from Disk",
    "tool_type": "executable",
    "description": "Loads content from any file path on disk. Use for reading specifications, code, documentation, or configuration files. Can read from anywhere on the filesystem (not restricted to ./output/). Useful for self-optimization tasks where the system reads its own code.",
    "tags": [
      "file-io",
      "load",
      "read",
      "disk",
      "input"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "python",
      "args": [
        "-c",
        "import sys, json, pathlib; data=json.load(sys.stdin); path=pathlib.Path(data['filepath']); content=path.read_text() if path.exists() else None; print(json.dumps({'status': 'loaded' if content else 'not_found', 'content': content, 'path': str(path)}))"
      ],
      "install_command": null
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356695Z"
    },
    "created_at": "2025-11-15T23:05:49.011719Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_15_plus_25": {
    "tool_id": "calculate_15_plus_25",
    "name": "calculate 15 plus 25",
    "tool_type": "workflow",
    "description": "calculate 15 plus 25",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_15_plus_25",
      "quality_score": 1.1,
      "latency_ms": 788,
      "memory_mb_peak": 1.64,
      "created_at": "2025-11-15T03:59:07.086267+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356699Z"
    },
    "created_at": "2025-11-15T03:59:07.086285Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_code_to_do_one_plus_rand": {
    "tool_id": "write_code_to_do_one_plus_rand",
    "name": "write code to do one plus random number under 50",
    "tool_type": "workflow",
    "description": "write code to do one plus random number under 50",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_code_to_do_one_plus_rand",
      "quality_score": 1.1,
      "latency_ms": 685,
      "memory_mb_peak": 1.62,
      "created_at": "2025-11-15T04:08:37.271268+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356702Z"
    },
    "created_at": "2025-11-15T04:08:37.271301Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_technical_article_on_n": {
    "tool_id": "write_a_technical_article_on_n",
    "name": "write a technical article on nodules",
    "tool_type": "workflow",
    "description": "write a technical article on nodules",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_technical_article_on_n",
      "quality_score": 1.2000000000000002,
      "latency_ms": 33,
      "memory_mb_peak": 1.63,
      "created_at": "2025-11-15T04:16:26.611391+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356705Z"
    },
    "created_at": "2025-11-15T04:16:26.611410Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "pip_install": {
    "tool_id": "pip_install",
    "name": "Install Python Package",
    "tool_type": "executable",
    "description": "Installs Python packages using pip. Use when code requires external dependencies like requests, numpy, pandas, etc. Can install single packages or multiple packages at once. Supports version specifications (e.g., 'requests>=2.28.0'). Essential for code that imports third-party libraries.",
    "tags": [
      "dependencies",
      "pip",
      "install",
      "packages",
      "requirements",
      "setup"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "command": "python",
      "args": [
        "pip_install_tool.py"
      ],
      "install_command": null
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356709Z"
    },
    "created_at": "2025-11-15T23:05:49.011725Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "fast_content_writer": {
    "tool_id": "fast_content_writer",
    "name": "Fast Content Writer",
    "tool_type": "llm",
    "description": "Fast content generation using gemma3:4b. Best for stories, technical articles, essays, documentation, creative writing. Good balance of speed and quality for text generation tasks.",
    "tags": [
      "fast",
      "content",
      "writing",
      "story",
      "article",
      "gemma3"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "gemma3:4b",
      "llm_endpoint": null,
      "system_prompt": "You are a skilled content writer using gemma3:4b. Generate engaging, well-structured content for stories, technical articles, essays, and documentation.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "Generate content for this task:\n\n{task}\n\nRequirements:\n- Generate Python code that creates the requested content\n- Use print() or json.dumps() to output the content\n- Ensure the content is well-structured and engaging\n- Follow proper formatting and style\n- Include appropriate error handling\n\nGenerate clean, working code that produces the content.",
      "cost_tier": "free",
      "speed_tier": "fast",
      "quality_tier": "very-good",
      "max_output_length": "long"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356712Z"
    },
    "created_at": "2025-11-15T04:29:01.140398Z",
    "usage_count": 5,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke": {
    "tool_id": "write_a_joke",
    "name": "Generates a short, humorous joke based on predefined topics and a random number.",
    "tool_type": "workflow",
    "description": "write a joke",
    "tags": [
      "joke generation",
      "randomization",
      "topic selection",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_joke",
      "quality_score": 1.1,
      "latency_ms": 1629,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T04:33:08.225914+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356717Z"
    },
    "created_at": "2025-11-15T04:33:08.225941Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "wtie_mea_joke_about_the_welsh": {
    "tool_id": "wtie_mea_joke_about_the_welsh",
    "name": "wtie mea joke about the welsh and make up a random number.",
    "tool_type": "workflow",
    "description": "wtie mea joke about the welsh and make up a random number.",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "wtie_mea_joke_about_the_welsh",
      "quality_score": 1.2000000000000002,
      "latency_ms": 37,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T04:37:52.223348+00:00",
      "success_count": 1,
      "total_runs": 1,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356720Z"
    },
    "created_at": "2025-11-15T04:37:52.223369Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke_1763181926": {
    "tool_id": "write_a_joke_1763181926",
    "name": "Generates a joke based on user input (topic and optional setup)",
    "tool_type": "workflow",
    "description": "write a joke",
    "tags": [
      "joke",
      "generation",
      "nlp",
      "content_creation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_joke_1763181926",
      "quality_score": 1.2000000000000002,
      "latency_ms": 37,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T04:47:11.727841+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Generates a joke based on user input (topic and optional setup)",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356723Z"
    },
    "created_at": "2025-11-15T04:47:11.727855Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_joke": {
    "tool_id": "write_me_a_joke",
    "name": "Generates a joke based on user input topic and tone.",
    "tool_type": "workflow",
    "description": "write me a joke",
    "tags": [
      "joke_generation",
      "natural_language_processing",
      "machine_learning",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_joke",
      "quality_score": 1.1,
      "latency_ms": 675,
      "memory_mb_peak": 1.87,
      "created_at": "2025-11-15T04:51:25.425866+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Generates a joke based on user input topic and tone.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356727Z"
    },
    "created_at": "2025-11-15T04:51:25.425885Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_joke_1763182563": {
    "tool_id": "write_me_a_joke_1763182563",
    "name": "Generates a joke based on user input.",
    "tool_type": "workflow",
    "description": "write me a joke",
    "tags": [
      "joke",
      "generation",
      "nlp",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_joke_1763182563",
      "quality_score": 1.2000000000000002,
      "latency_ms": 33,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T04:56:34.138293+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Generates a joke based on user input.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356730Z"
    },
    "created_at": "2025-11-15T04:56:34.138310Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "content_generator": {
    "tool_id": "content_generator",
    "name": "Content Generator",
    "tool_type": "llm",
    "description": "General purpose content generation tool. Can generate jokes, stories, articles, essays, documentation, and creative writing. Use this from code via call_tool() when you need LLM-generated content.",
    "tags": [
      "content",
      "generation",
      "creative",
      "writing",
      "llm-tool"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": "llama3",
      "llm_endpoint": null,
      "system_prompt": "You are a creative content generator. Generate engaging, high-quality content based on the user's request. Be creative, natural, and appropriate to the content type.\n\nPriority: {priority}\nQuality expectation: {quality_level}\nSpeed requirement: {speed_requirement}",
      "prompt_template": "{prompt}\n\nGenerate creative, engaging content that matches this request. Return ONLY the content itself, no explanations or meta-commentary.",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "long"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356734Z"
    },
    "created_at": "2025-11-15T23:05:48.995166Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_5_and_3_1763184838": {
    "tool_id": "add_5_and_3_1763184838",
    "name": "add 5 and 3",
    "tool_type": "workflow",
    "description": "add 5 and 3",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_5_and_3_1763184838",
      "quality_score": 1.2000000000000002,
      "latency_ms": 33,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T05:34:25.206282+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "add 5 and 3",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356737Z"
    },
    "created_at": "2025-11-15T05:34:25.206297Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "multiply_6_by_7": {
    "tool_id": "multiply_6_by_7",
    "name": "Multiply 6 by 7",
    "tool_type": "workflow",
    "description": "multiply 6 by 7",
    "tags": [
      "arithmetic",
      "multiplication",
      "basic",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "multiply_6_by_7",
      "quality_score": 1.2000000000000002,
      "latency_ms": 32,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T05:39:37.051514+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Multiply 6 by 7",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356740Z"
    },
    "created_at": "2025-11-15T05:39:37.051531Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem": {
    "tool_id": "write_a_poem",
    "name": "Python code for generating a poem based on user input using a hybrid approach combining natural language processing (NLP) and machine learning (ML) techniques.",
    "tool_type": "workflow",
    "description": "write a poem",
    "tags": [
      "python",
      "nlp",
      "ml",
      "poetry",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_poem",
      "quality_score": 1.2000000000000002,
      "latency_ms": 34,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T05:43:05.313568+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code for generating a poem based on user input using a hybrid approach combining natural language processing (NLP) and machine learning (ML) techniques.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356744Z"
    },
    "created_at": "2025-11-15T05:43:05.313587Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_7_and_9": {
    "tool_id": "add_7_and_9",
    "name": "Calculates the sum of two integers.",
    "tool_type": "workflow",
    "description": "add 7 and 9",
    "tags": [
      "addition",
      "arithmetic",
      "integer",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_7_and_9",
      "quality_score": 1.2000000000000002,
      "latency_ms": 30,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T05:48:46.152613+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculates the sum of two integers.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356747Z"
    },
    "created_at": "2025-11-15T05:48:46.152626Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculat_1_1": {
    "tool_id": "calculat_1_1",
    "name": "Calculates 1+1",
    "tool_type": "workflow",
    "description": "CALCULAT 1+1",
    "tags": [
      "arithmetic",
      "addition",
      "calculator",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculat_1_1",
      "quality_score": 1.2000000000000002,
      "latency_ms": 41,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T06:12:04.938106+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculates 1+1",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356751Z"
    },
    "created_at": "2025-11-15T06:12:04.938129Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "calculate_5_plus_5": {
    "tool_id": "calculate_5_plus_5",
    "name": "Calculates 5 + 5 and prints the result as JSON.",
    "tool_type": "workflow",
    "description": "calculate 5 plus 5",
    "tags": [
      "arithmetic",
      "addition",
      "json",
      "simple",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "calculate_5_plus_5",
      "quality_score": 1.2000000000000002,
      "latency_ms": 26,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T06:14:46.234003+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculates 5 + 5 and prints the result as JSON.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356755Z"
    },
    "created_at": "2025-11-15T06:14:46.234019Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_then_translate_a_poen": {
    "tool_id": "write_then_translate_a_poen",
    "name": "Python code that generates a piece of content using the provided workflow composition and tools.",
    "tool_type": "workflow",
    "description": "write then translate a poen",
    "tags": [
      "python",
      "content generation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_then_translate_a_poen",
      "quality_score": 1.2000000000000002,
      "latency_ms": 29,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T06:22:10.129240+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that generates a piece of content using the provided workflow composition and tools.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356758Z"
    },
    "created_at": "2025-11-15T06:22:10.129256Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "tell_a_joke": {
    "tool_id": "tell_a_joke",
    "name": "Python code for generating jokes based on user-provided topics using LLM tools.",
    "tool_type": "workflow",
    "description": "tell a joke",
    "tags": [
      "python",
      "llm",
      "jokes",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "tell_a_joke",
      "quality_score": 1.2000000000000002,
      "latency_ms": 33,
      "memory_mb_peak": 1.87,
      "created_at": "2025-11-15T06:24:41.879927+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code for generating jokes based on user-provided topics using LLM tools.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356761Z"
    },
    "created_at": "2025-11-15T06:24:41.879945Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "tell_me_a_joke_about_programmi": {
    "tool_id": "tell_me_a_joke_about_programmi",
    "name": "Python code to generate a joke about programming using the content generation LLM tool.",
    "tool_type": "workflow",
    "description": "tell me a joke about programming",
    "tags": [
      "python",
      "llm",
      "content generation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "tell_me_a_joke_about_programmi",
      "quality_score": 1.2000000000000002,
      "latency_ms": 34,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T12:52:01.973335+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code to generate a joke about programming using the content generation LLM tool.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356765Z"
    },
    "created_at": "2025-11-15T12:52:01.973353Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_joke_and_translate_to_1763216276": {
    "tool_id": "write_a_joke_and_translate_to_1763216276",
    "name": "Python code for generating a joke in French based on an English input.",
    "tool_type": "workflow",
    "description": "write a joke and translate to french",
    "tags": [
      "python",
      "code generation",
      "joke",
      "translation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_joke_and_translate_to_1763216276",
      "quality_score": 1.1,
      "latency_ms": 1011,
      "memory_mb_peak": 1.88,
      "created_at": "2025-11-15T14:19:42.965735+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code for generating a joke in French based on an English input.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356768Z"
    },
    "created_at": "2025-11-15T14:19:42.965761Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "multiply_6_and_7_1763228888": {
    "tool_id": "multiply_6_and_7_1763228888",
    "name": "Calculates the product of 6 and 7 and prints the result as JSON.",
    "tool_type": "workflow",
    "description": "multiply 6 and 7",
    "tags": [
      "arithmetic",
      "multiplication",
      "json",
      "basic",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "multiply_6_and_7_1763228888",
      "quality_score": 1.2000000000000002,
      "latency_ms": 34,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T17:49:29.207589+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Calculates the product of 6 and 7 and prints the result as JSON.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356772Z"
    },
    "created_at": "2025-11-15T17:49:29.207608Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "http_content_fetcher": {
    "tool_id": "http_content_fetcher",
    "name": "HTTP Content Fetcher",
    "tool_type": "api_connector",
    "description": "Comprehensive HTTP client supporting all HTTP methods (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS), all body types (JSON, form-data, multipart, XML, text, binary), various authentication methods (Bearer, API Key, Basic, Digest), and flexible response handling. Designed for seamless integration with DSE workflow system. Can fetch content from any URL and return data in multiple formats.",
    "tags": [
      "http",
      "fetch",
      "content-fetching",
      "web",
      "api",
      "rest",
      "api-connector",
      "http-client",
      "download",
      "upload",
      "json",
      "xml",
      "form-data",
      "authentication",
      "bearer",
      "api-key",
      "workflow-integration"
    ],
    "parameters": {
      "url": {
        "type": "string",
        "required": true,
        "description": "Target URL to fetch content from"
      },
      "method": {
        "type": "string",
        "required": false,
        "default": "GET",
        "enum": [
          "GET",
          "POST",
          "PUT",
          "DELETE",
          "PATCH",
          "HEAD",
          "OPTIONS",
          "TRACE"
        ],
        "description": "HTTP method to use"
      },
      "headers": {
        "type": "object",
        "required": false,
        "description": "Custom HTTP headers"
      },
      "body": {
        "type": [
          "object",
          "string",
          "bytes"
        ],
        "required": false,
        "description": "Request body (dict, string, or bytes)"
      },
      "body_type": {
        "type": "string",
        "required": false,
        "default": "json",
        "enum": [
          "json",
          "form",
          "multipart",
          "xml",
          "text",
          "binary",
          "custom"
        ],
        "description": "Body content type"
      },
      "params": {
        "type": "object",
        "required": false,
        "description": "URL query parameters"
      },
      "auth": {
        "type": "object",
        "required": false,
        "description": "Authentication configuration (bearer, api_key, basic, digest, custom)"
      },
      "timeout": {
        "type": "integer",
        "required": false,
        "description": "Request timeout in seconds"
      },
      "response_format": {
        "type": "string",
        "required": false,
        "default": "auto",
        "enum": [
          "auto",
          "json",
          "text",
          "binary"
        ],
        "description": "Expected response format"
      }
    },
    "metadata": {
      "implementation_path": "src/http_content_fetcher.py",
      "implementation_class": "HTTPContentFetcher",
      "factory_function": "create_http_fetcher",
      "supports_streaming": true,
      "supports_file_upload": true,
      "supports_file_download": true,
      "max_retries": 3,
      "retry_backoff_factor": 0.3,
      "default_timeout": 30,
      "supported_methods": [
        "GET",
        "POST",
        "PUT",
        "DELETE",
        "PATCH",
        "HEAD",
        "OPTIONS",
        "TRACE"
      ],
      "supported_body_types": [
        "json",
        "form",
        "multipart",
        "xml",
        "text",
        "binary",
        "custom"
      ],
      "supported_auth_types": [
        "bearer",
        "api_key",
        "basic",
        "digest",
        "custom"
      ],
      "supported_response_formats": [
        "auto",
        "json",
        "text",
        "binary"
      ],
      "cost_tier": "low",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "reliability": "high",
      "workflow_compatible": true,
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356775Z"
    },
    "created_at": "2025-11-15T18:53:13.571594+00:00",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "accept_input_from_user": {
    "tool_id": "accept_input_from_user",
    "name": "Accept input from user",
    "tool_type": "workflow",
    "description": "Accept input from user",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "accept_input_from_user",
      "quality_score": 1.2000000000000002,
      "latency_ms": 23,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T19:00:00.330949+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Accept input from user",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356779Z"
    },
    "created_at": "2025-11-15T19:00:00.330968Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "save_input_to_database": {
    "tool_id": "save_input_to_database",
    "name": "Save input to database",
    "tool_type": "workflow",
    "description": "Save input to database",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "save_input_to_database",
      "quality_score": 1.1,
      "latency_ms": 888,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T19:05:48.796106+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Save input to database",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356782Z"
    },
    "created_at": "2025-11-15T19:05:48.796125Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "http_server": {
    "tool_id": "http_server",
    "name": "HTTP Server",
    "tool_type": "custom",
    "description": "HTTP server that allows workflows to serve content via HTTP. Supports both HTML and JSON/API responses. Enable workflows to be exposed as web services or REST APIs. Can register endpoints, handle requests, and return formatted responses.",
    "tags": [
      "http",
      "server",
      "api",
      "web",
      "rest",
      "endpoint",
      "service",
      "html",
      "json"
    ],
    "parameters": {},
    "metadata": {
      "from_config": true,
      "llm_model": null,
      "llm_endpoint": null,
      "system_prompt": null,
      "prompt_template": null,
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent",
      "max_output_length": "long"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356787Z"
    },
    "created_at": "2025-11-15T23:05:49.011732Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "review_this_code_usr_bin_en": {
    "tool_id": "review_this_code_usr_bin_en",
    "name": "Python script to review and validate shebang lines for Python interpreters.",
    "tool_type": "workflow",
    "description": "Review this code #!/usr/bin/env python3",
    "tags": [
      "shebang",
      "validation",
      "python",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "review_this_code_usr_bin_en",
      "quality_score": 1.2000000000000002,
      "latency_ms": 36,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T19:50:03.317107+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python script to review and validate shebang lines for Python interpreters.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356791Z"
    },
    "created_at": "2025-11-15T19:50:03.317127Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "install_python_package": {
    "tool_id": "install_python_package",
    "name": "Installs Python packages based on JSON input and reports installation status.",
    "tool_type": "workflow",
    "description": "Install Python Package",
    "tags": [
      "python",
      "pip",
      "package_installation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "install_python_package",
      "quality_score": 1.2000000000000002,
      "latency_ms": 42,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T19:59:19.151802+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Installs Python packages based on JSON input and reports installation status.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356794Z"
    },
    "created_at": "2025-11-15T19:59:19.151824Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "model_selector": {
    "tool_id": "model_selector",
    "name": "Model Selector",
    "tool_type": "custom",
    "description": "Intelligently select the best backend and model for a given task. Supports natural language selection like 'use GPT-4' or 'use Claude'. Considers speed, cost, quality, and context window requirements. Available backends: Ollama, OpenAI, Anthropic, Azure, LM Studio.",
    "tags": [
      "selection",
      "optimization",
      "model-management",
      "planning",
      "backend"
    ],
    "parameters": {
      "task_description": {
        "type": "string",
        "description": "Description of the task to perform"
      },
      "constraints": {
        "type": "object",
        "description": "Optional constraints like max_cost, min_speed"
      },
      "backend_preference": {
        "type": "string",
        "description": "Preferred backend (openai, anthropic, azure, etc.)"
      },
      "model_preference": {
        "type": "string",
        "description": "Preferred specific model name"
      },
      "top_k": {
        "type": "number",
        "description": "Number of recommendations to return (default: 3)"
      }
    },
    "metadata": {
      "speed_tier": "very-fast",
      "cost_tier": "free",
      "quality_tier": "excellent",
      "latency_ms": 50,
      "capability": "Model and backend selection with multi-backend support"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:27.727323Z"
    },
    "created_at": "2025-11-16T01:18:27.727316Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_poem_1763241023": {
    "tool_id": "write_a_poem_1763241023",
    "name": "Write a poem",
    "tool_type": "workflow",
    "description": "Write a poem",
    "tags": [
      "generated",
      "chat",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_poem_1763241023",
      "quality_score": 1.2000000000000002,
      "latency_ms": 43,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-15T21:13:03.025254+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Write a poem",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356801Z"
    },
    "created_at": "2025-11-15T21:13:03.025275Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "translate_the_poem_to_french": {
    "tool_id": "translate_the_poem_to_french",
    "name": "Translates an English poem to French while preserving meaning and tone.",
    "tool_type": "workflow",
    "description": "Translate the poem to French",
    "tags": [
      "translation",
      "poem",
      "French",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "translate_the_poem_to_french",
      "quality_score": 1.1,
      "latency_ms": 846,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-15T21:16:36.803438+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Translates an English poem to French while preserving meaning and tone.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356804Z"
    },
    "created_at": "2025-11-15T21:16:36.803465Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "add_1_5": {
    "tool_id": "add_1_5",
    "name": "Adds two integers or generates a joke about cats",
    "tool_type": "workflow",
    "description": "add 1 + 5",
    "tags": [
      "addition",
      "arithmetic",
      "joke",
      "content_generation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "add_1_5",
      "quality_score": 1.1,
      "latency_ms": 1071,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-15T22:28:13.519027+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Adds two integers or generates a joke about cats",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356808Z"
    },
    "created_at": "2025-11-15T22:28:13.519050Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "get_english_word": {
    "tool_id": "get_english_word",
    "name": "Python code that generates a single English word from an input string, given the user's request \"get english word\".",
    "tool_type": "workflow",
    "description": "get english word",
    "tags": [
      "python",
      "code generation",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "get_english_word",
      "quality_score": 1.1,
      "latency_ms": 883,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T00:00:05.281771+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that generates a single English word from an input string, given the user's request \"get english word\".",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356811Z"
    },
    "created_at": "2025-11-16T00:00:05.281792Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "basic_calculator": {
    "tool_id": "basic_calculator",
    "name": "Basic Calculator",
    "tool_type": "executable",
    "description": "Fast arithmetic operations (add, subtract, multiply, divide, power, modulo). Direct Python execution - no LLM needed. Use for simple math.",
    "tags": [
      "math",
      "arithmetic",
      "calculator",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\basic_calculator.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); ops={'add': lambda a,b: a+b, 'subtract': lambda a,b: a-b, 'multiply': lambda a,b: a*b, 'divide': lambda a,b: a/b if b!=0 else float('inf'), 'power': lambda a,b: a**b, 'modulo': lambda a,b: a%b if b!=0 else 0}; result=ops.get(data['operation'], ops['add'])(data.get('a', 0), data.get('b', 0)); print(json.dumps({'result': result, 'operation': data.get('operation', 'add')}))"
      ],
      "input_schema": {
        "operation": "str - Operation: 'add', 'subtract', 'multiply', 'divide', 'power', 'modulo'",
        "a": "number - First operand",
        "b": "number - Second operand"
      },
      "output_schema": {
        "result": "number - Result of the operation",
        "operation": "str - Operation performed"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356815Z"
    },
    "created_at": "2025-11-16T00:20:57.633389Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "text_formatter": {
    "tool_id": "text_formatter",
    "name": "Text Formatter",
    "tool_type": "executable",
    "description": "Fast text formatting operations (uppercase, lowercase, title case, reverse, trim, etc.). Direct Python execution - instant results.",
    "tags": [
      "text",
      "formatting",
      "string",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\text_formatter.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); text=data.get('text', ''); ops={'upper': str.upper, 'lower': str.lower, 'title': str.title, 'capitalize': str.capitalize, 'reverse': lambda s: s[::-1], 'trim': str.strip, 'remove_spaces': lambda s: s.replace(' ', '')}; result=ops.get(data.get('operation', 'lower'), ops['lower'])(text); print(json.dumps({'result': result, 'operation': data.get('operation', 'lower'), 'original': text}))"
      ],
      "input_schema": {
        "text": "str - Text to format",
        "operation": "str - Operation: 'upper', 'lower', 'title', 'capitalize', 'reverse', 'trim', 'remove_spaces'"
      },
      "output_schema": {
        "result": "str - Formatted text",
        "operation": "str - Operation performed",
        "original": "str - Original text"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356818Z"
    },
    "created_at": "2025-11-16T00:20:57.640199Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "unit_converter": {
    "tool_id": "unit_converter",
    "name": "Unit Converter",
    "tool_type": "executable",
    "description": "Fast unit conversions (length, weight, temperature, time). Direct Python execution. Supports common units like meters/feet, kg/lbs, celsius/fahrenheit, etc.",
    "tags": [
      "conversion",
      "units",
      "measurement",
      "fast",
      "deterministic"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "executable\\unit_converter.yaml",
      "command": "python",
      "args": [
        "-c",
        "import sys, json; data=json.load(sys.stdin); conversions={'m_to_ft': lambda x: x*3.28084, 'ft_to_m': lambda x: x/3.28084, 'kg_to_lbs': lambda x: x*2.20462, 'lbs_to_kg': lambda x: x/2.20462, 'c_to_f': lambda x: x*9/5+32, 'f_to_c': lambda x: (x-32)*5/9, 'km_to_mi': lambda x: x*0.621371, 'mi_to_km': lambda x: x/0.621371}; conv=data.get('conversion', 'm_to_ft'); result=conversions.get(conv, conversions['m_to_ft'])(data.get('value', 0)); print(json.dumps({'result': result, 'conversion': conv, 'original_value': data.get('value', 0)}))"
      ],
      "input_schema": {
        "conversion": "str - Conversion type: 'm_to_ft', 'ft_to_m', 'kg_to_lbs', 'lbs_to_kg', 'c_to_f', 'f_to_c', 'km_to_mi', 'mi_to_km'",
        "value": "number - Value to convert"
      },
      "output_schema": {
        "result": "number - Converted value",
        "conversion": "str - Conversion performed",
        "original_value": "number - Original value"
      },
      "cost_tier": "free",
      "speed_tier": "very-fast",
      "quality_tier": "excellent"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356821Z"
    },
    "created_at": "2025-11-16T00:20:57.641535Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "quick_translator": {
    "tool_id": "quick_translator",
    "name": "Quick Translator",
    "tool_type": "llm",
    "description": "Direct translation for words and short phrases. Returns immediate results without code generation. For longer translations (paragraphs, documents), use NMT translator or full translation workflow instead.",
    "tags": [
      "translation",
      "quick",
      "words",
      "phrases",
      "llm"
    ],
    "parameters": {},
    "metadata": {
      "from_yaml": true,
      "yaml_file": "llm\\quick_translator.yaml",
      "llm_tier": "content.tier_2",
      "llm_role": "translator",
      "system_prompt": "You are a translator. Translate text accurately and concisely.\n\nPriority: {priority}\nQuality: {quality_level}\nSpeed: {speed_requirement}\n",
      "prompt_template": "Translate the following from {source_lang} to {target_lang}:\n\n\"{text}\"\n\nProvide ONLY the translation, no explanations or alternatives.\n",
      "cost_tier": "medium",
      "speed_tier": "fast",
      "quality_tier": "excellent",
      "max_output_length": "short"
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356825Z"
    },
    "created_at": "2025-11-16T00:20:57.648576Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_a_haiku_about_coding": {
    "tool_id": "write_a_haiku_about_coding",
    "name": "Python code that generates a Haiku about coding using natural language processing and programming concepts.",
    "tool_type": "workflow",
    "description": "write a haiku about coding",
    "tags": [
      "python",
      "natural language processing",
      "programming",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_a_haiku_about_coding",
      "quality_score": 1.1,
      "latency_ms": 863,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T00:36:08.122382+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that generates a Haiku about coding using natural language processing and programming concepts.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356828Z"
    },
    "created_at": "2025-11-16T00:36:08.122401Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "exit_1763253889": {
    "tool_id": "exit_1763253889",
    "name": "Python code that prints the string 'exit' when a specific input is provided.",
    "tool_type": "workflow",
    "description": "exit",
    "tags": [
      "python",
      "paradigms",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "exit_1763253889",
      "quality_score": 1.2000000000000002,
      "latency_ms": 51,
      "memory_mb_peak": 1.91,
      "created_at": "2025-11-16T00:46:00.821330+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that prints the string 'exit' when a specific input is provided.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356831Z"
    },
    "created_at": "2025-11-16T00:46:00.821348Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_poem": {
    "tool_id": "write_me_a_poem",
    "name": "Python code that generates a poem based on user input using LLM tools.",
    "tool_type": "workflow",
    "description": "write me a poem",
    "tags": [
      "python",
      "llm",
      "poetry",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_poem",
      "quality_score": 1.1,
      "latency_ms": 1036,
      "memory_mb_peak": 1.9,
      "created_at": "2025-11-16T01:04:54.024940+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that generates a poem based on user input using LLM tools.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356835Z"
    },
    "created_at": "2025-11-16T01:04:54.024984Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  },
  "write_me_a_poem_1763255171": {
    "tool_id": "write_me_a_poem_1763255171",
    "name": "Python code that generates a poem based on user input using natural language processing and machine learning techniques.",
    "tool_type": "workflow",
    "description": "write me a poem",
    "tags": [
      "python",
      "nlp",
      "machine-learning",
      "poetry",
      "auto-generated",
      "workflow"
    ],
    "parameters": {},
    "metadata": {
      "node_id": "write_me_a_poem_1763255171",
      "quality_score": 1.2000000000000002,
      "latency_ms": 46,
      "memory_mb_peak": 1.89,
      "created_at": "2025-11-16T01:09:17.223041+00:00",
      "success_count": 1,
      "total_runs": 1,
      "full_title": "Python code that generates a poem based on user input using natural language processing and machine learning techniques.",
      "from_index": true
    },
    "constraints": {},
    "current_usage": {
      "storage_mb": 0.0,
      "memory_mb": 0.0,
      "calls_count": 0,
      "last_reset": "2025-11-16T01:18:18.356838Z"
    },
    "created_at": "2025-11-16T01:09:17.223066Z",
    "usage_count": 0,
    "version": "1.0.0",
    "definition_hash": "",
    "breaking_changes": []
  }
}