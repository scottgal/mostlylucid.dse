#!/usr/bin/env python3
"""
Mock Generator Tool

Generates pytest fixtures and mock data for testing Python tools.
Creates comprehensive mocks for subprocess calls, file I/O, and tool outputs.

Usage:
    # Generate mocks for a tool
    python mock_generator.py <tool_name>

    # Generate for all tools
    python mock_generator.py --all

    # Specify output directory
    python mock_generator.py <tool_name> --output-dir tests/

Exit codes:
    0 - Success
    1 - Generation failed
    2 - Invalid arguments
"""

import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict


@dataclass
class MockScenario:
    """Represents a mock test scenario."""
    name: str
    description: str
    input_file_content: str
    expected_output: Dict[str, Any]
    subprocess_mock: Dict[str, Any]
    file_state: str  # 'unchanged', 'modified', 'created', 'deleted'


class MockGenerator:
    """Generates pytest mocks and fixtures for tools."""

    def __init__(self, tool_name: str, output_dir: Optional[Path] = None):
        """
        Initialize mock generator.

        Args:
            tool_name: Name of the tool (e.g., 'ruff_checker')
            output_dir: Output directory for generated mocks
        """
        self.tool_name = tool_name
        self.output_dir = output_dir or Path(__file__).parent
        self.mock_file = self.output_dir / f"{tool_name}_mocks.py"

    def generate_mock_file(self, scenarios: List[MockScenario]) -> str:
        """
        Generate complete mock file with fixtures.

        Args:
            scenarios: List of mock scenarios

        Returns:
            Generated Python code as string
        """
        code = self._generate_header()
        code += self._generate_imports()
        code += self._generate_shared_fixtures()
        code += self._generate_scenario_fixtures(scenarios)
        code += self._generate_subprocess_mocks(scenarios)
        code += self._generate_mock_data()
        return code

    def _generate_header(self) -> str:
        """Generate file header."""
        return f'''"""
Mock fixtures for {self.tool_name} tests.

This file is auto-generated by mock_generator.py.
Contains pytest fixtures for testing {self.tool_name}.
"""

'''

    def _generate_imports(self) -> str:
        """Generate import statements."""
        return '''import pytest
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, Any
from unittest.mock import MagicMock, Mock


'''

    def _generate_shared_fixtures(self) -> str:
        """Generate shared fixtures used across tests."""
        return '''# ===== Shared Fixtures =====

@pytest.fixture
def temp_python_file():
    """Create a temporary Python file for testing."""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write('print("Hello, World!")\\n')
        temp_path = Path(f.name)
    yield temp_path
    if temp_path.exists():
        temp_path.unlink()


@pytest.fixture
def temp_dir():
    """Create a temporary directory for testing."""
    import tempfile
    temp_dir_path = Path(tempfile.mkdtemp())
    yield temp_dir_path
    import shutil
    shutil.rmtree(temp_dir_path, ignore_errors=True)


@pytest.fixture
def mock_subprocess_success(mocker):
    """Mock subprocess.run to return success (exit code 0)."""
    mock = mocker.patch('subprocess.run')
    mock.return_value = Mock()
    mock.return_value.returncode = 0
    mock.return_value.stdout = ''
    mock.return_value.stderr = ''
    return mock


@pytest.fixture
def mock_subprocess_failure(mocker):
    """Mock subprocess.run to return failure (exit code 1)."""
    mock = mocker.patch('subprocess.run')
    mock.return_value = Mock()
    mock.return_value.returncode = 1
    mock.return_value.stdout = 'Error: issues found'
    mock.return_value.stderr = ''
    return mock


@pytest.fixture
def mock_subprocess_error(mocker):
    """Mock subprocess.run to return error (exit code 2)."""
    mock = mocker.patch('subprocess.run')
    mock.return_value = Mock()
    mock.return_value.returncode = 2
    mock.return_value.stdout = ''
    mock.return_value.stderr = 'Error: tool not found'
    return mock


@pytest.fixture
def mock_file_not_found(mocker):
    """Mock subprocess.run to raise FileNotFoundError."""
    mock = mocker.patch('subprocess.run')
    mock.side_effect = FileNotFoundError('Tool not found')
    return mock


@pytest.fixture
def mock_timeout(mocker):
    """Mock subprocess.run to raise TimeoutExpired."""
    mock = mocker.patch('subprocess.run')
    mock.side_effect = subprocess.TimeoutExpired('command', 30)
    return mock


'''

    def _generate_scenario_fixtures(self, scenarios: List[MockScenario]) -> str:
        """Generate fixtures for each scenario."""
        code = "# ===== Scenario-Specific Fixtures =====\n\n"

        for scenario in scenarios:
            fixture_name = scenario.name.lower().replace(' ', '_').replace('-', '_')

            code += f'''@pytest.fixture
def {fixture_name}():
    """{scenario.description}"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
        f.write("""{scenario.input_file_content}""")
        temp_path = Path(f.name)
    yield temp_path
    if temp_path.exists():
        temp_path.unlink()


'''

        return code

    def _generate_subprocess_mocks(self, scenarios: List[MockScenario]) -> str:
        """Generate subprocess mock fixtures for scenarios."""
        code = "# ===== Subprocess Mocks for Scenarios =====\n\n"

        for scenario in scenarios:
            mock_name = f"mock_{scenario.name.lower().replace(' ', '_').replace('-', '_')}_subprocess"

            code += f'''@pytest.fixture
def {mock_name}(mocker):
    """Mock subprocess for {scenario.name} scenario."""
    mock = mocker.patch('subprocess.run')
    mock.return_value = Mock()
    mock.return_value.returncode = {scenario.subprocess_mock.get('returncode', 0)}
    mock.return_value.stdout = """{scenario.subprocess_mock.get('stdout', '')}"""
    mock.return_value.stderr = """{scenario.subprocess_mock.get('stderr', '')}"""
    return mock


'''

        return code

    def _generate_mock_data(self) -> str:
        """Generate mock data constants."""
        return '''# ===== Mock Data Constants =====

MOCK_TOOL_VERSION = "1.0.0"

MOCK_JSON_OUTPUT_TEMPLATE = {
    "success": True,
    "issues_found": 0,
    "output": "No issues found"
}

MOCK_ERROR_OUTPUT = {
    "success": False,
    "issues_found": 0,
    "output": "Error occurred"
}
'''

    def write_mock_file(self, content: str):
        """Write generated mock content to file."""
        self.mock_file.write_text(content)
        print(f"Generated mock file: {self.mock_file}")


# Tool-specific scenario generators

def generate_ruff_scenarios() -> List[MockScenario]:
    """Generate scenarios for ruff_checker."""
    return [
        MockScenario(
            name="clean_file",
            description="Python file with no linting issues",
            input_file_content='''#!/usr/bin/env python3
"""Clean Python file."""

def main():
    """Main function."""
    print("Hello, World!")

if __name__ == '__main__':
    main()
''',
            expected_output={"success": True, "issues_found": 0},
            subprocess_mock={"returncode": 0, "stdout": "", "stderr": ""},
            file_state="unchanged"
        ),
        MockScenario(
            name="file_with_unused_imports",
            description="Python file with unused imports",
            input_file_content='''import sys
import os  # unused
import json  # unused

def main():
    print(sys.version)

if __name__ == '__main__':
    main()
''',
            expected_output={"success": False, "issues_found": 2},
            subprocess_mock={
                "returncode": 1,
                "stdout": '[{"code": "F401", "message": "\'os\' imported but unused"}]',
                "stderr": ""
            },
            file_state="modified"
        ),
        MockScenario(
            name="file_with_syntax_error",
            description="Python file with syntax errors",
            input_file_content='''def main(
    print("Missing closing paren")
''',
            expected_output={"success": False, "issues_found": 1},
            subprocess_mock={
                "returncode": 1,
                "stdout": "SyntaxError: invalid syntax",
                "stderr": ""
            },
            file_state="unchanged"
        )
    ]


def generate_autoflake_scenarios() -> List[MockScenario]:
    """Generate scenarios for autoflake_checker."""
    return [
        MockScenario(
            name="file_all_imports_used",
            description="Python file with all imports used",
            input_file_content='''import sys
import os

def main():
    print(sys.version)
    print(os.name)

if __name__ == '__main__':
    main()
''',
            expected_output={"success": True, "changes_needed": False},
            subprocess_mock={"returncode": 0, "stdout": "", "stderr": ""},
            file_state="unchanged"
        ),
        MockScenario(
            name="file_with_unused_imports",
            description="Python file with unused imports",
            input_file_content='''import sys
import os  # unused
import json  # unused

def main():
    print(sys.version)
''',
            expected_output={"success": True, "changes_needed": True},
            subprocess_mock={"returncode": 0, "stdout": "import sys\n\ndef main():\n    print(sys.version)", "stderr": ""},
            file_state="modified"
        )
    ]


def generate_pyupgrade_scenarios() -> List[MockScenario]:
    """Generate scenarios for pyupgrade_checker."""
    return [
        MockScenario(
            name="modern_code",
            description="Python file with modern syntax",
            input_file_content='''def main():
    name = "World"
    print(f"Hello, {name}!")
''',
            expected_output={"success": True, "changes_needed": False},
            subprocess_mock={"returncode": 0, "stdout": "", "stderr": ""},
            file_state="unchanged"
        ),
        MockScenario(
            name="old_style_formatting",
            description="Python file using old-style string formatting",
            input_file_content='''def main():
    name = "World"
    print("Hello, %s!" % name)
''',
            expected_output={"success": True, "changes_needed": True},
            subprocess_mock={
                "returncode": 0,
                "stdout": 'def main():\n    name = "World"\n    print(f"Hello, {name}!")',
                "stderr": ""
            },
            file_state="modified"
        )
    ]


def generate_mypy_scenarios() -> List[MockScenario]:
    """Generate scenarios for mypy_checker."""
    return [
        MockScenario(
            name="well_typed_code",
            description="Python file with correct type annotations",
            input_file_content='''def add(a: int, b: int) -> int:
    return a + b

result: int = add(1, 2)
''',
            expected_output={"success": True, "errors_found": 0},
            subprocess_mock={"returncode": 0, "stdout": "Success: no issues found in 1 source file", "stderr": ""},
            file_state="unchanged"
        ),
        MockScenario(
            name="type_mismatch",
            description="Python file with type errors",
            input_file_content='''def add(a: int, b: int) -> int:
    return a + b

result: str = add(1, 2)  # Type error
''',
            expected_output={"success": False, "errors_found": 1},
            subprocess_mock={
                "returncode": 1,
                "stdout": "test.py:4:1: error: Incompatible types in assignment",
                "stderr": ""
            },
            file_state="unchanged"
        )
    ]


def generate_bandit_scenarios() -> List[MockScenario]:
    """Generate scenarios for bandit_checker."""
    return [
        MockScenario(
            name="secure_code",
            description="Python file with no security issues",
            input_file_content='''import hashlib

def hash_password(password: str) -> str:
    return hashlib.sha256(password.encode()).hexdigest()
''',
            expected_output={"success": True, "issues_found": 0},
            subprocess_mock={"returncode": 0, "stdout": "No issues identified.", "stderr": ""},
            file_state="unchanged"
        ),
        MockScenario(
            name="sql_injection_vulnerability",
            description="Python file with SQL injection vulnerability",
            input_file_content='''import sqlite3

def get_user(user_id):
    conn = sqlite3.connect('users.db')
    cursor = conn.cursor()
    query = f"SELECT * FROM users WHERE id = {user_id}"  # Vulnerable
    cursor.execute(query)
    return cursor.fetchone()
''',
            expected_output={"success": False, "issues_found": 1},
            subprocess_mock={
                "returncode": 1,
                "stdout": '{"results": [{"issue_severity": "MEDIUM", "issue_text": "Possible SQL injection"}]}',
                "stderr": ""
            },
            file_state="unchanged"
        )
    ]


def main() -> None:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Generate pytest mocks and fixtures for tools'
    )
    parser.add_argument(
        'tool_name',
        nargs='?',
        help='Name of the tool (e.g., ruff_checker, autoflake_checker)'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='Generate mocks for all tools'
    )
    parser.add_argument(
        '--output-dir',
        type=Path,
        help='Output directory for generated mocks'
    )

    args = parser.parse_args()

    if not args.tool_name and not args.all:
        print("Error: Provide tool_name or use --all", file=sys.stderr)
        sys.exit(2)

    tools_to_generate = []
    if args.all:
        tools_to_generate = [
            ('ruff_checker', generate_ruff_scenarios),
            ('autoflake_checker', generate_autoflake_scenarios),
            ('pyupgrade_checker', generate_pyupgrade_scenarios),
            ('mypy_checker', generate_mypy_scenarios),
            ('bandit_checker', generate_bandit_scenarios)
        ]
    else:
        # Map tool name to scenario generator
        scenario_generators = {
            'ruff_checker': generate_ruff_scenarios,
            'autoflake_checker': generate_autoflake_scenarios,
            'pyupgrade_checker': generate_pyupgrade_scenarios,
            'mypy_checker': generate_mypy_scenarios,
            'bandit_checker': generate_bandit_scenarios
        }

        if args.tool_name not in scenario_generators:
            print(f"Error: Unknown tool '{args.tool_name}'", file=sys.stderr)
            print(f"Available tools: {', '.join(scenario_generators.keys())}", file=sys.stderr)
            sys.exit(2)

        tools_to_generate = [(args.tool_name, scenario_generators[args.tool_name])]

    # Generate mocks for each tool
    for tool_name, generator_func in tools_to_generate:
        print(f"\nGenerating mocks for {tool_name}...")

        mock_gen = MockGenerator(tool_name, args.output_dir)
        scenarios = generator_func()

        mock_content = mock_gen.generate_mock_file(scenarios)
        mock_gen.write_mock_file(mock_content)

        print(f"✓ Generated {len(scenarios)} scenarios for {tool_name}")

    print("\n✓ Mock generation complete!")
    sys.exit(0)


if __name__ == '__main__':
    main()
